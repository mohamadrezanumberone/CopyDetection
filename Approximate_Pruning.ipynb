{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamadrezanumberone/CopyDetection/blob/master/Approximate_Pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElVeuqlSkrH4"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu8AH32AkpZE",
        "outputId": "e4b0e100-49f0-4560-b03b-3126148f7deb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ptflops\n",
            "  Downloading ptflops-0.6.9.tar.gz (12 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from ptflops) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->ptflops) (4.1.1)\n",
            "Building wheels for collected packages: ptflops\n",
            "  Building wheel for ptflops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ptflops: filename=ptflops-0.6.9-py3-none-any.whl size=11712 sha256=ac5c01bdd3c9d565677f497b1644d8dd3faf87b7ca4d3d00987e350c05b70b21\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/71/2f/92426c1ef33fb2e275b533878d8378f91c7f26846d9669019c\n",
            "Successfully built ptflops\n",
            "Installing collected packages: ptflops\n",
            "Successfully installed ptflops-0.6.9\n"
          ]
        }
      ],
      "source": [
        "!pip install ptflops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGlznXnPj8Sc"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import gzip\n",
        "import shutil\n",
        "import torchvision\n",
        "import torch.utils.data as data\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import time\n",
        "import os\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "import torchsummary\n",
        "from sklearn.cluster import KMeans\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "from scipy import ndimage\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from collections import OrderedDict \n",
        "import math\n",
        "import torch.quantization.quantize_fx as quantize_fx\n",
        "from torch.quantization import QuantStub, DeQuantStub\n",
        "from ptflops import get_model_complexity_info\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuErdWcGk-b6"
      },
      "source": [
        "# Initialization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Tmu4LpIk3EW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a01cf78b-9aaa-4c51-bbc0-36a87338d325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "num_class = 10\n",
        "num_epochs = 15\n",
        "batch_size = 64\n",
        "feature_extract = True\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN_afon3a3Ff"
      },
      "source": [
        "# Mounting Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkXGE5qRa8se"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CIFAR10('./CIFAR10', train= True, transform= transforms.ToTensor(), target_transform = None, download= True)\n",
        "test_dataset = CIFAR10('./CIFAR10', train= False, transform= transforms.ToTensor(), target_transform = None, download= True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMdV9JhIe0NL",
        "outputId": "84d78af0-6715-422e-8989-cfb0d7b7d2ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgFLB-0Ma_tI"
      },
      "source": [
        "# Copying Content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmleqcIMlymg"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/My Drive/Colab Notebooks/SVHN/raw_svhn_imgs\" \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oP3O41__IMbb"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/My Drive/Colab Notebooks/SVHN/svhn_lbls\" \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4RjNOcZbHA7"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/My Drive/Colab Notebooks/SVHN/cls_svhn_imgs\" \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8VpCCUqxwwz"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/MyDrive/Colab Notebooks/SVHN/raw_t_svhn_imgs\" \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucYftA3rxyK4"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/My Drive/Colab Notebooks/SVHN/t_svhn_lbls\" \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ad0jUrYvxyaJ"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/My Drive/Colab Notebooks/SVHN/cls_t__svhn_imgs\" \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFQR-YPmUz46"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/My Drive/Colab Notebooks/CIFAR/raw_imgs\" \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfOCCytNUz47"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/My Drive/Colab Notebooks/CIFAR/labels\" \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uH870KW0Uz47"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/My Drive/Colab Notebooks/CIFAR/cls_imgs\" \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g3A6SjBUz47"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/MyDrive/Colab Notebooks/CIFAR/t_raw_imgs\" \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zAEdJedUz48"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/My Drive/Colab Notebooks/CIFAR/t_labels\" \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qc2BiuWiUz48"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/My Drive/Colab Notebooks/CIFAR/t_clustered\" \"/content/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3sxlY8RbWIk"
      },
      "source": [
        "# Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nwn3EFG8A7x"
      },
      "outputs": [],
      "source": [
        "img_s = torch.load('raw_svhn_imgs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBARo0tk8A7z",
        "outputId": "5fd83183-e9c8-410b-ebd2-be4929f6d1dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([73257, 3, 32, 32])"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imgs = [torch.tensor(t).squeeze(0).float() for t in img_s]\n",
        "imgs = torch.stack(imgs, dim=0).float().to(device)\n",
        "imgs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMj7D5Oe8A7z"
      },
      "outputs": [],
      "source": [
        "t_img_s = torch.load('raw_t_svhn_imgs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmttac1u8A70",
        "outputId": "b4599bec-7d0e-455e-c774-98ba135e5e69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([26032, 3, 32, 32])"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t_imgs = [torch.tensor(t).squeeze(0).float() for t in t_img_s]\n",
        "t_imgs = torch.stack(t_imgs, dim=0).float().to(device)\n",
        "t_imgs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dP5ZLYi48A70"
      },
      "outputs": [],
      "source": [
        "cls_imgs = torch.load('cls_svhn_imgs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5UwvLwZ8A70",
        "outputId": "55019a6b-721f-4aab-8254-83bbe8d9a1f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([73257, 1, 32, 32])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clustered_imgs = torch.tensor(cls_imgs).unsqueeze(1).float().to(device)\n",
        "clustered_imgs.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bIUw-7i8A71"
      },
      "outputs": [],
      "source": [
        "t_cls_imgs = torch.load('cls_t__svhn_imgs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTSPl9yV8A71",
        "outputId": "06ef6542-6057-4435-a422-15afb81b354c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([26032, 1, 32, 32])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t_clustered_imgs = torch.tensor(t_cls_imgs).unsqueeze(1).float().to(device)\n",
        "t_clustered_imgs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LylPIto_8A71"
      },
      "outputs": [],
      "source": [
        "lbls = torch.load('svhn_lbls')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDeuPSbq8A72",
        "outputId": "21079039-07b6-4b12-e2b3-b3b3b93797cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([73257])"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lbls = torch.tensor(lbls)\n",
        "lbls.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCMsI4AN8A72"
      },
      "outputs": [],
      "source": [
        "t_lbls = torch.load('t_svhn_lbls')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1IJDGTz8A72",
        "outputId": "63ea4d5b-86b0-4419-f956-d5eada823430"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([26032])"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t_lbls = torch.tensor(t_lbls)\n",
        "t_lbls.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayyYpGy0loaY"
      },
      "outputs": [],
      "source": [
        "img_s = torch.load('raw_imgs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc0fx3Vb7aSS",
        "outputId": "afdfcb38-9b84-4880-85a2-a4e4ab7a821e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "imgs = [torch.tensor(t).squeeze(0).float() for t in img_s]\n",
        "imgs = torch.stack(imgs, dim=0).float().to(device)\n",
        "imgs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxUn5eBn5SZ6"
      },
      "outputs": [],
      "source": [
        "t_img_s = torch.load('t_raw_imgs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLv3E10v5Sn6",
        "outputId": "5d50d0b5-6721-4840-e21a-a273f7151e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "t_imgs = [torch.tensor(t).squeeze(0).float() for t in t_img_s]\n",
        "t_imgs = torch.stack(t_imgs, dim=0).float().to(device)\n",
        "t_imgs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geVEz89ObVGF"
      },
      "outputs": [],
      "source": [
        "cls_imgs = torch.load('cls_imgs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybxB5PLgJN7G",
        "outputId": "92ae4913-1f27-464f-d10d-be1ede349b56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 1, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "clustered_imgs = torch.tensor(cls_imgs).unsqueeze(1).float().to(device)\n",
        "clustered_imgs.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cteESkvg6es1"
      },
      "outputs": [],
      "source": [
        "t_cls_imgs = torch.load('t_clustered')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evEt__P76e5v",
        "outputId": "774207d5-17bb-43f9-9cb2-5bfc97f02f9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 1, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "t_clustered_imgs = torch.tensor(t_cls_imgs).unsqueeze(1).float().to(device)\n",
        "t_clustered_imgs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWHI70YbIbXk"
      },
      "outputs": [],
      "source": [
        "lbls = torch.load('labels')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKISiJhfIbif",
        "outputId": "5ab52cce-fdae-4f66-a771-03a8bb2fd4b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "lbls = torch.tensor(lbls)\n",
        "lbls.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KngIOSC6Hf8"
      },
      "outputs": [],
      "source": [
        "t_lbls = torch.load('t_labels')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_liw11gn6Hnz",
        "outputId": "fd26a667-afc0-4b65-9bf0-801332e1afb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "t_lbls = torch.tensor(t_lbls)\n",
        "t_lbls.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dciBGVIol4kf"
      },
      "source": [
        "# Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fv-MLFyMl8q3"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(data.Dataset):\n",
        "    def __init__(self):\n",
        "        self.raw_images = imgs\n",
        "        self.clustered_images = clustered_imgs\n",
        "        self.labels = lbls\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, image_labels, clusteredimage = self.raw_images[idx], self.labels[idx], self.clustered_images[idx]\n",
        "        return image, image_labels, clusteredimage\n",
        "    def __len__(self):\n",
        "        return len(self.raw_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gh6hNAba86Z1"
      },
      "outputs": [],
      "source": [
        "class TestCustomDataset(data.Dataset):\n",
        "    def __init__(self):\n",
        "        self.t_raw_images = t_imgs\n",
        "        self.t_clustered_images = t_clustered_imgs\n",
        "        self.t_labels = t_lbls\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        test_image, test_image_labels, testclusteredimage  = self.t_raw_images[idx], self.t_labels[idx], self.t_clustered_images[idx]\n",
        "        return test_image, test_image_labels, testclusteredimage\n",
        "    def __len__(self):\n",
        "        return len(self.t_raw_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdIVyq1bppSg"
      },
      "outputs": [],
      "source": [
        "# class CustomDataset(data.Dataset):\n",
        "#     def __init__(self):\n",
        "#         self.raw_images = imgs\n",
        "#         self.labels = lbls\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         image, image_labels = self.raw_images[idx], self.labels[idx]\n",
        "#         return image, image_labels\n",
        "#     def __len__(self):\n",
        "#         return len(self.raw_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2jxE3gTppb5"
      },
      "outputs": [],
      "source": [
        "# class TestCustomDataset(data.Dataset):\n",
        "#     def __init__(self):\n",
        "#         self.t_raw_images = t_imgs\n",
        "#         self.t_labels = t_lbls\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         test_image, test_image_labels  = self.t_raw_images[idx], self.t_labels[idx]\n",
        "#         return test_image, test_image_labels\n",
        "#     def __len__(self):\n",
        "#         return len(self.t_raw_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w29H2Hc4mJ3L"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b32sIZ0QmIuC"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset()\n",
        "test_dataset = TestCustomDataset()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMXZ_4ezmPzQ"
      },
      "outputs": [],
      "source": [
        "# train, test = torch.utils.data.random_split(train_dataset, [40000, 10000])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36twpWcZiuCO"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CWeBp_Gmy6g"
      },
      "outputs": [],
      "source": [
        "dataloaders = {'train': train_loader ,'test': test_loader}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9iC-sVmmsAx"
      },
      "outputs": [],
      "source": [
        "one_train_batch_imgs, one_train_batch_lbls, cls= next(iter(dataloaders['train']))\n",
        "print(one_train_batch_imgs, '\\n', one_train_batch_lbls, '\\n', cls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_Hr1uSky-dR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa3d411d-da83-4332-a648-fad41bdb9770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.4941, 0.4980, 0.4118,  ..., 0.2314, 0.2784, 0.2824],\n",
            "          [0.3216, 0.3882, 0.2980,  ..., 0.1373, 0.2275, 0.2902],\n",
            "          [0.1176, 0.1725, 0.2667,  ..., 0.1216, 0.1804, 0.2902],\n",
            "          ...,\n",
            "          [0.1490, 0.1020, 0.0549,  ..., 0.5882, 0.5255, 0.5020],\n",
            "          [0.2941, 0.1451, 0.0745,  ..., 0.5373, 0.5255, 0.4667],\n",
            "          [0.3255, 0.2471, 0.1098,  ..., 0.5529, 0.5255, 0.4706]],\n",
            "\n",
            "         [[0.4980, 0.5059, 0.3961,  ..., 0.2627, 0.3137, 0.3216],\n",
            "          [0.3255, 0.3843, 0.2706,  ..., 0.1608, 0.2588, 0.3294],\n",
            "          [0.1176, 0.1569, 0.2235,  ..., 0.1451, 0.2078, 0.3333],\n",
            "          ...,\n",
            "          [0.1647, 0.1255, 0.0941,  ..., 0.5255, 0.4510, 0.4196],\n",
            "          [0.2902, 0.1608, 0.1176,  ..., 0.4667, 0.4549, 0.3961],\n",
            "          [0.3020, 0.2549, 0.1529,  ..., 0.4784, 0.4627, 0.4157]],\n",
            "\n",
            "         [[0.5255, 0.5373, 0.4118,  ..., 0.2784, 0.3255, 0.3255],\n",
            "          [0.3490, 0.4078, 0.2745,  ..., 0.1882, 0.2824, 0.3294],\n",
            "          [0.1412, 0.1725, 0.2118,  ..., 0.1843, 0.2392, 0.3216],\n",
            "          ...,\n",
            "          [0.2431, 0.2431, 0.1765,  ..., 0.4588, 0.3922, 0.3647],\n",
            "          [0.3294, 0.2392, 0.2039,  ..., 0.4078, 0.4000, 0.3412],\n",
            "          [0.3176, 0.2941, 0.2392,  ..., 0.4314, 0.4118, 0.3647]]],\n",
            "\n",
            "\n",
            "        [[[0.9922, 0.9647, 0.9765,  ..., 0.9608, 0.9725, 0.8902],\n",
            "          [0.9804, 0.9569, 0.9686,  ..., 0.9412, 0.9529, 0.8824],\n",
            "          [0.9882, 0.9647, 0.9686,  ..., 0.9412, 0.9451, 0.8745],\n",
            "          ...,\n",
            "          [0.6706, 0.6118, 0.5843,  ..., 0.5255, 0.6039, 0.6235],\n",
            "          [0.6667, 0.6039, 0.5686,  ..., 0.5529, 0.5843, 0.6353],\n",
            "          [0.6392, 0.6157, 0.5922,  ..., 0.5373, 0.5765, 0.6431]],\n",
            "\n",
            "         [[0.9882, 0.9608, 0.9725,  ..., 0.9529, 0.9647, 0.8863],\n",
            "          [0.9765, 0.9529, 0.9647,  ..., 0.9451, 0.9529, 0.8824],\n",
            "          [0.9843, 0.9608, 0.9647,  ..., 0.9529, 0.9569, 0.8824],\n",
            "          ...,\n",
            "          [0.7333, 0.6824, 0.6392,  ..., 0.5451, 0.6588, 0.6745],\n",
            "          [0.7176, 0.6627, 0.6118,  ..., 0.5647, 0.6314, 0.6784],\n",
            "          [0.6667, 0.6510, 0.6118,  ..., 0.5451, 0.6196, 0.6824]],\n",
            "\n",
            "         [[1.0000, 0.9843, 0.9922,  ..., 0.9804, 1.0000, 0.9059],\n",
            "          [1.0000, 0.9765, 0.9882,  ..., 0.9686, 0.9882, 0.9020],\n",
            "          [1.0000, 0.9843, 0.9882,  ..., 0.9725, 0.9882, 0.9020],\n",
            "          ...,\n",
            "          [0.9255, 0.8784, 0.8196,  ..., 0.6824, 0.8157, 0.7882],\n",
            "          [0.8980, 0.8471, 0.7843,  ..., 0.6941, 0.7804, 0.7882],\n",
            "          [0.8314, 0.8196, 0.7647,  ..., 0.6706, 0.7647, 0.7843]]],\n",
            "\n",
            "\n",
            "        [[[0.0471, 0.0353, 0.0314,  ..., 0.0471, 0.1529, 0.0941],\n",
            "          [0.0471, 0.0235, 0.0314,  ..., 0.0941, 0.1412, 0.0980],\n",
            "          [0.0275, 0.0431, 0.0392,  ..., 0.1176, 0.1020, 0.0745],\n",
            "          ...,\n",
            "          [0.3059, 0.3725, 0.2314,  ..., 0.2588, 0.2667, 0.2353],\n",
            "          [0.2902, 0.3020, 0.2078,  ..., 0.2471, 0.2784, 0.2431],\n",
            "          [0.1765, 0.2745, 0.2588,  ..., 0.2510, 0.2706, 0.2824]],\n",
            "\n",
            "         [[0.1843, 0.1922, 0.1882,  ..., 0.1176, 0.3765, 0.1255],\n",
            "          [0.1765, 0.1412, 0.1333,  ..., 0.2902, 0.3451, 0.1647],\n",
            "          [0.1216, 0.2275, 0.1333,  ..., 0.3176, 0.2902, 0.2510],\n",
            "          ...,\n",
            "          [0.6392, 0.7020, 0.5765,  ..., 0.6157, 0.5608, 0.4980],\n",
            "          [0.6314, 0.7020, 0.6118,  ..., 0.6353, 0.5412, 0.5451],\n",
            "          [0.5569, 0.6980, 0.6471,  ..., 0.6392, 0.5961, 0.6627]],\n",
            "\n",
            "         [[0.0471, 0.0275, 0.0314,  ..., 0.0353, 0.1216, 0.0706],\n",
            "          [0.0275, 0.0235, 0.0353,  ..., 0.0588, 0.0824, 0.0667],\n",
            "          [0.0235, 0.0392, 0.0275,  ..., 0.0431, 0.0510, 0.0314],\n",
            "          ...,\n",
            "          [0.4275, 0.4549, 0.2471,  ..., 0.4196, 0.3373, 0.2118],\n",
            "          [0.3686, 0.2902, 0.2157,  ..., 0.2824, 0.2314, 0.2118],\n",
            "          [0.2157, 0.2275, 0.2314,  ..., 0.2275, 0.1725, 0.2431]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.0039, 0.0078, 0.0078,  ..., 0.2667, 0.2627, 0.2667],\n",
            "          [0.0000, 0.0039, 0.0078,  ..., 0.2784, 0.2745, 0.2941],\n",
            "          [0.0000, 0.0000, 0.0039,  ..., 0.3059, 0.3059, 0.3255],\n",
            "          ...,\n",
            "          [0.6275, 0.6510, 0.6863,  ..., 0.6353, 0.6275, 0.6431],\n",
            "          [0.6588, 0.6667, 0.6667,  ..., 0.6471, 0.6353, 0.6392],\n",
            "          [0.6745, 0.6510, 0.6471,  ..., 0.6275, 0.6196, 0.6235]],\n",
            "\n",
            "         [[0.1922, 0.1961, 0.2000,  ..., 0.4314, 0.4314, 0.4392],\n",
            "          [0.2039, 0.2039, 0.2118,  ..., 0.4353, 0.4353, 0.4588],\n",
            "          [0.2196, 0.2196, 0.2275,  ..., 0.4627, 0.4667, 0.4863],\n",
            "          ...,\n",
            "          [0.7529, 0.7608, 0.8000,  ..., 0.7608, 0.7529, 0.7686],\n",
            "          [0.7804, 0.7725, 0.7765,  ..., 0.7686, 0.7569, 0.7647],\n",
            "          [0.8118, 0.7686, 0.7725,  ..., 0.7608, 0.7529, 0.7569]],\n",
            "\n",
            "         [[0.3961, 0.4000, 0.4157,  ..., 0.6314, 0.6275, 0.6314],\n",
            "          [0.4196, 0.4353, 0.4471,  ..., 0.6392, 0.6353, 0.6510],\n",
            "          [0.4627, 0.4824, 0.4863,  ..., 0.6667, 0.6667, 0.6824],\n",
            "          ...,\n",
            "          [0.8235, 0.8157, 0.8510,  ..., 0.8353, 0.8275, 0.8510],\n",
            "          [0.8471, 0.8196, 0.8235,  ..., 0.8392, 0.8353, 0.8431],\n",
            "          [0.8784, 0.8196, 0.8196,  ..., 0.8353, 0.8353, 0.8431]]],\n",
            "\n",
            "\n",
            "        [[[0.0039, 0.0078, 0.0353,  ..., 0.0039, 0.0039, 0.0000],\n",
            "          [0.0039, 0.0039, 0.0118,  ..., 0.0118, 0.0078, 0.0000],\n",
            "          [0.0118, 0.0078, 0.0039,  ..., 0.0078, 0.0078, 0.0000],\n",
            "          ...,\n",
            "          [0.0196, 0.1686, 0.3176,  ..., 0.0118, 0.0118, 0.0118],\n",
            "          [0.0510, 0.2275, 0.3333,  ..., 0.0235, 0.0118, 0.0118],\n",
            "          [0.0784, 0.2706, 0.3804,  ..., 0.0275, 0.0118, 0.0118]],\n",
            "\n",
            "         [[0.0039, 0.0157, 0.0549,  ..., 0.0039, 0.0039, 0.0000],\n",
            "          [0.0039, 0.0157, 0.0235,  ..., 0.0118, 0.0078, 0.0000],\n",
            "          [0.0118, 0.0078, 0.0039,  ..., 0.0078, 0.0078, 0.0000],\n",
            "          ...,\n",
            "          [0.0196, 0.1647, 0.3255,  ..., 0.0118, 0.0118, 0.0118],\n",
            "          [0.0549, 0.2314, 0.3373,  ..., 0.0078, 0.0118, 0.0118],\n",
            "          [0.0824, 0.2784, 0.3843,  ..., 0.0039, 0.0118, 0.0118]],\n",
            "\n",
            "         [[0.0039, 0.0118, 0.0510,  ..., 0.0039, 0.0039, 0.0000],\n",
            "          [0.0039, 0.0118, 0.0196,  ..., 0.0118, 0.0078, 0.0000],\n",
            "          [0.0118, 0.0078, 0.0039,  ..., 0.0078, 0.0078, 0.0000],\n",
            "          ...,\n",
            "          [0.0157, 0.1294, 0.3020,  ..., 0.0118, 0.0118, 0.0118],\n",
            "          [0.0471, 0.2039, 0.3137,  ..., 0.0118, 0.0118, 0.0118],\n",
            "          [0.0627, 0.2392, 0.3451,  ..., 0.0118, 0.0118, 0.0118]]],\n",
            "\n",
            "\n",
            "        [[[0.1059, 0.1098, 0.1098,  ..., 0.1216, 0.1098, 0.1020],\n",
            "          [0.0941, 0.0941, 0.0980,  ..., 0.1333, 0.1216, 0.1176],\n",
            "          [0.1098, 0.1137, 0.1176,  ..., 0.1255, 0.1176, 0.1216],\n",
            "          ...,\n",
            "          [0.0588, 0.0588, 0.0588,  ..., 0.0353, 0.0353, 0.0392],\n",
            "          [0.0588, 0.0588, 0.0588,  ..., 0.0510, 0.0392, 0.0353],\n",
            "          [0.0588, 0.0588, 0.0588,  ..., 0.1373, 0.1412, 0.1098]],\n",
            "\n",
            "         [[0.3059, 0.3098, 0.3098,  ..., 0.3098, 0.2980, 0.2902],\n",
            "          [0.2941, 0.2941, 0.2980,  ..., 0.3216, 0.3098, 0.3059],\n",
            "          [0.2980, 0.3020, 0.3059,  ..., 0.3137, 0.3059, 0.3098],\n",
            "          ...,\n",
            "          [0.0588, 0.0588, 0.0588,  ..., 0.0667, 0.0667, 0.0667],\n",
            "          [0.0588, 0.0588, 0.0588,  ..., 0.0941, 0.0824, 0.0706],\n",
            "          [0.0588, 0.0588, 0.0588,  ..., 0.1882, 0.1922, 0.1529]],\n",
            "\n",
            "         [[0.5529, 0.5569, 0.5529,  ..., 0.5647, 0.5412, 0.5333],\n",
            "          [0.5333, 0.5333, 0.5373,  ..., 0.5725, 0.5529, 0.5490],\n",
            "          [0.5333, 0.5373, 0.5412,  ..., 0.5647, 0.5490, 0.5529],\n",
            "          ...,\n",
            "          [0.0588, 0.0588, 0.0588,  ..., 0.1176, 0.1216, 0.1255],\n",
            "          [0.0588, 0.0588, 0.0588,  ..., 0.1529, 0.1451, 0.1333],\n",
            "          [0.0510, 0.0510, 0.0510,  ..., 0.2588, 0.2667, 0.2275]]]]) \n",
            " tensor([3, 8, 4, 3, 0, 5, 7, 6, 1, 6, 8, 1, 1, 8, 8, 5, 5, 1, 9, 4, 0, 6, 5, 9,\n",
            "        5, 7, 6, 3, 2, 4, 4, 7, 6, 2, 0, 7, 6, 2, 5, 7, 1, 9, 9, 0, 3, 3, 5, 6,\n",
            "        1, 4, 2, 4, 5, 3, 3, 6, 2, 4, 0, 8, 2, 8, 5, 8]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "one_train_batch_imgs, one_train_batch_lbls= next(iter(dataloaders['train']))\n",
        "print(one_train_batch_imgs, '\\n', one_train_batch_lbls, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FVRbz3gGF7A"
      },
      "outputs": [],
      "source": [
        "for batch_number, (a, b, c) in enumerate(dataloaders['train']):\n",
        "    print(batch_number, a.shape, b.shape, c.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Mayji59zC2s",
        "outputId": "7e96639b-5a99-4582-f715-7610e6978e85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "1 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "2 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "3 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "4 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "5 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "6 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "7 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "8 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "9 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "10 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "11 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "12 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "13 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "14 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "15 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "16 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "17 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "18 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "19 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "20 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "21 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "22 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "23 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "24 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "25 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "26 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "27 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "28 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "29 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "30 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "31 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "32 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "33 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "34 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "35 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "36 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "37 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "38 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "39 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "40 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "41 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "42 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "43 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "44 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "45 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "46 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "47 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "48 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "49 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "50 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "51 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "52 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "53 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "54 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "55 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "56 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "57 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "58 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "59 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "60 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "61 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "62 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "63 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "64 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "65 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "66 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "67 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "68 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "69 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "70 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "71 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "72 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "73 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "74 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "75 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "76 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "77 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "78 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "79 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "80 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "81 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "82 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "83 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "84 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "85 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "86 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "87 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "88 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "89 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "90 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "91 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "92 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "93 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "94 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "95 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "96 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "97 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "98 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "99 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "100 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "101 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "102 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "103 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "104 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "105 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "106 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "107 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "108 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "109 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "110 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "111 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "112 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "113 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "114 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "115 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "116 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "117 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "118 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "119 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "120 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "121 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "122 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "123 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "124 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "125 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "126 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "127 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "128 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "129 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "130 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "131 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "132 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "133 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "134 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "135 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "136 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "137 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "138 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "139 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "140 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "141 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "142 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "143 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "144 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "145 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "146 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "147 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "148 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "149 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "150 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "151 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "152 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "153 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "154 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "155 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "156 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "157 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "158 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "159 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "160 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "161 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "162 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "163 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "164 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "165 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "166 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "167 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "168 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "169 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "170 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "171 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "172 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "173 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "174 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "175 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "176 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "177 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "178 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "179 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "180 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "181 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "182 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "183 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "184 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "185 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "186 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "187 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "188 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "189 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "190 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "191 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "192 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "193 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "194 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "195 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "196 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "197 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "198 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "199 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "200 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "201 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "202 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "203 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "204 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "205 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "206 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "207 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "208 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "209 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "210 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "211 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "212 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "213 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "214 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "215 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "216 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "217 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "218 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "219 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "220 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "221 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "222 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "223 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "224 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "225 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "226 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "227 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "228 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "229 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "230 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "231 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "232 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "233 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "234 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "235 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "236 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "237 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "238 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "239 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "240 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "241 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "242 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "243 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "244 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "245 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "246 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "247 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "248 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "249 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "250 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "251 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "252 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "253 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "254 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "255 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "256 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "257 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "258 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "259 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "260 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "261 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "262 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "263 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "264 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "265 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "266 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "267 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "268 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "269 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "270 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "271 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "272 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "273 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "274 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "275 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "276 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "277 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "278 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "279 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "280 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "281 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "282 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "283 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "284 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "285 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "286 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "287 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "288 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "289 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "290 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "291 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "292 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "293 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "294 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "295 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "296 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "297 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "298 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "299 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "300 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "301 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "302 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "303 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "304 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "305 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "306 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "307 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "308 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "309 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "310 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "311 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "312 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "313 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "314 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "315 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "316 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "317 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "318 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "319 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "320 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "321 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "322 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "323 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "324 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "325 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "326 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "327 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "328 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "329 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "330 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "331 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "332 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "333 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "334 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "335 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "336 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "337 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "338 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "339 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "340 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "341 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "342 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "343 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "344 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "345 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "346 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "347 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "348 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "349 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "350 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "351 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "352 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "353 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "354 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "355 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "356 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "357 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "358 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "359 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "360 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "361 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "362 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "363 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "364 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "365 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "366 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "367 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "368 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "369 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "370 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "371 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "372 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "373 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "374 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "375 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "376 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "377 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "378 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "379 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "380 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "381 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "382 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "383 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "384 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "385 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "386 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "387 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "388 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "389 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "390 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "391 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "392 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "393 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "394 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "395 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "396 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "397 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "398 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "399 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "400 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "401 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "402 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "403 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "404 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "405 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "406 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "407 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "408 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "409 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "410 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "411 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "412 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "413 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "414 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "415 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "416 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "417 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "418 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "419 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "420 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "421 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "422 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "423 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "424 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "425 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "426 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "427 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "428 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "429 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "430 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "431 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "432 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "433 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "434 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "435 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "436 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "437 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "438 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "439 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "440 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "441 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "442 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "443 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "444 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "445 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "446 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "447 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "448 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "449 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "450 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "451 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "452 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "453 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "454 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "455 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "456 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "457 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "458 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "459 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "460 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "461 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "462 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "463 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "464 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "465 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "466 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "467 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "468 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "469 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "470 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "471 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "472 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "473 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "474 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "475 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "476 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "477 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "478 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "479 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "480 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "481 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "482 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "483 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "484 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "485 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "486 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "487 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "488 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "489 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "490 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "491 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "492 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "493 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "494 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "495 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "496 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "497 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "498 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "499 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "500 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "501 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "502 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "503 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "504 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "505 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "506 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "507 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "508 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "509 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "510 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "511 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "512 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "513 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "514 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "515 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "516 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "517 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "518 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "519 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "520 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "521 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "522 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "523 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "524 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "525 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "526 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "527 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "528 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "529 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "530 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "531 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "532 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "533 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "534 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "535 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "536 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "537 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "538 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "539 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "540 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "541 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "542 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "543 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "544 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "545 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "546 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "547 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "548 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "549 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "550 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "551 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "552 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "553 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "554 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "555 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "556 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "557 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "558 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "559 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "560 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "561 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "562 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "563 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "564 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "565 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "566 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "567 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "568 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "569 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "570 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "571 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "572 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "573 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "574 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "575 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "576 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "577 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "578 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "579 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "580 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "581 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "582 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "583 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "584 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "585 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "586 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "587 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "588 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "589 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "590 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "591 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "592 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "593 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "594 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "595 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "596 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "597 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "598 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "599 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "600 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "601 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "602 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "603 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "604 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "605 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "606 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "607 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "608 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "609 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "610 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "611 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "612 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "613 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "614 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "615 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "616 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "617 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "618 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "619 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "620 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "621 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "622 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "623 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "624 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "625 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "626 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "627 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "628 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "629 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "630 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "631 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "632 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "633 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "634 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "635 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "636 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "637 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "638 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "639 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "640 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "641 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "642 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "643 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "644 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "645 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "646 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "647 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "648 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "649 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "650 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "651 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "652 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "653 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "654 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "655 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "656 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "657 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "658 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "659 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "660 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "661 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "662 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "663 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "664 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "665 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "666 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "667 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "668 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "669 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "670 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "671 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "672 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "673 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "674 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "675 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "676 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "677 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "678 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "679 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "680 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "681 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "682 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "683 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "684 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "685 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "686 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "687 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "688 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "689 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "690 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "691 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "692 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "693 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "694 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "695 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "696 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "697 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "698 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "699 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "700 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "701 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "702 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "703 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "704 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "705 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "706 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "707 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "708 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "709 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "710 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "711 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "712 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "713 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "714 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "715 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "716 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "717 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "718 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "719 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "720 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "721 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "722 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "723 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "724 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "725 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "726 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "727 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "728 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "729 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "730 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "731 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "732 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "733 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "734 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "735 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "736 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "737 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "738 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "739 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "740 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "741 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "742 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "743 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "744 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "745 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "746 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "747 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "748 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "749 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "750 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "751 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "752 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "753 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "754 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "755 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "756 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "757 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "758 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "759 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "760 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "761 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "762 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "763 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "764 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "765 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "766 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "767 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "768 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "769 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "770 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "771 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "772 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "773 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "774 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "775 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "776 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "777 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "778 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "779 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "780 torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
            "781 torch.Size([16, 3, 32, 32]) torch.Size([16])\n"
          ]
        }
      ],
      "source": [
        "for batch_number, (a, b) in enumerate(dataloaders['train']):\n",
        "    print(batch_number, a.shape, b.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk1TJ9-gm0TW"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmNQ5dWWm43E"
      },
      "outputs": [],
      "source": [
        "class ConvApprox(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
        "\n",
        "        super(ConvApprox, self).__init__() \n",
        "        self.weight = nn.Parameter(torch.Tensor(out_channels, in_channels, kernel_size, kernel_size))\n",
        "        self.bias = None\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = (kernel_size, kernel_size)\n",
        "        self.stride = stride\n",
        "        # unfold\n",
        "        self.unfold = nn.Unfold(kernel_size=(kernel_size, kernel_size), stride=stride)\n",
        "        self.reset_parameters()\n",
        "    \n",
        "    def reset_parameters(self):\n",
        "        n = self.in_channels\n",
        "        for k in self.kernel_size:\n",
        "            n *= k\n",
        "        stdv = 1. / math.sqrt(n)\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, images, clusters):\n",
        "\n",
        "        # Image input\n",
        "        img_unfold = self.unfold(images)\n",
        "        b, c, n = img_unfold.shape\n",
        "\n",
        "        # Clustered image input\n",
        "        clusterimg_unfold = self.unfold(clusters)\n",
        "\n",
        "        img_unfold = img_unfold.view(b, 3, 9, n)\n",
        "        num_batch, _, num_windows = clusterimg_unfold.size()\n",
        "\n",
        "        # Mean \n",
        "        avg_unfold = torch.mean(img_unfold, dim=2).to(device)\n",
        "\n",
        "        variance = clusterimg_unfold.var(dim=1, keepdim=True)\n",
        "        same_ids = variance == 0\n",
        "\n",
        "        same_data = []\n",
        "        diff_data = []\n",
        "\n",
        "        output = torch.zeros((num_batch, 1, self.out_channels, num_windows)).to(device)\n",
        "\n",
        "        w = self.weight.view(self.out_channels, self.in_channels, -1).to(device)\n",
        "\n",
        "        for i, s in enumerate(same_ids):\n",
        "            # Same\n",
        "            sames = clusterimg_unfold[i, 0, s[0]]\n",
        "            # Diff\n",
        "            diffs = clusterimg_unfold[i, :, torch.logical_not(s[0])].t().flatten()\n",
        "            #\n",
        "            same_data = torch.matmul(torch.sum(w, dim=-1), avg_unfold[i, :, s[0]]).to(device)\n",
        "            diff_data = torch.matmul((w).sum(-1) , avg_unfold[i, : ,torch.logical_not(s[0])]).to(device)\n",
        "            # \n",
        "            output[i, 0, :, s[0]] += same_data\n",
        "            output[i, 0, :, torch.logical_not(s[0])] += diff_data.clone()\n",
        "\n",
        "        #Fold \n",
        "        fold = nn.Fold(output_size=(int(np.sqrt(num_windows)), int(np.sqrt(num_windows))), kernel_size=(1, 1))\n",
        "        output = fold(output.squeeze(1)).to(device)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVAd3RIdLFbN"
      },
      "outputs": [],
      "source": [
        "# class Convnet(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Convnet, self).__init__()\n",
        "#         self.base = models.resnet101(pretrained= True).to(device)\n",
        "  \n",
        "     \n",
        "#     def forward(self, x):\n",
        "#         y = self.base(x)\n",
        "\n",
        "#         return y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Convnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Convnet, self).__init__()\n",
        "        # self.base = models.vgg16(pretrained= True).to(device)\n",
        "        base = models.vgg16(pretrained= True).to(device)\n",
        "        # layers = list(base.children())\n",
        "        # self.l0 = ConvApprox(3, 64, 3, 1)\n",
        "        self.l1 = nn.Sequential(*[base.features[i] for i in range(0, 30)])\n",
        "        self.l2 = nn.Sequential(*[base.avgpool])\n",
        "        self.l3 = nn.Linear(25088, 64, bias=False).to(device)\n",
        "        self.l4 = nn.Linear(in_features=64, out_features=10, bias=False).to(device)\n",
        "        \n",
        "     \n",
        "    def forward(self, x):\n",
        "        y = self.l1(x)\n",
        "        y = self.l2(y)\n",
        "        y = y.view(y.size(0), -1)\n",
        "        y = self.l3(y)\n",
        "        y = self.l4(y)\n",
        " \n",
        "        return y"
      ],
      "metadata": {
        "id": "0idhb_OYZZSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class Convnet(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Convnet, self).__init__()\n",
        "#         # self.base = models.resnet101(pretrained= True).to(device)\n",
        "#         base = models.resnet50(pretrained= True).to(device)\n",
        "#         layers = list(base.children())\n",
        "#         # self.l0 = ConvApprox(3, 64, 3, 1)\n",
        "#         self.l1 = nn.Sequential(*layers[0:-1])\n",
        "#         self.l2 = nn.Linear(2048, 64, bias=False).to(device)\n",
        "#         self.l3 = nn.Linear(in_features=64, out_features=10, bias=False).to(device)\n",
        "        \n",
        "     \n",
        "#     def forward(self,x):\n",
        "#         y = self.l1(x)\n",
        "#         y = y.view(y.size(0), -1)\n",
        "#         y = self.l2(y)\n",
        "#         y = self.l3(y)\n",
        "\n",
        "#         return y"
      ],
      "metadata": {
        "id": "5eii2P31fYQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9chhwd0mB9ZR"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XqP2wMBCCCd",
        "outputId": "f9af025c-a16c-43f5-84a2-45b1ed859263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Convnet(\n",
              "  (l1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "  )\n",
              "  (l2): Sequential(\n",
              "    (0): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  )\n",
              "  (l3): Linear(in_features=25088, out_features=64, bias=False)\n",
              "  (l4): Linear(in_features=64, out_features=10, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "model = Convnet()\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvUdpTUdKIHv",
        "outputId": "abe937cc-74e8-46ee-8755-2a09042e8de2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.l1[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWKzL7RoAgCK"
      },
      "outputs": [],
      "source": [
        "base = models.resnet50(pretrained= True).to(device)\n",
        "layers = list(base.children())\n",
        "# layers[0][0]\n",
        "base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcfYWT33JKZw"
      },
      "outputs": [],
      "source": [
        "# base.features[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhwv-W3k5Svh",
        "outputId": "ce21bae4-6079-4fc7-b392-e30042df5d0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Convnet(\n",
              "  (l1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "  )\n",
              "  (l2): Sequential(\n",
              "    (0): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  )\n",
              "  (l3): Linear(in_features=25088, out_features=64, bias=False)\n",
              "  (l4): Linear(in_features=64, out_features=10, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "model = Convnet().to(device)\n",
        "model\n",
        "# torchsummary.summary(model, (3, 32, 32),(1, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61a836IshAK3"
      },
      "outputs": [],
      "source": [
        "imgs, lbls = next(iter(dataloaders['train']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwnAIVycARCI"
      },
      "outputs": [],
      "source": [
        "imgs, lbls= next(iter(dataloaders['test']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scdyN4Qcn72h",
        "outputId": "fea38447-bef8-4917-9930-e7aa2eb0621f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.8430e-01,  1.0322e-01,  1.1524e-01,  7.6123e-02, -4.9111e-02,\n",
              "          4.7501e-01, -2.0542e-01, -1.6312e-03,  3.1625e-01,  1.5889e-01],\n",
              "        [-3.9420e-02,  1.3095e-01,  1.1438e-01, -1.3994e-01,  2.7578e-01,\n",
              "         -1.9204e-01,  1.6807e-01, -7.6512e-02,  1.3753e-01, -2.0022e-01],\n",
              "        [ 2.4122e-01,  1.2064e-02,  5.5164e-01,  1.6900e-01, -2.7141e-01,\n",
              "          2.3368e-01,  1.6035e-01, -2.8291e-02,  3.1390e-01, -3.4117e-02],\n",
              "        [ 1.1104e-02, -1.1950e-01,  8.0807e-02, -1.0937e-02, -5.3778e-02,\n",
              "          1.0329e-01,  1.6419e-02, -4.2420e-03,  3.4136e-01, -6.2061e-03],\n",
              "        [ 1.2037e-01, -9.5196e-02,  2.1311e-01,  2.0422e-01,  3.4598e-02,\n",
              "          1.7099e-01, -1.0383e-01,  7.6558e-02,  9.7153e-02, -9.5707e-02],\n",
              "        [ 1.3231e-01, -3.1673e-02,  2.2487e-01,  2.4805e-03, -1.2538e-01,\n",
              "          3.4209e-01, -3.0412e-01,  6.6811e-03,  3.1670e-01, -1.5172e-01],\n",
              "        [ 8.9200e-03,  3.8776e-02,  1.7576e-01, -3.0295e-03, -3.2036e-04,\n",
              "          7.5876e-02,  8.9094e-02, -3.7655e-02,  2.4840e-01, -4.3348e-02],\n",
              "        [ 8.7801e-02, -1.8567e-01,  1.7389e-01, -8.5668e-03,  2.0363e-02,\n",
              "          1.1689e-01,  2.6224e-01, -4.2615e-02,  1.8299e-01, -5.7608e-02],\n",
              "        [-2.3053e-01, -9.5019e-02,  2.3100e-01, -2.4032e-02, -7.5393e-02,\n",
              "          1.6447e-01, -4.6888e-02,  1.1383e-01,  1.1589e-01, -1.9975e-01],\n",
              "        [ 1.6272e-01, -1.2927e-01,  1.5127e-01, -1.8259e-01, -1.9388e-01,\n",
              "          2.1520e-01, -2.0645e-01,  1.0551e-02,  3.7318e-01, -1.9962e-01],\n",
              "        [-9.9708e-02, -1.6618e-02,  1.8055e-01, -2.8592e-01,  1.6945e-01,\n",
              "         -3.6821e-01, -5.5317e-03, -1.3717e-01, -1.4489e-01, -1.1553e-02],\n",
              "        [ 7.4795e-02, -8.4673e-02,  1.5493e-01, -6.2574e-02,  1.1424e-01,\n",
              "          1.9458e-01, -1.6809e-02,  2.2988e-03,  1.9941e-01, -6.4575e-02],\n",
              "        [-2.0092e-02, -1.3410e-02,  2.8139e-01, -1.1623e-01,  8.7526e-02,\n",
              "         -6.6158e-03, -7.0944e-02,  3.3803e-01, -1.4737e-01,  2.5651e-02],\n",
              "        [ 8.2755e-02, -5.2071e-02,  4.3104e-01,  1.1982e-01,  1.6290e-01,\n",
              "          3.5206e-01,  1.8798e-01,  8.4710e-02,  3.5865e-01, -1.2297e-01],\n",
              "        [ 2.0439e-01, -5.7156e-03,  2.8119e-01,  3.6655e-02, -2.5351e-01,\n",
              "          2.7579e-01,  6.3088e-02, -2.4102e-02,  2.4193e-01,  2.0780e-01],\n",
              "        [ 1.2368e-01, -5.6545e-04, -1.8186e-01, -1.7605e-01,  3.4013e-01,\n",
              "          2.2334e-01,  6.2879e-02, -3.9217e-02,  4.6707e-01,  7.4103e-02],\n",
              "        [-1.1648e-02, -1.4978e-01,  3.1151e-01,  2.3687e-02, -1.4515e-01,\n",
              "          1.2483e-01, -3.0953e-02, -7.3559e-02,  3.7128e-01,  9.7718e-02],\n",
              "        [ 1.9614e-01,  5.5615e-02,  3.6482e-01,  1.2102e-02,  2.2383e-02,\n",
              "          3.1808e-01,  1.8558e-01, -1.2385e-01,  2.6714e-01, -5.2467e-02],\n",
              "        [-1.0999e-01,  2.2411e-01, -6.1839e-02, -5.0420e-02,  3.9753e-02,\n",
              "          2.5643e-02,  8.3407e-02,  2.6403e-01, -3.0554e-01, -1.3171e-01],\n",
              "        [ 6.5957e-02,  4.4130e-03, -1.0590e-01, -1.0948e-01, -1.0879e-02,\n",
              "          3.3986e-01, -2.9031e-01,  7.8238e-02,  3.4219e-01,  1.5795e-02],\n",
              "        [ 4.5737e-02, -1.3138e-01,  9.7318e-02,  6.3319e-02,  3.1921e-03,\n",
              "          4.3100e-02, -7.4834e-02,  1.1377e-01,  1.2884e-01,  4.7349e-02],\n",
              "        [-2.9297e-02, -1.8576e-02,  1.0521e-01, -7.7595e-02,  1.3819e-01,\n",
              "          4.1439e-02, -5.0390e-02,  4.0428e-02,  6.5336e-02, -5.8875e-02],\n",
              "        [-1.0791e-01, -1.0837e-01,  1.5981e-01, -1.4718e-01,  1.4466e-01,\n",
              "          2.6797e-01,  1.6283e-01, -1.0145e-01,  3.3698e-01,  9.5396e-02],\n",
              "        [-2.7334e-02,  1.7375e-02,  8.0147e-02,  6.6947e-02,  6.1375e-02,\n",
              "          3.5316e-01,  8.7032e-02, -1.8328e-01, -9.7082e-02, -9.2760e-02],\n",
              "        [-1.4764e-01, -1.8955e-01,  8.4157e-02, -2.5411e-01, -2.8744e-02,\n",
              "          2.6064e-01, -2.9004e-02, -5.8032e-03,  2.4706e-01,  2.2348e-02],\n",
              "        [ 2.0501e-01,  1.4833e-01,  2.2574e-01, -1.6171e-01, -1.1890e-01,\n",
              "          2.1148e-01,  1.3177e-01, -1.1388e-02,  2.2825e-02,  5.1340e-02],\n",
              "        [ 6.3765e-03,  1.1663e-01, -1.0525e-01, -9.3159e-02, -1.4689e-02,\n",
              "          2.9020e-01, -1.5581e-01, -3.4702e-02,  2.4717e-01, -4.0076e-02],\n",
              "        [ 4.7110e-02,  1.4707e-01,  6.8221e-02,  1.3740e-01,  1.0679e-01,\n",
              "          6.8411e-02,  9.4696e-02,  5.8942e-02,  1.7519e-01,  1.8501e-01],\n",
              "        [ 8.2313e-03,  1.1173e-01,  6.8148e-02,  1.6496e-01, -4.0395e-02,\n",
              "         -5.9546e-02,  1.5524e-01, -2.3618e-02,  6.0831e-02,  1.1156e-01],\n",
              "        [ 4.0285e-02,  3.4020e-01,  1.1825e-02,  2.4229e-02,  8.3675e-02,\n",
              "          2.9477e-02,  1.8822e-02,  1.0221e-01,  8.8755e-02, -1.9283e-01],\n",
              "        [-1.5097e-01, -9.8882e-02,  4.7419e-01,  8.9622e-02, -1.0502e-03,\n",
              "          2.1061e-02,  3.1068e-01, -1.1303e-02,  4.2076e-01,  1.0313e-01],\n",
              "        [ 1.8134e-01, -1.9389e-01,  2.7755e-01, -2.1258e-01,  1.7931e-01,\n",
              "          3.7097e-01,  1.0634e-01,  8.2561e-03,  1.8950e-01, -7.9065e-02],\n",
              "        [-8.1102e-02, -2.1311e-02,  1.1698e-02, -9.4718e-02, -1.6306e-01,\n",
              "         -1.6119e-01, -1.7585e-01,  2.2544e-01, -6.3022e-02,  3.1088e-01],\n",
              "        [-3.7189e-02, -6.0687e-02,  1.0513e-01,  6.2638e-02, -1.5389e-01,\n",
              "          1.5847e-01, -5.1510e-02,  3.9066e-02,  3.5355e-01,  1.3888e-01],\n",
              "        [ 1.1902e-01,  2.0598e-02,  3.5479e-02, -1.7172e-01,  1.0401e-01,\n",
              "          1.5308e-01,  7.7642e-02, -1.5083e-01,  1.7285e-01, -1.5980e-02],\n",
              "        [ 2.1132e-01,  1.9990e-02,  1.8193e-01, -2.3460e-01, -1.0377e-02,\n",
              "          3.1915e-01, -1.3710e-01, -4.7937e-02,  3.3488e-02, -1.1610e-01],\n",
              "        [ 3.0535e-02, -1.7415e-01,  1.2506e-02,  2.3613e-02, -5.7425e-02,\n",
              "          1.7380e-01,  1.5731e-02,  3.5921e-02,  2.9339e-01,  1.0585e-01],\n",
              "        [-1.6507e-01, -1.4796e-02, -3.3994e-03, -1.5093e-01,  1.2412e-01,\n",
              "         -1.0308e-01,  3.5884e-02,  1.2010e-03,  3.5721e-02, -3.2581e-02],\n",
              "        [ 5.1753e-02, -1.0225e-01,  9.0738e-02, -2.7009e-02,  7.0935e-02,\n",
              "          1.7699e-01, -1.8613e-01,  1.4580e-01,  3.1151e-01, -1.2374e-01],\n",
              "        [-2.9780e-02, -4.2999e-02,  3.1239e-01,  8.3250e-02, -1.7383e-01,\n",
              "         -1.8533e-01,  6.9504e-02,  2.5759e-01,  1.4936e-02, -8.2168e-02],\n",
              "        [ 1.5599e-01,  9.9791e-02,  9.3282e-03, -1.3469e-01, -5.7661e-02,\n",
              "          1.2599e-01, -6.8358e-02,  2.7987e-01,  4.0107e-02,  3.1520e-01],\n",
              "        [-1.1572e-01,  7.9926e-02, -5.8553e-02, -1.3046e-01,  1.5343e-01,\n",
              "          1.1397e-01,  1.5786e-01, -7.3367e-02,  4.0745e-02, -9.1281e-02],\n",
              "        [ 1.8060e-02, -1.0399e-01,  1.1755e-01, -1.2231e-01,  9.8952e-02,\n",
              "          1.6841e-01,  2.0072e-01, -1.0891e-01,  2.3017e-01,  1.4358e-02],\n",
              "        [ 2.1162e-01, -4.9465e-02,  4.7504e-01,  8.5540e-02, -1.1302e-02,\n",
              "          3.7680e-01,  6.2364e-02,  5.6911e-02,  4.8227e-01, -1.2944e-01],\n",
              "        [-4.8654e-02, -1.6007e-01,  4.7807e-01,  1.3310e-01,  4.8546e-02,\n",
              "          1.2874e-01,  2.7434e-01, -7.3309e-02,  5.3091e-01,  2.7020e-03],\n",
              "        [-1.5325e-01,  1.1403e-01, -1.3647e-02,  5.1352e-02,  6.5213e-04,\n",
              "         -5.5388e-02,  2.3371e-01,  2.5690e-01,  7.7759e-02,  2.0921e-01],\n",
              "        [ 2.1045e-01,  3.4009e-02,  9.7502e-02,  8.2521e-02, -2.0152e-01,\n",
              "          5.8124e-01,  1.2306e-01,  1.5197e-02,  1.5355e-01,  1.3512e-01],\n",
              "        [-1.6822e-01, -1.3047e-01,  1.1540e-01, -1.0580e-01,  2.2644e-01,\n",
              "         -1.5715e-01,  2.1868e-01,  8.1431e-02,  2.9851e-01,  5.9999e-03],\n",
              "        [-1.7436e-01,  2.9343e-02,  2.1628e-01, -2.8423e-02,  1.6417e-01,\n",
              "         -2.8220e-02, -1.0819e-01,  3.8112e-02,  2.5314e-01, -7.0871e-03],\n",
              "        [-4.5785e-02, -2.0188e-02,  2.1265e-02, -8.0167e-02, -8.1550e-02,\n",
              "          1.0673e-01,  2.4855e-01, -7.0980e-02,  3.8326e-02, -8.9916e-02],\n",
              "        [ 6.9878e-02, -2.0354e-02,  3.6873e-01,  8.2681e-02, -1.4731e-01,\n",
              "          7.1302e-02, -1.4987e-02,  2.2226e-01, -3.2408e-02, -1.4864e-01],\n",
              "        [ 4.9517e-03, -1.7015e-01,  1.4632e-01,  5.1564e-02,  1.6802e-01,\n",
              "          1.8804e-01,  8.3968e-02, -1.2167e-01,  4.1696e-01,  5.0966e-02],\n",
              "        [-2.3060e-01, -1.9494e-01, -4.7845e-02, -4.9231e-01,  2.6703e-01,\n",
              "          1.0488e-01,  4.1641e-01, -2.8137e-01,  4.0325e-01,  1.8201e-01],\n",
              "        [ 2.3307e-01, -6.1017e-02,  1.3540e-01, -1.1517e-01,  1.4994e-01,\n",
              "          4.9594e-02,  2.2118e-02,  1.0439e-01,  1.1237e-01, -7.3479e-02],\n",
              "        [ 7.0221e-02, -6.0099e-02,  2.3469e-01, -8.9031e-02, -4.2427e-02,\n",
              "         -3.5378e-04,  3.0291e-02,  5.4727e-02,  2.0229e-01,  3.8087e-02],\n",
              "        [-6.0336e-02,  1.0146e-01,  8.0786e-02, -2.3800e-02, -1.0538e-01,\n",
              "          3.4464e-01, -1.1220e-01, -4.7804e-02,  2.2533e-01, -4.6134e-02],\n",
              "        [-7.8557e-02, -6.1079e-02,  1.0797e-02, -1.0310e-01,  1.0999e-01,\n",
              "         -2.2772e-03,  1.5535e-01, -7.2869e-02,  1.3200e-01, -7.5133e-02],\n",
              "        [-2.3318e-01,  1.6096e-01, -1.1292e-02,  1.5108e-01,  7.0241e-02,\n",
              "         -1.4220e-01,  1.5343e-01, -7.0562e-02, -7.7070e-02,  5.1890e-03],\n",
              "        [ 1.6895e-01,  1.7359e-02,  1.4697e-01,  9.7980e-03, -4.6239e-02,\n",
              "          3.9180e-01, -1.2769e-01, -1.1305e-02,  1.3422e-01, -8.1936e-02],\n",
              "        [-3.5837e-01, -1.5691e-01,  1.8393e-01,  1.3314e-01,  3.8546e-01,\n",
              "         -3.7349e-01,  3.7122e-01,  4.1959e-01, -1.4561e-01, -1.9302e-01],\n",
              "        [-4.4546e-02, -8.0698e-02,  5.7106e-01,  1.1828e-01, -4.4734e-02,\n",
              "         -6.0027e-02,  3.6529e-01,  1.0267e-01,  2.8305e-01,  5.3641e-02],\n",
              "        [-1.3956e-02, -1.5577e-02,  2.5654e-01, -3.1120e-01,  4.0315e-01,\n",
              "          1.8038e-01,  3.2190e-01, -2.6437e-01,  3.5382e-01,  1.7815e-01],\n",
              "        [-1.0760e-01, -1.8471e-01,  4.5079e-02,  3.5658e-02,  1.2546e-01,\n",
              "          5.3646e-02,  1.6814e-01, -3.6401e-02,  3.1414e-01,  1.1157e-01],\n",
              "        [-4.9265e-02,  5.6972e-02,  1.3222e-01, -9.0667e-02,  2.6632e-01,\n",
              "         -4.2142e-02,  2.8429e-01,  8.8289e-02,  3.2320e-02,  6.3785e-02]],\n",
              "       device='cuda:0', grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "model(imgs.cuda()).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q45MLvYv3AHs"
      },
      "outputs": [],
      "source": [
        "# torchsummary.summary(model,((3, 32, 32), 1, 32, 32) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbvaDfsh5_Tx",
        "outputId": "d57f3e38-efaf-4c15-9190-7b91e4e5260e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 32, 32])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = next(iter(dataloaders['train']))\n",
        "a[0].shape\n",
        "# model(a[0].cuda()).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxWiEIsSGdjo"
      },
      "source": [
        "# Prune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVf38opIehNh"
      },
      "outputs": [],
      "source": [
        "def prune_model_global_unstructured(model, layer_type, proportion):\n",
        "    module_tups = []\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, layer_type):\n",
        "            module_tups.append((module, 'weight'))\n",
        "\n",
        "    prune.global_unstructured(\n",
        "        parameters=module_tups, pruning_method=prune.L1Unstructured,\n",
        "        amount=proportion\n",
        "    )\n",
        "    for module, _ in module_tups:\n",
        "        prune.remove(module, 'weight')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4NZFhqo-3ZU"
      },
      "outputs": [],
      "source": [
        "# model = Convnet().to(device)\n",
        "model = prune_model_global_unstructured(model, nn.Conv2d , 0.3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqkWZCUmOaBQ"
      },
      "outputs": [],
      "source": [
        "# model = prune_model_global_unstructured(model, nn.BatchNorm2d , 0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEap4r84Gf6q",
        "outputId": "ec0806c8-f92b-484d-db2d-650f38363def"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvApprox(\n",
              "  (unfold): Unfold(kernel_size=(3, 3), dilation=1, padding=0, stride=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# pruning convapprox\n",
        "parameters_to_prune = (\n",
        "    (model.l0, 'weight'),   \n",
        ")\n",
        "\n",
        "model_prune = prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.9,\n",
        ")\n",
        "prune.remove(model.l0, 'weight')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy89A2A9GhiT",
        "outputId": "837f2880-066d-4978-baab-c0cac54a770b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=25088, out_features=64, bias=False)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "# pruning fully-connected layer1\n",
        "parameters_to_prune = (\n",
        "    (model.l3, 'weight'),   \n",
        ")\n",
        "\n",
        "model_prune = prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.3,\n",
        ")\n",
        "prune.remove(model.l3, 'weight')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVy45c_9Ghr_",
        "outputId": "9ee552a2-79bf-4fdf-a028-8d66a8eb80f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=64, out_features=10, bias=False)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "# pruning fully-connected layer2\n",
        "parameters_to_prune = (\n",
        "    (model.l4, 'weight'),   \n",
        ")\n",
        "\n",
        "model_prune = prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.3,\n",
        ")\n",
        "prune.remove(model.l4, 'weight')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQHI3wqGGuKu"
      },
      "source": [
        "# Save pruned and compress Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cs235etsGq8j"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"resnet101_CIFAR-80.pt\")\n",
        "!gzip -qf /content/resnet101_CIFAR-80.pt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fib5BrL147a6"
      },
      "outputs": [],
      "source": [
        "save_name = 'VGG16_SVHN_90.pt'\n",
        "path = F\"/content/drive/MyDrive/Colab Notebooks/SVHN/{save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvHcrY8yG1q9"
      },
      "source": [
        "# Sparsity of all Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2rSGmaWuEyA",
        "outputId": "250bb0dd-f696-4d43-aea8-98926ae1d329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sparsity in l0.weight: 89.99%\n",
            "Sparsity in l2.weight: 90.00%\n",
            "Global sparsity: 90.00%\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    \"Sparsity in l0.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.l0.weight == 0))\n",
        "        / float(model.l0.weight.nelement())\n",
        "    )\n",
        ")\n",
        "# print(\n",
        "#     \"Sparsity in l1.weight: {:.2f}%\".format(\n",
        "#         100. * float(torch.sum(model.l1.weight == 0))\n",
        "#         / float(model.l1.weight.nelement())\n",
        "#     )\n",
        "# )\n",
        "print(\n",
        "    \"Sparsity in l2.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.l2.weight == 0))\n",
        "        / float(model.l2.weight.nelement())\n",
        "    )\n",
        ")\n",
        "# print(\n",
        "#     \"Sparsity in l3.weight: {:.2f}%\".format(\n",
        "#         100. * float(torch.sum(model.l3.weight == 0))\n",
        "#         / float(model.l3.weight.nelement())\n",
        "#     )\n",
        "# )\n",
        "print(\n",
        "    \"Global sparsity: {:.2f}%\".format(\n",
        "        100. * float(\n",
        "            torch.sum(model.l0.weight == 0)\n",
        "            # + torch.sum(model.l1.weight == 0)\n",
        "            + torch.sum(model.l2.weight == 0)\n",
        "            # + torch.sum(model.l3.weight == 0)\n",
        "        )\n",
        "        / float(\n",
        "            model.l0.weight.nelement()\n",
        "            # + model.l1.weight.nelement()\n",
        "            + model.l2.weight.nelement()\n",
        "            # + model.l3.weight.nelement()\n",
        "\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuEkdLVItGz2",
        "outputId": "9ad554da-7ddd-4426-fbda-35bbc8b64552"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Linear(in_features=64, out_features=10, bias=False)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model = Convnet()\n",
        "\n",
        "# parameters_to_prune = (\n",
        "#     (model.l0, 'weight'),\n",
        "#     (model.l1[1], 'weight'),\n",
        "#     (model.l1[4], 'weight'),\n",
        "#     (model.l1[9], 'weight'),\n",
        "#     (model.l1[11], 'weight'),\n",
        "#     (model.l1[13], 'weight'),\n",
        "#     (model.l1[16], 'weight'),\n",
        "#     (model.l1[18], 'weight'),\n",
        "#     (model.l1[20], 'weight'),\n",
        "#     (model.l1[23], 'weight'),\n",
        "#     (model.l1[25], 'weight'),\n",
        "#     (model.l1[27], 'weight'),\n",
        "#     (model.l3, 'weight'),\n",
        "#     (model.l4, 'weight'),\n",
        "# )\n",
        "\n",
        "# prune.global_unstructured(\n",
        "#     parameters_to_prune,\n",
        "#     pruning_method=prune.L1Unstructured,\n",
        "#     amount=0.4,\n",
        "# )\n",
        "# prune.remove(model.l0, 'weight')\n",
        "# prune.remove(model.l1[1], 'weight')\n",
        "# prune.remove(model.l1[4], 'weight')\n",
        "# prune.remove(model.l1[9], 'weight')\n",
        "# prune.remove(model.l1[11], 'weight')\n",
        "# prune.remove(model.l1[13], 'weight')\n",
        "# prune.remove(model.l1[16], 'weight')\n",
        "# prune.remove(model.l1[18], 'weight')\n",
        "# prune.remove(model.l1[20], 'weight')\n",
        "# prune.remove(model.l1[23], 'weight')\n",
        "# prune.remove(model.l1[25], 'weight')\n",
        "# prune.remove(model.l1[27], 'weight')\n",
        "# prune.remove(model.l3, 'weight')\n",
        "# prune.remove(model.l4, 'weight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPMTRmbo_KmG"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgrdADal_KL0"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDTyhYri_ve_"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFSId-SZ_vQ4"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs):#, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    # if is_inception and phase == 'train':\n",
        "                    #     # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                    #     outputs, aux_outputs = model(inputs)\n",
        "                    #     loss1 = criterion(outputs, labels)\n",
        "                    #     loss2 = criterion(aux_outputs, labels)\n",
        "                    #     loss = loss1 + 0.4*loss2\n",
        "                    # else:\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'test':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best test Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8nDAJE4h7r8"
      },
      "source": [
        "\n",
        "\n",
        "resnet50-CIFAR-30% pruning (conv2d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsOV9wlmAUpY",
        "outputId": "50a7d5d2-56ea-492c-9c52-f1bae6fcc7bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.8026 Acc: 0.7271\n",
            "test Loss: 0.5796 Acc: 0.8054\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.4305 Acc: 0.8547\n",
            "test Loss: 0.4636 Acc: 0.8461\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.2965 Acc: 0.9023\n",
            "test Loss: 0.4177 Acc: 0.8613\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.2107 Acc: 0.9295\n",
            "test Loss: 0.4438 Acc: 0.8585\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.1622 Acc: 0.9455\n",
            "test Loss: 0.4692 Acc: 0.8669\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.1212 Acc: 0.9595\n",
            "test Loss: 0.4775 Acc: 0.8682\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.0929 Acc: 0.9681\n",
            "test Loss: 0.5194 Acc: 0.8674\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.0827 Acc: 0.9721\n",
            "test Loss: 0.4896 Acc: 0.8763\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.0725 Acc: 0.9759\n",
            "test Loss: 0.5000 Acc: 0.8731\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.0538 Acc: 0.9818\n",
            "test Loss: 0.5934 Acc: 0.8621\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.0538 Acc: 0.9828\n",
            "test Loss: 0.5180 Acc: 0.8764\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.0416 Acc: 0.9866\n",
            "test Loss: 0.6039 Acc: 0.8642\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.0380 Acc: 0.9875\n",
            "test Loss: 0.5112 Acc: 0.8801\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.0344 Acc: 0.9888\n",
            "test Loss: 0.5287 Acc: 0.8763\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.0259 Acc: 0.9915\n",
            "test Loss: 0.5551 Acc: 0.8863\n",
            "\n",
            "Training complete in 8m 29s\n",
            "Best test Acc: 0.886300\n"
          ]
        }
      ],
      "source": [
        "model_ft, hist = train_model(model, dataloaders, criterion, optimizer, num_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVDMYnK9BBkW"
      },
      "source": [
        "# Model Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM_VMBV-A0oK",
        "outputId": "31f568db-50f3-493e-d5eb-9c8bed9260d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model's state_dict:\n",
            "l0.weight \t torch.Size([64, 3, 3, 3])\n",
            "l1.1.bias \t torch.Size([64])\n",
            "l1.1.weight \t torch.Size([64, 64, 3, 3])\n",
            "l1.4.bias \t torch.Size([128])\n",
            "l1.4.weight \t torch.Size([128, 64, 3, 3])\n",
            "l1.6.bias \t torch.Size([128])\n",
            "l1.6.weight \t torch.Size([128, 128, 3, 3])\n",
            "l1.9.bias \t torch.Size([256])\n",
            "l1.9.weight \t torch.Size([256, 128, 3, 3])\n",
            "l1.11.bias \t torch.Size([256])\n",
            "l1.11.weight \t torch.Size([256, 256, 3, 3])\n",
            "l1.13.bias \t torch.Size([256])\n",
            "l1.13.weight \t torch.Size([256, 256, 3, 3])\n",
            "l1.16.bias \t torch.Size([512])\n",
            "l1.16.weight \t torch.Size([512, 256, 3, 3])\n",
            "l1.18.bias \t torch.Size([512])\n",
            "l1.18.weight \t torch.Size([512, 512, 3, 3])\n",
            "l1.20.bias \t torch.Size([512])\n",
            "l1.20.weight \t torch.Size([512, 512, 3, 3])\n",
            "l1.23.bias \t torch.Size([512])\n",
            "l1.23.weight \t torch.Size([512, 512, 3, 3])\n",
            "l1.25.bias \t torch.Size([512])\n",
            "l1.25.weight \t torch.Size([512, 512, 3, 3])\n",
            "l1.27.bias \t torch.Size([512])\n",
            "l1.27.weight \t torch.Size([512, 512, 3, 3])\n",
            "l3.weight \t torch.Size([64, 25088])\n",
            "l4.weight \t torch.Size([10, 64])\n",
            "Optimizer's state_dict:\n",
            "state \t {0: {'momentum_buffer': tensor([[[[-4.2349e-05, -4.2349e-05, -4.2349e-05],\n",
            "          [-4.2349e-05, -4.2349e-05, -4.2349e-05],\n",
            "          [-4.2349e-05, -4.2349e-05, -4.2349e-05]],\n",
            "\n",
            "         [[-2.2540e-06, -2.2540e-06, -2.2540e-06],\n",
            "          [-2.2540e-06, -2.2540e-06, -2.2540e-06],\n",
            "          [-2.2540e-06, -2.2540e-06, -2.2540e-06]],\n",
            "\n",
            "         [[-1.9075e-06, -1.9075e-06, -1.9075e-06],\n",
            "          [-1.9075e-06, -1.9075e-06, -1.9075e-06],\n",
            "          [-1.9075e-06, -1.9075e-06, -1.9075e-06]]],\n",
            "\n",
            "\n",
            "        [[[-1.8117e-02, -1.8117e-02, -1.8117e-02],\n",
            "          [-1.8117e-02, -1.8117e-02, -1.8117e-02],\n",
            "          [-1.8117e-02, -1.8117e-02, -1.8117e-02]],\n",
            "\n",
            "         [[-1.0760e-02, -1.0760e-02, -1.0760e-02],\n",
            "          [-1.0760e-02, -1.0760e-02, -1.0760e-02],\n",
            "          [-1.0760e-02, -1.0760e-02, -1.0760e-02]],\n",
            "\n",
            "         [[-4.0889e-02, -4.0889e-02, -4.0889e-02],\n",
            "          [-4.0889e-02, -4.0889e-02, -4.0889e-02],\n",
            "          [-4.0889e-02, -4.0889e-02, -4.0889e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5225e-02,  1.5225e-02,  1.5225e-02],\n",
            "          [ 1.5225e-02,  1.5225e-02,  1.5225e-02],\n",
            "          [ 1.5225e-02,  1.5225e-02,  1.5225e-02]],\n",
            "\n",
            "         [[ 2.7907e-02,  2.7907e-02,  2.7907e-02],\n",
            "          [ 2.7907e-02,  2.7907e-02,  2.7907e-02],\n",
            "          [ 2.7907e-02,  2.7907e-02,  2.7907e-02]],\n",
            "\n",
            "         [[ 2.3602e-02,  2.3602e-02,  2.3602e-02],\n",
            "          [ 2.3602e-02,  2.3602e-02,  2.3602e-02],\n",
            "          [ 2.3602e-02,  2.3602e-02,  2.3602e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-5.1781e-04, -5.1781e-04, -5.1781e-04],\n",
            "          [-5.1781e-04, -5.1781e-04, -5.1781e-04],\n",
            "          [-5.1781e-04, -5.1781e-04, -5.1781e-04]],\n",
            "\n",
            "         [[-6.8180e-04, -6.8180e-04, -6.8180e-04],\n",
            "          [-6.8180e-04, -6.8180e-04, -6.8180e-04],\n",
            "          [-6.8180e-04, -6.8180e-04, -6.8180e-04]],\n",
            "\n",
            "         [[-8.2862e-04, -8.2862e-04, -8.2862e-04],\n",
            "          [-8.2862e-04, -8.2862e-04, -8.2862e-04],\n",
            "          [-8.2862e-04, -8.2862e-04, -8.2862e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 5.2295e-06,  5.2295e-06,  5.2295e-06],\n",
            "          [ 5.2295e-06,  5.2295e-06,  5.2295e-06],\n",
            "          [ 5.2295e-06,  5.2295e-06,  5.2295e-06]],\n",
            "\n",
            "         [[ 4.4854e-05,  4.4854e-05,  4.4854e-05],\n",
            "          [ 4.4854e-05,  4.4854e-05,  4.4854e-05],\n",
            "          [ 4.4854e-05,  4.4854e-05,  4.4854e-05]],\n",
            "\n",
            "         [[ 9.1876e-05,  9.1876e-05,  9.1876e-05],\n",
            "          [ 9.1876e-05,  9.1876e-05,  9.1876e-05],\n",
            "          [ 9.1876e-05,  9.1876e-05,  9.1876e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 5.1775e-02,  5.1775e-02,  5.1775e-02],\n",
            "          [ 5.1775e-02,  5.1775e-02,  5.1775e-02],\n",
            "          [ 5.1775e-02,  5.1775e-02,  5.1775e-02]],\n",
            "\n",
            "         [[ 4.9602e-02,  4.9602e-02,  4.9602e-02],\n",
            "          [ 4.9602e-02,  4.9602e-02,  4.9602e-02],\n",
            "          [ 4.9602e-02,  4.9602e-02,  4.9602e-02]],\n",
            "\n",
            "         [[ 4.9369e-02,  4.9369e-02,  4.9369e-02],\n",
            "          [ 4.9369e-02,  4.9369e-02,  4.9369e-02],\n",
            "          [ 4.9369e-02,  4.9369e-02,  4.9369e-02]]]], device='cuda:0')}, 1: {'momentum_buffer': tensor([ 5.4465e-04, -4.1693e-06, -3.4941e-03, -5.2267e-03, -2.8107e-02,\n",
            "         3.8578e-02,  2.5816e-03, -1.0889e-02,  1.9686e-02,  2.6500e-02,\n",
            "         2.2371e-03,  4.4911e-02,  3.5194e-02, -2.6876e-04,  1.7297e-02,\n",
            "         4.6778e-03, -2.9052e-03, -6.6530e-03,  2.1767e-02,  4.0436e-02,\n",
            "        -1.6156e-02, -9.9022e-03,  4.2729e-02,  4.6297e-03,  2.3023e-02,\n",
            "        -2.0466e-11, -1.4736e-02, -1.8928e-03, -7.3079e-03,  3.1350e-03,\n",
            "        -1.9131e-03,  6.2734e-03,  3.3334e-02,  2.9102e-03, -3.5838e-02,\n",
            "         1.1637e-02,  2.7848e-03,  7.0941e-06, -2.8521e-02,  1.4321e-03,\n",
            "        -4.2665e-02,  8.2449e-02, -1.4378e-02, -2.1581e-03, -4.2366e-03,\n",
            "         5.8760e-02,  1.7088e-03, -4.4291e-03,  1.5413e-02,  4.1294e-05,\n",
            "        -9.0543e-03,  2.2359e-04,  6.0309e-03,  8.8085e-03, -3.0607e-03,\n",
            "         1.8638e-02, -1.6156e-02, -4.5132e-02, -1.5478e-02, -1.9681e-03,\n",
            "        -2.6676e-02, -2.0766e-05,  5.5754e-02,  8.8132e-02], device='cuda:0')}, 2: {'momentum_buffer': tensor([[[[ 1.2479e-30,  2.7057e-25, -7.1054e-34],\n",
            "          [ 1.2487e-30,  1.2031e-25, -2.8865e-34],\n",
            "          [ 5.7725e-34,  7.6618e-33, -1.2532e-28]],\n",
            "\n",
            "         [[ 2.8897e-04,  2.3165e-04,  4.3128e-05],\n",
            "          [ 3.2132e-04,  2.6749e-04,  4.9024e-05],\n",
            "          [ 4.8879e-05,  2.1209e-05,  1.9519e-06]],\n",
            "\n",
            "         [[ 4.0003e-04,  3.5829e-04,  5.8981e-05],\n",
            "          [ 4.5361e-04,  4.1167e-04,  6.4147e-05],\n",
            "          [-1.2083e-05, -3.0427e-05,  2.5166e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.7836e-06, -5.4227e-06,  3.9429e-10],\n",
            "          [-7.4548e-06, -7.2525e-06,  1.4464e-11],\n",
            "          [-6.6918e-06, -6.2886e-06, -5.8130e-08]],\n",
            "\n",
            "         [[-6.2549e-08, -3.9275e-08,  5.2872e-17],\n",
            "          [-1.9069e-08,  7.1989e-10,  1.3919e-13],\n",
            "          [-1.4445e-08,  9.4990e-09, -7.9311e-14]],\n",
            "\n",
            "         [[ 8.8512e-05,  9.1204e-05,  7.2934e-06],\n",
            "          [ 1.0168e-04,  1.0417e-04,  7.5393e-06],\n",
            "          [-3.0444e-05, -2.6531e-05,  8.9980e-08]]],\n",
            "\n",
            "\n",
            "        [[[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
            "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
            "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
            "\n",
            "         [[-3.9980e-08, -3.3738e-08, -7.9752e-15],\n",
            "          [-1.3355e-07, -1.3929e-07, -1.4158e-14],\n",
            "          [-2.4738e-07, -2.5979e-07, -9.9419e-15]],\n",
            "\n",
            "         [[-6.4359e-06, -6.4623e-06, -2.6931e-07],\n",
            "          [-6.6796e-06, -6.7062e-06, -2.6988e-07],\n",
            "          [-6.9593e-06, -6.9811e-06, -2.7015e-07]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3367e-06, -1.3598e-06, -7.4865e-08],\n",
            "          [-1.2492e-06, -1.2758e-06, -7.5130e-08],\n",
            "          [-1.1065e-06, -1.1286e-06, -7.6438e-08]],\n",
            "\n",
            "         [[-8.4694e-09, -7.7631e-09, -6.6742e-09],\n",
            "          [-5.5099e-09, -5.7829e-09, -5.9122e-09],\n",
            "          [-2.9427e-09, -4.8449e-09, -5.1181e-09]],\n",
            "\n",
            "         [[-4.0680e-06, -4.0930e-06, -1.9387e-07],\n",
            "          [-4.1465e-06, -4.1688e-06, -1.9364e-07],\n",
            "          [-4.2217e-06, -4.2379e-06, -1.9391e-07]]],\n",
            "\n",
            "\n",
            "        [[[-9.1525e-07, -1.1447e-06, -9.7534e-07],\n",
            "          [-2.1595e-07, -3.9647e-07, -4.9014e-07],\n",
            "          [-8.5204e-08, -5.5920e-07, -6.7646e-07]],\n",
            "\n",
            "         [[ 1.8263e-02,  1.7038e-02,  2.2535e-02],\n",
            "          [ 1.2226e-02,  1.3685e-02,  2.3118e-02],\n",
            "          [ 8.3688e-03,  1.1063e-02,  2.4891e-02]],\n",
            "\n",
            "         [[ 2.5696e-02,  2.8349e-02,  5.1787e-02],\n",
            "          [ 1.4788e-02,  2.4105e-02,  5.3545e-02],\n",
            "          [ 5.7314e-03,  2.0547e-02,  5.7204e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4206e-04, -1.6216e-04, -1.3367e-04],\n",
            "          [-1.3466e-04, -9.7665e-05, -5.6311e-05],\n",
            "          [-2.0518e-04, -1.4586e-04, -8.3047e-05]],\n",
            "\n",
            "         [[-1.8695e-06, -2.6029e-06, -2.2928e-06],\n",
            "          [-3.0405e-06, -2.3382e-06, -2.3673e-06],\n",
            "          [-1.7113e-06, -1.6570e-06, -1.4709e-06]],\n",
            "\n",
            "         [[ 6.0522e-03,  6.8674e-03,  1.6355e-02],\n",
            "          [ 2.7207e-03,  5.8572e-03,  1.7036e-02],\n",
            "          [ 1.2750e-03,  7.0217e-03,  2.0534e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
            "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
            "          [-5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
            "\n",
            "         [[ 3.5141e-13, -4.1682e-13, -2.0289e-13],\n",
            "          [-6.6618e-14, -1.7680e-06, -1.7907e-06],\n",
            "          [-6.0475e-15, -1.8307e-06, -1.8499e-06]],\n",
            "\n",
            "         [[-2.1892e-12,  8.0338e-12, -4.0992e-12],\n",
            "          [ 4.2977e-09, -3.6572e-05, -3.6557e-05],\n",
            "          [ 4.2566e-09, -3.6828e-05, -3.6816e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.0965e-13,  3.1641e-13, -1.1717e-13],\n",
            "          [ 4.6304e-10, -1.0994e-06, -1.0883e-06],\n",
            "          [ 4.7645e-10, -1.0014e-06, -9.8936e-07]],\n",
            "\n",
            "         [[ 4.2416e-17, -5.2006e-16, -5.8405e-16],\n",
            "          [-1.3723e-12,  1.4422e-11,  3.7653e-10],\n",
            "          [-1.3902e-12, -9.0730e-10, -1.0160e-09]],\n",
            "\n",
            "         [[-1.7404e-12, -5.4325e-12, -4.2324e-12],\n",
            "          [ 3.2739e-09, -2.0385e-05, -2.0360e-05],\n",
            "          [ 3.2775e-09, -2.0472e-05, -2.0453e-05]]],\n",
            "\n",
            "\n",
            "        [[[-4.6350e-07, -6.9065e-07, -7.1569e-07],\n",
            "          [-2.3293e-07, -3.4956e-07, -4.3863e-07],\n",
            "          [-2.3503e-07, -2.9633e-07, -3.4578e-07]],\n",
            "\n",
            "         [[ 2.2274e-02,  2.2806e-02,  2.3596e-02],\n",
            "          [ 1.9188e-02,  2.1174e-02,  2.1537e-02],\n",
            "          [ 2.1063e-02,  2.4432e-02,  2.5358e-02]],\n",
            "\n",
            "         [[ 3.6030e-02,  3.7774e-02,  4.2731e-02],\n",
            "          [ 3.4641e-02,  3.8768e-02,  4.3046e-02],\n",
            "          [ 4.2443e-02,  4.9692e-02,  5.4779e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.7663e-05, -6.9001e-05, -3.5932e-05],\n",
            "          [-4.8370e-05, -5.0866e-05, -2.8660e-05],\n",
            "          [-6.8083e-05, -5.7986e-05, -1.1692e-05]],\n",
            "\n",
            "         [[ 7.4759e-07,  2.5980e-07,  2.9001e-07],\n",
            "          [ 4.1844e-07,  6.2978e-07,  8.0922e-07],\n",
            "          [ 1.5006e-06,  6.5655e-07,  4.6409e-07]],\n",
            "\n",
            "         [[ 1.0642e-02,  1.0756e-02,  1.2679e-02],\n",
            "          [ 1.0853e-02,  1.1757e-02,  1.3624e-02],\n",
            "          [ 1.4074e-02,  1.6128e-02,  1.8307e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.8560e-07,  7.7232e-07,  6.8726e-07],\n",
            "          [ 3.2261e-07,  3.6093e-07,  4.9656e-07],\n",
            "          [ 3.2728e-07,  4.2008e-07,  7.1527e-07]],\n",
            "\n",
            "         [[ 3.7314e-02,  2.4328e-02,  1.6510e-02],\n",
            "          [ 4.0261e-02,  2.7848e-02,  2.0088e-02],\n",
            "          [ 3.3059e-02,  2.4217e-02,  1.7463e-02]],\n",
            "\n",
            "         [[ 5.9154e-02,  3.1636e-02,  6.9242e-03],\n",
            "          [ 5.7767e-02,  2.9306e-02,  7.9929e-03],\n",
            "          [ 4.7218e-02,  2.1783e-02,  2.4199e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5594e-04, -1.6665e-04, -2.0125e-04],\n",
            "          [-1.2412e-04, -6.8717e-05, -1.1423e-04],\n",
            "          [-5.2830e-05, -1.7869e-05, -6.9756e-05]],\n",
            "\n",
            "         [[-1.0472e-06, -8.4886e-07,  6.8241e-07],\n",
            "          [-8.5149e-07, -1.6540e-06,  1.4158e-06],\n",
            "          [-2.1203e-06, -1.0447e-06,  1.1704e-06]],\n",
            "\n",
            "         [[ 8.3702e-03,  2.6337e-03, -3.4131e-03],\n",
            "          [ 6.7053e-03,  8.3153e-04, -4.1875e-03],\n",
            "          [ 5.5331e-03, -1.8634e-03, -6.9847e-03]]]], device='cuda:0')}, 3: {'momentum_buffer': tensor([ 4.2077e-03,  1.2005e-02, -1.3176e-02,  3.9541e-03,  1.3445e-02,\n",
            "        -2.8025e-03, -4.6033e-03,  1.7655e-02,  1.8052e-03, -3.7887e-03,\n",
            "         2.0696e-02, -1.3347e-02,  3.1346e-03, -2.1207e-04, -7.6891e-03,\n",
            "        -8.7652e-03, -7.5697e-03,  7.8561e-03, -1.6213e-02, -6.2881e-03,\n",
            "         1.3456e-03,  7.0465e-03, -2.6883e-02, -1.6790e-02, -2.5592e-02,\n",
            "        -2.9561e-03, -1.6304e-02, -1.0490e-02,  3.9079e-05, -8.2202e-03,\n",
            "        -1.2028e-03,  1.9451e-02,  4.5747e-03,  3.2537e-03, -4.7283e-03,\n",
            "         1.8268e-02,  2.4388e-03, -2.4595e-02, -3.9039e-03, -1.3909e-02,\n",
            "         4.9514e-03, -1.1175e-02,  3.0626e-04, -2.0486e-02, -1.3362e-02,\n",
            "        -7.0699e-03, -5.3812e-04, -1.5644e-04,  3.3146e-03, -9.4211e-03,\n",
            "        -1.3401e-02, -5.6743e-03, -1.0306e-02,  2.6549e-02,  5.0774e-04,\n",
            "         1.5049e-02,  9.2409e-03, -4.0078e-03,  8.7418e-03,  1.6744e-02,\n",
            "        -1.1087e-02, -9.7085e-03,  1.0889e-02, -1.0792e-02, -1.9528e-03,\n",
            "        -4.1011e-03, -2.8790e-03, -3.1147e-03, -5.3860e-03, -2.1954e-04,\n",
            "        -8.9552e-03,  2.7858e-03,  6.5411e-04,  3.0070e-03, -8.6163e-03,\n",
            "         3.8705e-03,  3.7985e-03, -1.3324e-02, -1.3389e-02,  1.7489e-03,\n",
            "        -7.3202e-04, -9.1203e-03,  1.7265e-02,  1.4509e-02,  8.3773e-04,\n",
            "         3.3413e-03,  4.3812e-03, -2.1384e-02, -5.2132e-03, -4.4532e-03,\n",
            "        -5.5671e-03, -9.5956e-03, -5.9125e-03,  1.9393e-02, -1.1901e-02,\n",
            "         9.2448e-04, -5.3428e-03, -2.1709e-02, -2.3651e-02,  6.1978e-03,\n",
            "         9.8944e-03,  1.3177e-03,  9.7031e-06, -5.1899e-04, -8.6897e-03,\n",
            "         6.6798e-03, -1.6876e-03, -1.8163e-02,  2.3646e-02, -1.8322e-03,\n",
            "        -1.9146e-02, -4.7233e-03, -1.5612e-03,  3.3090e-03,  6.5259e-03,\n",
            "        -2.5956e-03, -8.2956e-03,  1.1195e-02,  4.7386e-03, -1.0372e-02,\n",
            "         6.0570e-03,  1.7348e-02,  9.3843e-03, -1.2739e-03,  1.5694e-02,\n",
            "        -2.6895e-02, -5.0941e-02, -1.7557e-02], device='cuda:0')}, 4: {'momentum_buffer': tensor([[[[-2.7752e-11,  4.2050e-07,  2.2642e-07],\n",
            "          [-3.6312e-12,  9.0820e-06,  1.3255e-06],\n",
            "          [-9.3965e-09, -2.2355e-05, -3.6700e-05]],\n",
            "\n",
            "         [[ 3.1318e-10, -2.1525e-07,  2.5490e-08],\n",
            "          [ 1.0107e-09,  5.9822e-08,  3.5456e-08],\n",
            "          [-1.4641e-10,  5.7883e-08,  5.7510e-09]],\n",
            "\n",
            "         [[ 6.7379e-03,  5.0679e-03,  1.2629e-03],\n",
            "          [-6.1645e-03, -5.7732e-03, -5.8810e-03],\n",
            "          [-5.7470e-03, -2.4105e-03, -2.2150e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0911e-13,  4.8551e-08, -7.9996e-12],\n",
            "          [ 4.3642e-08,  2.2729e-07,  3.8615e-12],\n",
            "          [-1.4391e-13, -1.6145e-13, -6.0171e-15]],\n",
            "\n",
            "         [[-1.3489e-03, -1.5396e-03, -1.8067e-03],\n",
            "          [-5.8078e-03, -5.1416e-03, -6.0950e-03],\n",
            "          [-2.7092e-03, -1.0535e-03, -1.6903e-03]],\n",
            "\n",
            "         [[ 2.8083e-03, -8.7701e-04, -3.1669e-03],\n",
            "          [-4.2799e-03, -1.2328e-02, -1.2703e-02],\n",
            "          [-1.0388e-02, -1.7000e-02, -6.8490e-03]]],\n",
            "\n",
            "\n",
            "        [[[-8.2539e-07, -3.0060e-06,  1.8571e-06],\n",
            "          [-1.4421e-06, -9.1971e-07, -9.1599e-07],\n",
            "          [ 2.8465e-06,  5.0813e-07, -1.8798e-05]],\n",
            "\n",
            "         [[-1.1376e-09, -2.6502e-09, -6.1396e-08],\n",
            "          [-3.0345e-10,  4.2739e-10,  2.2399e-08],\n",
            "          [-8.9251e-11, -1.2327e-10,  1.9133e-08]],\n",
            "\n",
            "         [[ 3.6764e-03,  3.7857e-03,  4.1489e-03],\n",
            "          [ 7.2719e-03,  8.9411e-03,  1.2376e-02],\n",
            "          [ 5.4385e-03,  6.2371e-03,  8.3590e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.9416e-14, -1.3520e-07, -9.1553e-14],\n",
            "          [-1.1793e-09, -6.5322e-08, -2.5559e-12],\n",
            "          [ 9.1242e-14, -6.7071e-14, -7.6555e-14]],\n",
            "\n",
            "         [[-2.1109e-03, -2.5823e-03, -4.0203e-03],\n",
            "          [ 3.8625e-04, -1.8735e-04, -7.9489e-04],\n",
            "          [-2.2442e-03, -3.7332e-03, -4.1561e-03]],\n",
            "\n",
            "         [[ 1.6083e-02,  6.1163e-03,  1.3179e-02],\n",
            "          [ 1.4505e-02,  7.2585e-03,  1.5648e-02],\n",
            "          [ 1.1240e-02,  5.3665e-03,  1.6790e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5881e-07,  1.4412e-06, -1.5808e-07],\n",
            "          [ 6.5728e-06, -8.0261e-06, -1.4937e-06],\n",
            "          [ 1.1507e-07, -2.0366e-05, -1.4299e-05]],\n",
            "\n",
            "         [[ 1.7383e-14, -5.0146e-09,  1.2298e-09],\n",
            "          [-4.7228e-13,  1.7210e-08, -1.8818e-07],\n",
            "          [-8.1832e-10,  4.4863e-09, -1.0038e-07]],\n",
            "\n",
            "         [[-4.7652e-02, -4.5141e-02, -3.6177e-02],\n",
            "          [-1.9285e-02, -8.6080e-03, -6.3410e-03],\n",
            "          [-1.7221e-02, -1.0476e-02, -4.1915e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.9117e-13,  6.6665e-11, -5.9055e-14],\n",
            "          [-9.8614e-07, -9.4851e-08, -2.6524e-11],\n",
            "          [-2.0738e-15,  3.8640e-14,  6.9497e-14]],\n",
            "\n",
            "         [[-1.8703e-02, -1.8788e-02, -1.4304e-02],\n",
            "          [-1.9531e-02, -1.2084e-02, -7.1321e-03],\n",
            "          [-1.2961e-02, -6.4848e-03,  1.4869e-03]],\n",
            "\n",
            "         [[-4.0170e-02, -1.5309e-02, -2.6187e-02],\n",
            "          [-2.0169e-02, -2.5698e-03, -2.2523e-02],\n",
            "          [ 1.8369e-03, -1.3838e-03, -2.7624e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.9072e-06, -8.8021e-07,  4.1788e-07],\n",
            "          [-1.5697e-06, -1.9036e-06,  4.5358e-05],\n",
            "          [-4.2604e-07, -1.3437e-07, -4.7335e-05]],\n",
            "\n",
            "         [[-1.3414e-09,  3.8404e-09,  1.6412e-07],\n",
            "          [-2.5059e-09,  6.4477e-10,  1.2356e-07],\n",
            "          [ 6.4333e-11, -7.9786e-11,  3.9301e-08]],\n",
            "\n",
            "         [[-1.3561e-02, -1.6620e-02, -1.4833e-02],\n",
            "          [-4.1058e-02, -4.4214e-02, -4.5359e-02],\n",
            "          [-1.8240e-02, -2.0555e-02, -2.1114e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.0492e-09, -1.3427e-08, -8.4504e-11],\n",
            "          [ 5.8708e-15,  1.5404e-07, -1.1036e-12],\n",
            "          [-3.4720e-14, -2.3276e-13,  2.3883e-14]],\n",
            "\n",
            "         [[-5.0481e-03, -6.1653e-04,  4.7140e-04],\n",
            "          [-1.7638e-02, -1.5531e-02, -1.7651e-02],\n",
            "          [-4.3986e-03, -3.1357e-03, -8.7814e-03]],\n",
            "\n",
            "         [[ 4.1211e-04, -1.6825e-02, -3.7344e-03],\n",
            "          [-1.5852e-02, -4.2022e-02, -1.3412e-02],\n",
            "          [-1.9965e-02, -4.5817e-02, -1.0087e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.8678e-07,  3.8571e-06,  2.4088e-06],\n",
            "          [-2.7715e-06, -1.5389e-05,  8.5812e-06],\n",
            "          [-8.7510e-08,  5.0799e-06,  5.3096e-05]],\n",
            "\n",
            "         [[ 7.3029e-09,  4.3359e-09,  3.0677e-07],\n",
            "          [ 1.4020e-09,  1.0619e-08, -2.0848e-08],\n",
            "          [-2.3746e-10,  5.7542e-09, -1.0126e-08]],\n",
            "\n",
            "         [[-3.4120e-02, -4.1148e-02, -4.4266e-02],\n",
            "          [-5.7860e-02, -5.5540e-02, -5.4832e-02],\n",
            "          [-3.0487e-02, -2.4168e-02, -2.0670e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.6869e-07,  5.7249e-11,  9.7057e-11],\n",
            "          [ 1.5283e-06, -3.0580e-07, -7.9904e-12],\n",
            "          [-3.8264e-13,  2.6002e-14,  2.3201e-14]],\n",
            "\n",
            "         [[-3.5491e-03, -5.5598e-03, -1.9975e-03],\n",
            "          [-1.6311e-02, -1.2468e-02, -3.2680e-03],\n",
            "          [ 1.0273e-03,  1.6577e-03,  7.9647e-03]],\n",
            "\n",
            "         [[-3.8364e-02, -2.0008e-02, -2.9754e-02],\n",
            "          [-4.2826e-02, -3.4787e-02, -4.5092e-02],\n",
            "          [-2.9800e-02, -2.3261e-02, -2.3886e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9891e-08, -1.3812e-06, -2.2059e-06],\n",
            "          [-1.9071e-06,  9.2557e-07,  2.0405e-07],\n",
            "          [-7.3841e-06, -1.1930e-05, -1.8680e-07]],\n",
            "\n",
            "         [[ 2.4866e-14, -5.6790e-15,  3.6956e-14],\n",
            "          [ 2.1333e-14, -1.8109e-14,  1.7775e-15],\n",
            "          [ 2.4745e-12, -1.0430e-14,  1.1972e-14]],\n",
            "\n",
            "         [[-8.2801e-03, -4.0292e-03, -4.1532e-03],\n",
            "          [-2.1939e-02, -2.6937e-02, -1.6645e-02],\n",
            "          [-4.1061e-02, -3.8606e-02, -2.0865e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0478e-13, -3.7422e-15,  7.0634e-14],\n",
            "          [-7.2656e-15,  8.7547e-15, -3.5684e-15],\n",
            "          [-2.1194e-13,  8.2006e-15, -1.2993e-15]],\n",
            "\n",
            "         [[-1.1383e-03, -2.5111e-03, -4.0030e-03],\n",
            "          [-7.7077e-03, -6.8149e-03, -4.3427e-03],\n",
            "          [-1.5602e-02, -9.8294e-03, -2.1816e-03]],\n",
            "\n",
            "         [[-4.7919e-03, -1.9394e-02, -1.9065e-02],\n",
            "          [-2.7296e-04, -2.4644e-02, -3.4106e-02],\n",
            "          [-7.1133e-03, -2.6220e-02, -2.8826e-02]]]], device='cuda:0')}, 5: {'momentum_buffer': tensor([ 1.3186e-02,  1.5062e-03, -4.3125e-03, -6.0740e-03, -3.2231e-03,\n",
            "        -2.3379e-03, -5.1671e-03,  8.5969e-03,  1.4215e-02, -4.4886e-03,\n",
            "         1.2761e-02, -6.5505e-03,  7.3536e-03,  6.2855e-03, -5.5035e-03,\n",
            "        -1.3110e-02,  6.1543e-03,  1.9663e-05, -8.2121e-03, -6.8083e-04,\n",
            "         1.1982e-02, -1.1669e-02, -4.1140e-03,  7.1808e-03, -2.8800e-03,\n",
            "        -1.3565e-04, -8.7418e-04, -2.1814e-03,  7.9782e-03, -8.6418e-04,\n",
            "         1.1383e-03, -5.8765e-03, -4.7257e-03, -4.1698e-03,  6.7416e-04,\n",
            "        -1.5953e-02,  1.5101e-03, -3.7413e-05, -2.5247e-03, -1.8155e-03,\n",
            "        -8.9058e-03,  7.8202e-03,  1.1919e-03, -3.5618e-03,  1.3517e-02,\n",
            "        -6.9443e-05,  6.6645e-03,  1.8079e-03, -1.3097e-02, -1.4606e-03,\n",
            "        -1.4364e-02,  3.0030e-02,  2.9994e-04, -1.3937e-03, -3.3356e-03,\n",
            "         2.8044e-03,  1.4654e-02,  7.6617e-03, -7.4133e-03, -1.5851e-02,\n",
            "        -4.7691e-03,  8.1205e-04,  7.6094e-03,  5.1343e-03,  3.5742e-03,\n",
            "        -2.3318e-03, -4.8807e-03, -2.8190e-03,  4.1870e-03, -1.8789e-02,\n",
            "         2.0365e-02,  1.6590e-03,  8.4788e-03, -2.8211e-03,  3.1490e-03,\n",
            "        -9.9309e-03,  2.5822e-03,  5.5514e-03, -1.6570e-03,  1.1669e-02,\n",
            "         1.2475e-03, -3.4599e-03, -4.7562e-05, -2.2498e-02,  1.5682e-02,\n",
            "        -8.4207e-03,  2.6090e-03, -5.1312e-03, -6.3309e-03,  3.1810e-03,\n",
            "        -1.0113e-03, -4.6273e-03, -7.6322e-03,  4.8915e-03, -9.4969e-03,\n",
            "         1.2591e-02,  7.5420e-03, -5.4035e-03,  3.6358e-03, -2.6424e-03,\n",
            "         4.9172e-03,  1.7612e-03,  3.7781e-03,  7.3408e-03, -2.7167e-03,\n",
            "         3.3781e-03, -6.5655e-03,  4.2507e-03,  4.0724e-04,  1.0322e-02,\n",
            "         2.5760e-03,  1.3649e-03,  1.0440e-03, -4.7885e-03,  2.1998e-02,\n",
            "        -1.1618e-02, -7.8402e-03,  1.0905e-02,  3.0547e-03, -6.0278e-04,\n",
            "         2.7436e-03, -7.9387e-03,  2.3952e-03, -4.6777e-03, -5.2723e-03,\n",
            "         9.4937e-04, -4.6578e-03,  7.5504e-05], device='cuda:0')}, 6: {'momentum_buffer': tensor([[[[ 7.0032e-03, -7.9026e-05,  7.7820e-03],\n",
            "          [ 2.3982e-03, -3.5175e-04,  1.2418e-02],\n",
            "          [ 5.1075e-03,  2.5993e-03,  1.3929e-02]],\n",
            "\n",
            "         [[-2.5643e-03,  2.4655e-04, -2.7310e-04],\n",
            "          [ 1.9445e-03,  7.8715e-03,  6.1583e-03],\n",
            "          [ 6.0061e-03,  3.3429e-03, -1.3924e-05]],\n",
            "\n",
            "         [[ 1.0535e-02,  1.1054e-03,  5.7969e-03],\n",
            "          [ 4.1913e-03,  4.6448e-03,  6.8479e-03],\n",
            "          [ 1.3954e-02,  1.0799e-02,  1.8026e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.4443e-03,  4.8014e-03,  4.8581e-03],\n",
            "          [ 2.4945e-03,  4.7345e-03,  6.1530e-03],\n",
            "          [ 9.8138e-03,  1.7255e-02,  5.6763e-03]],\n",
            "\n",
            "         [[ 7.9268e-03,  1.8135e-02,  1.5803e-02],\n",
            "          [ 1.7507e-02,  2.2837e-02,  1.5245e-02],\n",
            "          [ 1.4296e-02,  1.2133e-02,  6.6811e-03]],\n",
            "\n",
            "         [[-2.6525e-03, -7.8493e-04,  4.1027e-03],\n",
            "          [ 4.9145e-03,  5.3298e-04, -1.8195e-03],\n",
            "          [-6.9812e-04,  1.7765e-03, -1.2985e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0201e-03,  1.1532e-03,  1.0976e-03],\n",
            "          [ 4.5971e-04, -2.1344e-03, -8.1553e-04],\n",
            "          [ 1.7930e-03, -2.2078e-03, -1.0330e-03]],\n",
            "\n",
            "         [[ 1.7089e-04, -1.9033e-03, -1.6712e-03],\n",
            "          [-7.1433e-03, -3.2172e-03, -3.0836e-03],\n",
            "          [ 5.7762e-04,  6.0507e-04, -8.8407e-04]],\n",
            "\n",
            "         [[ 4.1125e-04, -2.3803e-05, -1.5871e-04],\n",
            "          [ 8.6082e-03,  1.8509e-03,  1.8400e-03],\n",
            "          [-1.2182e-03, -6.4671e-03, -7.1351e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.3603e-03, -1.3494e-03,  4.5072e-03],\n",
            "          [-4.4286e-03, -4.0440e-03, -3.7760e-03],\n",
            "          [-8.8024e-04, -1.1510e-03, -2.1630e-03]],\n",
            "\n",
            "         [[ 3.1374e-03,  6.8542e-04, -7.2038e-03],\n",
            "          [ 5.4177e-03, -2.2330e-03,  6.3029e-04],\n",
            "          [ 7.4273e-03,  7.5708e-03,  1.9968e-03]],\n",
            "\n",
            "         [[ 4.4564e-03,  1.8357e-03,  3.8700e-04],\n",
            "          [ 6.3982e-03,  3.1021e-03, -6.9713e-04],\n",
            "          [ 3.0141e-03,  5.7266e-03,  7.1829e-03]]],\n",
            "\n",
            "\n",
            "        [[[-5.8559e-03, -5.2648e-03, -2.5986e-03],\n",
            "          [-1.4967e-03, -2.8716e-03,  6.8852e-05],\n",
            "          [-1.9129e-04, -4.1369e-03, -2.8935e-04]],\n",
            "\n",
            "         [[-3.2653e-03, -5.6190e-03, -1.6991e-04],\n",
            "          [-4.1927e-05, -2.3347e-03, -2.9051e-03],\n",
            "          [-1.7494e-03, -4.6729e-03,  7.0916e-04]],\n",
            "\n",
            "         [[-1.0390e-02, -1.7441e-02, -2.0296e-02],\n",
            "          [-4.5886e-03, -1.2006e-02, -1.5651e-02],\n",
            "          [-5.9925e-03, -7.1242e-03, -8.9987e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0471e-02, -7.5440e-03, -5.1300e-04],\n",
            "          [-1.2949e-03, -5.2490e-03,  5.6638e-04],\n",
            "          [ 1.1699e-03,  2.0052e-03,  4.4733e-03]],\n",
            "\n",
            "         [[-3.5281e-03, -1.1013e-03, -1.2125e-02],\n",
            "          [-1.1269e-03, -2.7975e-03, -1.5106e-02],\n",
            "          [ 6.0322e-03,  1.6040e-03,  3.1669e-03]],\n",
            "\n",
            "         [[-5.4237e-04, -6.2599e-05, -5.2291e-03],\n",
            "          [ 2.5643e-04,  1.0603e-03, -3.8078e-03],\n",
            "          [-5.5514e-03, -7.9489e-03, -8.4854e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.4382e-03, -2.3963e-03, -3.8357e-03],\n",
            "          [ 4.9390e-04,  2.0434e-03,  5.6836e-04],\n",
            "          [ 1.1288e-03, -2.7195e-03,  2.6855e-03]],\n",
            "\n",
            "         [[ 5.2875e-03,  3.6884e-03,  3.1806e-03],\n",
            "          [ 4.1211e-03,  4.5969e-04,  1.4713e-03],\n",
            "          [-9.4049e-04,  4.3117e-04, -2.6347e-04]],\n",
            "\n",
            "         [[-2.0537e-02, -1.2040e-02, -1.1145e-02],\n",
            "          [-1.0602e-02, -3.2583e-03, -3.2316e-03],\n",
            "          [ 3.3530e-03, -3.7910e-03, -1.0528e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.6788e-02,  9.9917e-03,  1.0506e-02],\n",
            "          [ 1.6649e-02,  1.8990e-03, -1.4377e-03],\n",
            "          [ 5.5821e-03,  1.9716e-03, -6.0423e-04]],\n",
            "\n",
            "         [[ 7.6207e-03,  9.8365e-03,  7.6474e-03],\n",
            "          [ 8.1192e-03,  5.7670e-03, -3.8679e-03],\n",
            "          [-9.0012e-04, -1.0436e-02, -1.5768e-02]],\n",
            "\n",
            "         [[ 2.9237e-03,  2.2085e-03,  2.2554e-03],\n",
            "          [ 4.3506e-04,  3.5638e-04,  1.6526e-03],\n",
            "          [ 1.1519e-03,  5.5994e-04, -1.4373e-03]]],\n",
            "\n",
            "\n",
            "        [[[-8.7866e-04,  1.6829e-03, -5.3813e-03],\n",
            "          [ 1.1448e-03,  3.0624e-03, -5.9131e-03],\n",
            "          [-1.1182e-03,  3.1413e-03, -5.5475e-03]],\n",
            "\n",
            "         [[-3.6677e-03,  1.4092e-03,  2.0719e-03],\n",
            "          [-3.8998e-03, -1.0669e-03, -3.3219e-03],\n",
            "          [ 5.8261e-04,  5.1776e-05,  6.7090e-04]],\n",
            "\n",
            "         [[-8.9728e-04, -4.1122e-03, -7.3061e-03],\n",
            "          [-1.1191e-04, -1.9206e-03, -6.7198e-03],\n",
            "          [-4.0175e-03, -1.8699e-03, -9.0733e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.7920e-03, -6.6685e-04,  3.7263e-03],\n",
            "          [-2.4852e-03,  2.2364e-03,  1.9199e-03],\n",
            "          [-5.0985e-03,  8.2725e-04, -8.7405e-04]],\n",
            "\n",
            "         [[ 1.2277e-03,  3.5271e-04,  4.1222e-03],\n",
            "          [-5.7830e-04, -3.7969e-03, -3.0578e-03],\n",
            "          [-1.4334e-03, -4.0406e-04, -1.9449e-03]],\n",
            "\n",
            "         [[-2.4687e-03, -2.2380e-03, -1.5154e-03],\n",
            "          [-1.1828e-03, -1.1077e-03, -2.4805e-03],\n",
            "          [ 1.6360e-03,  5.3038e-04, -3.6507e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.0695e-04,  9.8685e-04, -2.8078e-04],\n",
            "          [-4.1413e-05,  1.7715e-03,  3.2046e-04],\n",
            "          [ 2.4764e-04,  1.2150e-03,  1.0686e-03]],\n",
            "\n",
            "         [[-1.0852e-04,  3.3862e-04,  5.3794e-04],\n",
            "          [ 1.4976e-04,  1.3021e-03,  2.5905e-05],\n",
            "          [ 5.1619e-04,  1.3456e-03,  1.0830e-03]],\n",
            "\n",
            "         [[-6.7403e-05, -1.8059e-03, -1.7577e-03],\n",
            "          [-8.7489e-04, -1.4135e-05, -1.7894e-03],\n",
            "          [-1.3740e-04,  3.9201e-04, -5.7485e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.1920e-04,  4.6515e-04,  4.2499e-04],\n",
            "          [-6.7899e-05,  1.2318e-03,  5.1356e-04],\n",
            "          [ 1.3809e-03,  3.7564e-03,  2.8446e-03]],\n",
            "\n",
            "         [[-8.0196e-04, -1.9974e-04, -1.3475e-04],\n",
            "          [ 1.1726e-04, -5.8816e-04, -3.7400e-04],\n",
            "          [-1.4486e-03, -4.0636e-04,  1.9196e-03]],\n",
            "\n",
            "         [[ 4.6914e-05, -2.0389e-04,  6.2669e-05],\n",
            "          [-1.1020e-03, -1.1196e-03, -4.2235e-04],\n",
            "          [-1.4097e-04, -9.0789e-04, -1.7520e-03]]]], device='cuda:0')}, 7: {'momentum_buffer': tensor([ 4.8707e-03,  2.4091e-03, -3.2480e-03,  1.0761e-03, -5.0785e-03,\n",
            "         1.3888e-03, -5.2436e-03, -2.0452e-03, -8.4786e-03,  1.6792e-03,\n",
            "         4.5856e-03, -2.6391e-03,  1.7427e-03, -5.6902e-03, -1.3334e-03,\n",
            "        -2.5867e-03, -7.8879e-03,  2.5281e-03,  1.6318e-03,  1.0525e-04,\n",
            "         2.3641e-03,  1.2380e-04, -4.5642e-03,  1.0322e-02, -4.8708e-03,\n",
            "         3.9443e-03,  6.1882e-03, -8.2563e-03,  2.6795e-03, -4.0964e-04,\n",
            "        -1.3776e-03,  6.2114e-03, -2.0417e-03, -1.9146e-04,  3.9780e-03,\n",
            "        -1.9311e-03,  5.1636e-03, -1.5112e-03,  3.6522e-03, -6.5424e-03,\n",
            "         9.8311e-03,  1.6939e-03,  2.3600e-03,  5.9002e-03, -2.8106e-03,\n",
            "         5.9143e-03, -1.3815e-03, -4.6716e-03,  1.7269e-03, -7.4559e-03,\n",
            "         3.2133e-03,  3.4140e-04,  8.6192e-04, -7.4532e-03, -2.5838e-03,\n",
            "         2.0207e-03,  1.2248e-03, -8.4589e-03,  2.5602e-03, -2.5769e-03,\n",
            "         1.4890e-03, -1.3716e-03, -1.8110e-03,  1.9674e-03,  1.6373e-03,\n",
            "        -8.4335e-04,  5.2798e-03, -4.0346e-04, -3.5184e-05, -2.7288e-03,\n",
            "         2.7393e-03,  9.9481e-03, -3.9047e-03, -2.3446e-03,  7.0702e-03,\n",
            "         3.7211e-04, -3.2086e-03, -7.4534e-03, -6.9415e-04, -7.9264e-03,\n",
            "        -2.2833e-03,  3.6571e-03, -2.6943e-04, -1.1319e-03,  2.1547e-03,\n",
            "         4.3854e-03, -1.7776e-03, -6.1107e-03, -2.9382e-05,  3.3151e-03,\n",
            "        -4.8722e-03, -3.1521e-03,  4.4645e-03,  1.8330e-03,  1.4432e-03,\n",
            "        -2.1539e-03, -1.9631e-03,  4.0290e-03, -7.9525e-03,  1.5575e-04,\n",
            "        -1.3022e-03,  1.7287e-03, -2.3901e-03,  5.8848e-03, -2.7168e-05,\n",
            "         2.5022e-03,  6.2433e-04, -3.2210e-04,  9.7133e-03,  7.6690e-04,\n",
            "         1.3295e-03, -3.2264e-04, -9.1016e-04, -8.9117e-04,  1.7072e-03,\n",
            "        -3.8985e-03,  3.0882e-03, -1.9866e-03, -4.0782e-03,  1.2888e-02,\n",
            "        -1.8733e-03,  2.1025e-04, -7.8616e-03, -1.8943e-03,  8.9231e-03,\n",
            "         1.4140e-03, -9.9359e-03,  1.1210e-03, -1.0794e-03,  3.4307e-03,\n",
            "        -7.6393e-03, -6.0875e-03, -2.9518e-03,  9.5735e-03, -1.0318e-03,\n",
            "        -7.0316e-03, -1.1172e-03, -5.9183e-04,  8.5550e-04,  6.5894e-03,\n",
            "         7.7921e-04,  9.6422e-04,  7.7615e-04,  6.0916e-03,  4.5748e-03,\n",
            "        -6.5069e-04, -6.6414e-04,  3.2306e-03,  8.8683e-03,  2.9531e-03,\n",
            "        -4.1821e-03,  5.5803e-04, -6.4697e-03,  4.3690e-03,  2.4548e-04,\n",
            "        -7.0928e-03,  5.8309e-04,  1.9085e-03, -6.8079e-03,  9.7151e-05,\n",
            "        -1.1692e-04, -8.2065e-03, -2.4672e-04, -5.5170e-03, -1.5007e-03,\n",
            "        -1.9056e-03, -5.4949e-04,  3.2737e-03, -7.6412e-03,  3.7469e-03,\n",
            "        -1.7549e-03, -8.0324e-03,  8.4107e-04,  1.5483e-04,  6.9105e-05,\n",
            "         5.1069e-03, -2.3359e-03,  5.4891e-03, -3.7734e-04, -9.8433e-04,\n",
            "         3.4986e-03, -7.2324e-04, -3.4488e-03, -1.5760e-03,  2.3197e-03,\n",
            "         1.9109e-03,  5.0074e-04, -4.5857e-03, -2.4163e-04,  1.1727e-03,\n",
            "        -1.0718e-03,  4.2375e-04,  5.2020e-04,  4.0007e-04,  1.1503e-03,\n",
            "        -2.7777e-04,  1.6218e-03, -5.5763e-03, -2.1895e-03,  7.2541e-03,\n",
            "         5.0261e-03, -5.6237e-03,  9.3010e-04,  5.4207e-03, -8.1213e-03,\n",
            "        -9.7359e-03,  4.4974e-03,  9.5030e-04, -2.3466e-03, -1.4993e-03,\n",
            "        -2.0178e-03,  3.7623e-03, -2.0457e-03, -2.8953e-03,  5.0191e-03,\n",
            "         3.4640e-03, -2.9598e-03, -6.3267e-03, -6.5552e-03, -5.1182e-03,\n",
            "         1.8470e-03,  4.0588e-03, -2.3581e-03,  2.5423e-03, -2.6050e-03,\n",
            "        -2.6388e-03, -3.6649e-03, -2.2995e-04, -1.6673e-03,  3.0676e-04,\n",
            "        -2.4808e-03, -4.0971e-03, -1.2611e-03, -8.9384e-03, -5.5400e-03,\n",
            "         5.1219e-03, -1.5509e-04,  4.1680e-03,  4.0633e-03,  2.8834e-03,\n",
            "         4.2723e-03, -4.8391e-03,  3.4585e-03,  4.6361e-03, -1.0867e-02,\n",
            "         4.7867e-03,  5.6335e-03,  5.6684e-03,  3.1486e-03, -4.9789e-03,\n",
            "        -2.3537e-03,  2.0936e-03, -1.5470e-04,  5.2048e-03,  1.1120e-03,\n",
            "        -5.6153e-04], device='cuda:0')}, 8: {'momentum_buffer': tensor([[[[ 2.4490e-05, -1.9088e-03,  2.8276e-03],\n",
            "          [ 2.7961e-04,  2.8854e-03,  6.2516e-03],\n",
            "          [-1.6025e-03, -1.5077e-03, -2.4618e-04]],\n",
            "\n",
            "         [[ 7.7593e-04, -2.5553e-03, -5.8488e-04],\n",
            "          [ 9.9014e-04,  7.7460e-04,  2.0602e-03],\n",
            "          [-1.8316e-04,  2.6894e-03,  1.8663e-03]],\n",
            "\n",
            "         [[-2.6903e-04, -1.7043e-04,  3.5467e-03],\n",
            "          [-1.6005e-03,  2.6537e-03,  5.3936e-03],\n",
            "          [ 8.9576e-05,  6.1843e-04,  5.4264e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.7092e-05,  1.4495e-03,  7.7588e-03],\n",
            "          [ 8.2715e-04,  3.4314e-03,  4.3038e-03],\n",
            "          [ 9.1673e-04,  1.3359e-03, -1.4849e-03]],\n",
            "\n",
            "         [[ 1.2112e-03,  2.4959e-03,  1.8145e-03],\n",
            "          [ 9.9335e-04,  6.2839e-03,  2.6818e-03],\n",
            "          [ 9.1388e-04,  5.2270e-03,  5.5038e-03]],\n",
            "\n",
            "         [[ 2.7513e-05, -6.5276e-04, -1.9196e-04],\n",
            "          [ 5.7690e-04,  1.1185e-03, -8.0586e-05],\n",
            "          [ 7.8950e-05,  1.2849e-04,  1.6334e-06]]],\n",
            "\n",
            "\n",
            "        [[[-1.0328e-02, -1.0068e-02, -2.3113e-03],\n",
            "          [-6.0960e-04,  2.5529e-03,  1.2488e-03],\n",
            "          [-1.3176e-04,  8.3515e-03,  8.9871e-03]],\n",
            "\n",
            "         [[ 5.5080e-03,  4.0841e-03,  2.7315e-03],\n",
            "          [ 2.0500e-03,  6.0419e-03,  4.9060e-03],\n",
            "          [ 1.6960e-03,  1.8432e-03, -6.5260e-04]],\n",
            "\n",
            "         [[-8.2451e-04,  2.1055e-03,  1.1241e-05],\n",
            "          [-1.3878e-04, -3.9333e-04, -8.9176e-04],\n",
            "          [-7.0073e-04,  1.0656e-02,  3.0296e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.9341e-03,  3.9688e-04, -2.7715e-04],\n",
            "          [ 1.4194e-04,  1.2400e-03,  1.3485e-05],\n",
            "          [ 4.7741e-04, -2.8087e-04,  1.3179e-03]],\n",
            "\n",
            "         [[ 1.6267e-03, -1.2317e-03,  3.7628e-04],\n",
            "          [ 4.5496e-03, -1.0649e-03, -4.8327e-04],\n",
            "          [ 3.2085e-03, -1.2101e-03,  1.4731e-03]],\n",
            "\n",
            "         [[ 2.8009e-04,  2.9285e-04,  1.0776e-04],\n",
            "          [ 6.1814e-05,  6.1675e-04, -1.1643e-04],\n",
            "          [-8.7744e-05, -2.2334e-04,  1.5195e-04]]],\n",
            "\n",
            "\n",
            "        [[[-1.2021e-02, -1.0788e-02,  2.0579e-03],\n",
            "          [-1.3075e-02,  7.5471e-03,  1.5339e-02],\n",
            "          [-2.3660e-03,  6.7577e-04,  1.6822e-03]],\n",
            "\n",
            "         [[-2.7673e-04, -1.3100e-03, -9.8034e-04],\n",
            "          [ 2.4545e-03,  2.7663e-03,  2.7854e-03],\n",
            "          [-6.3504e-04, -1.1197e-03, -1.3361e-03]],\n",
            "\n",
            "         [[ 3.2981e-03,  2.8306e-05,  3.3197e-04],\n",
            "          [ 5.1871e-03, -5.0999e-03,  1.3928e-02],\n",
            "          [ 1.7165e-03, -2.6844e-03,  8.1433e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.7604e-03, -1.3308e-02,  3.5077e-03],\n",
            "          [ 5.1969e-03, -6.4979e-03,  1.7944e-03],\n",
            "          [-4.6778e-03, -6.3369e-03, -7.8382e-03]],\n",
            "\n",
            "         [[-1.6586e-03, -8.5868e-03,  6.9164e-03],\n",
            "          [ 1.9921e-03, -4.9446e-03,  8.6618e-03],\n",
            "          [-2.1397e-03,  6.9609e-03,  6.4990e-03]],\n",
            "\n",
            "         [[-3.3358e-03, -8.7630e-04, -7.6433e-05],\n",
            "          [-9.5430e-04,  5.4201e-04,  8.8807e-04],\n",
            "          [-2.1734e-04,  4.4212e-04, -3.1002e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.6557e-02,  1.8336e-02,  1.3290e-02],\n",
            "          [ 3.5027e-03,  8.1420e-03,  1.2739e-02],\n",
            "          [ 8.7900e-03,  2.1087e-02,  1.2703e-02]],\n",
            "\n",
            "         [[ 2.8806e-03,  8.7833e-04, -2.4522e-04],\n",
            "          [ 4.8988e-03,  5.5377e-03, -1.0031e-03],\n",
            "          [ 3.8478e-03,  2.5499e-03,  7.8745e-04]],\n",
            "\n",
            "         [[ 8.7255e-03,  3.9307e-03,  5.2737e-03],\n",
            "          [ 1.2634e-03, -1.7002e-03,  7.0714e-04],\n",
            "          [ 3.3561e-03,  9.0010e-04,  4.3444e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.2944e-04,  2.1864e-03,  1.4538e-03],\n",
            "          [-6.1685e-03,  2.5729e-03,  3.0731e-04],\n",
            "          [ 4.1400e-03,  8.8257e-03,  9.9257e-03]],\n",
            "\n",
            "         [[-3.8554e-04, -4.4478e-04,  3.1592e-03],\n",
            "          [ 3.0595e-03,  3.3838e-03,  9.7689e-03],\n",
            "          [ 8.5958e-03,  1.0185e-02,  1.4678e-02]],\n",
            "\n",
            "         [[ 2.8907e-03, -5.9115e-05, -4.6167e-04],\n",
            "          [ 6.2089e-04, -2.7604e-05,  8.1942e-05],\n",
            "          [ 8.2477e-04,  3.7977e-04,  1.2129e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2656e-02,  2.1274e-02,  1.6278e-03],\n",
            "          [ 2.3125e-02,  7.8009e-03, -6.1637e-03],\n",
            "          [ 1.4514e-02, -1.2990e-03,  1.4299e-03]],\n",
            "\n",
            "         [[-1.6239e-03, -6.0297e-04, -1.3370e-05],\n",
            "          [ 7.6923e-04,  1.2412e-03, -2.9481e-03],\n",
            "          [ 9.9254e-04,  1.5570e-03, -8.7334e-04]],\n",
            "\n",
            "         [[ 3.8434e-03, -1.4858e-03, -4.0950e-03],\n",
            "          [ 3.6867e-03,  1.2490e-03, -1.0716e-03],\n",
            "          [ 2.2663e-03,  9.0194e-04, -2.6239e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.0544e-02,  4.2179e-03, -9.0471e-03],\n",
            "          [ 1.9699e-03, -5.3524e-03, -6.0121e-03],\n",
            "          [ 4.2175e-03, -4.1177e-03, -9.9672e-05]],\n",
            "\n",
            "         [[ 7.2539e-04, -9.8346e-03, -3.7917e-03],\n",
            "          [-4.6737e-03, -1.0334e-02, -4.1004e-03],\n",
            "          [ 7.8153e-05, -2.2072e-03,  2.0455e-04]],\n",
            "\n",
            "         [[-1.2341e-03, -1.2828e-03, -2.5777e-04],\n",
            "          [-4.1988e-04,  4.2349e-04,  2.1587e-04],\n",
            "          [-3.0728e-04, -3.3519e-06,  1.4551e-04]]],\n",
            "\n",
            "\n",
            "        [[[-8.4062e-03, -1.7362e-03, -3.6856e-03],\n",
            "          [ 9.0127e-05, -4.1458e-03, -6.4443e-04],\n",
            "          [ 4.7660e-03,  4.2038e-03,  6.6087e-03]],\n",
            "\n",
            "         [[-1.0901e-03,  1.2345e-03,  2.5654e-03],\n",
            "          [-7.4176e-04, -3.5755e-03,  4.4740e-03],\n",
            "          [-3.4941e-03, -3.6544e-03,  1.0153e-03]],\n",
            "\n",
            "         [[ 1.2147e-03, -2.5198e-03,  7.5650e-03],\n",
            "          [-1.1177e-03,  5.6634e-03,  5.9704e-03],\n",
            "          [ 3.0923e-03,  9.2179e-04, -3.9952e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.3501e-03,  3.6264e-03,  4.5635e-03],\n",
            "          [-5.9067e-04,  4.1070e-04,  5.3012e-03],\n",
            "          [ 6.9063e-03,  1.5278e-03, -3.9928e-03]],\n",
            "\n",
            "         [[ 8.0580e-03,  3.9233e-03, -1.0823e-04],\n",
            "          [ 1.9611e-03, -3.3421e-03, -6.7331e-03],\n",
            "          [ 1.7288e-03, -4.4921e-03,  7.3090e-05]],\n",
            "\n",
            "         [[-5.9115e-04,  5.4694e-04,  2.9051e-05],\n",
            "          [ 3.4311e-04, -4.9261e-05,  2.5041e-04],\n",
            "          [ 1.2645e-04,  3.1976e-04, -4.3850e-05]]]], device='cuda:0')}, 9: {'momentum_buffer': tensor([-3.9963e-03,  2.0521e-03, -2.1390e-03, -7.8963e-04,  1.0292e-03,\n",
            "        -8.8435e-04, -1.5276e-03, -4.1454e-03,  4.3404e-03,  1.3032e-04,\n",
            "         8.8568e-04, -1.0253e-03, -2.3313e-03, -8.2599e-04, -1.5678e-03,\n",
            "         6.8942e-03,  2.1083e-03, -5.0257e-05,  4.2889e-03,  1.1788e-03,\n",
            "         1.1931e-03,  1.5736e-03,  5.6112e-03,  1.0448e-03,  6.7310e-04,\n",
            "        -4.0282e-03, -5.4690e-03,  1.4333e-03, -2.3440e-03,  6.6259e-04,\n",
            "         1.7769e-03, -5.6109e-03,  2.2733e-03, -2.6870e-03, -1.6774e-03,\n",
            "         7.0433e-04, -6.1391e-03, -1.8236e-03,  4.6004e-03, -3.6805e-03,\n",
            "         5.2113e-04, -1.4642e-03,  8.9138e-03,  8.7942e-04, -2.5688e-03,\n",
            "        -4.4376e-03, -2.8658e-03, -4.6048e-03,  2.5556e-03, -4.3002e-03,\n",
            "        -4.0501e-03, -3.3015e-03, -6.0754e-03,  7.2426e-05,  4.0474e-03,\n",
            "         2.3665e-03,  9.8076e-04, -3.2390e-03,  1.9796e-03, -1.1639e-03,\n",
            "        -3.9093e-03,  6.0733e-03,  2.2417e-03,  4.9749e-03, -4.7588e-03,\n",
            "        -9.9504e-04, -3.3587e-03,  3.6979e-03,  1.9711e-03,  1.4171e-03,\n",
            "        -2.3867e-03, -6.3390e-04,  6.8619e-03,  1.5106e-03,  2.4521e-03,\n",
            "        -3.8806e-03,  6.2625e-03, -4.9868e-03,  5.5674e-03,  1.0864e-02,\n",
            "        -2.1414e-03,  3.2606e-03,  4.9495e-03, -4.2498e-03, -7.0466e-05,\n",
            "         1.2995e-03, -4.3555e-04, -6.7973e-03,  7.1274e-03,  2.7688e-03,\n",
            "         7.9555e-04, -5.9752e-04,  3.7361e-03,  7.5753e-03, -1.6238e-03,\n",
            "         2.3889e-03, -4.6926e-03, -1.4893e-04, -3.5778e-04, -3.7284e-03,\n",
            "        -6.5217e-03, -3.3027e-03,  3.2909e-03,  2.6837e-03, -5.4117e-04,\n",
            "        -5.8186e-03,  4.8300e-03,  3.8595e-03,  1.6226e-03,  5.7132e-04,\n",
            "         1.1888e-03, -4.2778e-03,  1.1821e-03, -6.2615e-04,  5.3215e-04,\n",
            "         1.4822e-03, -2.5609e-03, -3.2102e-03,  1.8183e-03, -1.0088e-02,\n",
            "        -2.9545e-03, -1.5340e-03, -3.8329e-03,  4.8646e-03,  2.9688e-03,\n",
            "        -1.9712e-03,  4.2095e-03,  1.4914e-03, -6.0114e-04, -6.4010e-05,\n",
            "         4.5651e-03, -2.8046e-04, -3.6893e-03, -1.0594e-03,  3.8698e-03,\n",
            "         7.5214e-04,  4.6108e-05, -3.8808e-03,  3.5475e-03, -2.7446e-03,\n",
            "         1.3761e-03, -4.6121e-03,  1.5092e-03, -1.7800e-03,  1.1476e-03,\n",
            "        -2.7394e-03,  4.1008e-03,  2.0660e-03, -7.0876e-04, -1.1146e-03,\n",
            "        -3.9320e-04,  2.1908e-03,  8.9652e-03, -1.2282e-03, -3.0207e-04,\n",
            "         4.0757e-03, -9.8927e-04,  3.6658e-03,  5.1607e-03,  8.2799e-03,\n",
            "         1.2120e-03, -1.3071e-03,  2.2584e-03, -6.7103e-03,  7.1596e-04,\n",
            "        -4.8217e-03, -1.9715e-04, -2.4772e-04,  7.9854e-04, -2.0457e-03,\n",
            "         2.5299e-03,  6.4548e-03, -1.1013e-04, -2.6979e-03, -1.9176e-04,\n",
            "         2.8664e-03, -2.6676e-03, -8.7917e-04,  6.2927e-03, -5.7665e-04,\n",
            "         9.3804e-03, -3.4470e-03,  1.2978e-03, -2.5599e-03,  4.3525e-05,\n",
            "        -1.1597e-04,  3.9811e-03,  1.8691e-03,  1.1252e-03, -5.8479e-03,\n",
            "         2.5849e-03,  2.7532e-04,  1.0777e-03, -3.7704e-03, -2.8039e-03,\n",
            "        -4.5368e-03,  6.9867e-03,  3.3457e-03, -3.8347e-03,  2.8869e-03,\n",
            "        -2.1354e-03, -1.9377e-03, -4.0084e-03,  8.9875e-03, -3.6813e-03,\n",
            "         1.1122e-03,  1.6584e-04, -5.6781e-03, -3.7817e-03,  7.2690e-04,\n",
            "         6.5684e-04,  5.3703e-04,  4.7237e-03,  3.3577e-03,  2.9458e-03,\n",
            "        -2.1792e-03,  4.3161e-04,  3.8086e-03, -7.6948e-03,  9.9356e-04,\n",
            "        -2.3430e-03,  7.8185e-04,  6.2031e-04,  1.7415e-03,  1.1768e-03,\n",
            "        -8.4415e-04,  2.6103e-04, -6.2770e-03, -2.1113e-03, -2.2592e-03,\n",
            "         1.4466e-03,  3.5941e-03,  5.5566e-03,  3.6379e-03, -4.1303e-03,\n",
            "         6.1249e-03, -8.3866e-03, -8.4173e-04,  8.0161e-03,  1.4146e-03,\n",
            "        -2.9464e-03, -2.9459e-03, -1.3325e-03,  1.1910e-03, -5.7762e-03,\n",
            "         7.4634e-04,  2.7998e-03, -8.2011e-03, -3.3918e-03,  2.4100e-03,\n",
            "         1.5594e-03, -1.1641e-03, -4.0731e-04,  3.5865e-03, -1.5021e-03,\n",
            "         3.4641e-04], device='cuda:0')}, 10: {'momentum_buffer': tensor([[[[-1.6889e-03, -3.3456e-03,  1.5079e-03],\n",
            "          [-8.9773e-04,  7.4293e-04,  5.7428e-04],\n",
            "          [-4.8191e-04,  2.0319e-03,  6.3623e-04]],\n",
            "\n",
            "         [[-2.3602e-03, -1.8802e-03, -1.0732e-03],\n",
            "          [-3.5971e-03, -1.8844e-04, -1.2384e-03],\n",
            "          [-2.0715e-03, -4.3630e-04,  4.0839e-04]],\n",
            "\n",
            "         [[-2.9243e-03, -1.3298e-02, -3.5823e-03],\n",
            "          [ 1.5895e-03, -1.1004e-02, -5.9778e-03],\n",
            "          [-2.7450e-03, -7.9000e-03, -8.1592e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.9510e-03, -3.1090e-03, -1.4369e-03],\n",
            "          [-2.0673e-03, -1.6030e-03, -3.3177e-03],\n",
            "          [ 2.9271e-04, -1.5277e-03, -2.9819e-03]],\n",
            "\n",
            "         [[-5.9989e-03, -2.5492e-03, -6.4510e-03],\n",
            "          [-5.9963e-03, -6.3759e-03, -4.1741e-03],\n",
            "          [-8.4745e-03, -8.0326e-03,  6.5584e-03]],\n",
            "\n",
            "         [[ 1.4817e-03,  3.1144e-03,  3.3610e-03],\n",
            "          [-7.5188e-04,  7.9533e-03,  6.0490e-04],\n",
            "          [-4.5640e-04,  2.9076e-03,  1.5267e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0816e-03, -4.3611e-04, -7.9527e-06],\n",
            "          [-1.0389e-03, -2.0707e-03, -2.8619e-03],\n",
            "          [ 6.5909e-04,  7.9051e-04, -8.0760e-04]],\n",
            "\n",
            "         [[ 2.8771e-03,  1.6843e-03, -1.8235e-03],\n",
            "          [ 2.4191e-03,  3.4999e-03,  8.6371e-04],\n",
            "          [ 9.9585e-05,  1.0425e-03,  6.7240e-04]],\n",
            "\n",
            "         [[ 6.4632e-03,  1.3703e-03,  3.0079e-03],\n",
            "          [ 5.1562e-03,  4.8239e-03,  1.8456e-03],\n",
            "          [ 5.0265e-03,  1.2423e-03, -1.5844e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.3183e-03,  3.8200e-03,  1.4587e-03],\n",
            "          [ 2.2670e-03, -6.0496e-04,  2.1048e-04],\n",
            "          [ 1.7484e-03, -2.9463e-04,  8.7373e-04]],\n",
            "\n",
            "         [[ 8.4874e-04,  9.4526e-04,  2.2941e-04],\n",
            "          [ 2.2252e-03,  4.6316e-04,  6.0570e-04],\n",
            "          [-1.4594e-03, -3.6525e-03,  2.1081e-03]],\n",
            "\n",
            "         [[ 6.7301e-03,  1.8851e-03,  3.9847e-04],\n",
            "          [-1.3401e-04,  2.4071e-04,  4.2288e-04],\n",
            "          [-5.5484e-04, -1.4255e-03, -1.8210e-03]]],\n",
            "\n",
            "\n",
            "        [[[-9.4472e-04, -6.9085e-05,  5.0829e-04],\n",
            "          [-8.0594e-04, -3.8802e-04, -2.5375e-05],\n",
            "          [ 5.1874e-04,  2.9003e-04, -4.4590e-04]],\n",
            "\n",
            "         [[-1.0295e-03,  8.8156e-04, -4.8013e-04],\n",
            "          [-1.5908e-03, -3.7546e-04, -1.7007e-04],\n",
            "          [-1.2546e-03, -8.2854e-04,  3.3565e-04]],\n",
            "\n",
            "         [[-5.3875e-03, -2.6960e-03,  3.6241e-03],\n",
            "          [-2.0366e-03,  7.2147e-04, -1.7524e-03],\n",
            "          [-7.9984e-04,  3.9634e-03,  1.9448e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.6948e-03, -5.9567e-04, -1.6730e-04],\n",
            "          [-1.4653e-03, -2.7239e-03, -1.0955e-03],\n",
            "          [-1.2003e-03, -3.8530e-03, -4.5619e-04]],\n",
            "\n",
            "         [[-3.4043e-03, -4.2845e-03,  2.0203e-03],\n",
            "          [ 1.0977e-03, -6.6796e-04, -1.4122e-03],\n",
            "          [ 5.6694e-03,  4.1443e-03, -1.7699e-03]],\n",
            "\n",
            "         [[-3.6262e-03, -4.7810e-04,  4.0520e-04],\n",
            "          [-9.1492e-04,  1.2075e-03, -2.1356e-04],\n",
            "          [-1.6728e-03, -2.8590e-03, -1.2413e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.2635e-04, -1.3364e-03,  4.8240e-03],\n",
            "          [-9.5733e-04, -1.8440e-03,  4.6497e-03],\n",
            "          [ 8.4004e-04,  4.5677e-04,  3.5706e-03]],\n",
            "\n",
            "         [[-7.2321e-03, -2.0850e-04, -3.8781e-03],\n",
            "          [-1.6320e-03, -2.1641e-03, -4.0979e-04],\n",
            "          [-1.4389e-03,  1.5868e-03,  2.6849e-04]],\n",
            "\n",
            "         [[ 7.5790e-03,  4.7728e-03, -1.0242e-03],\n",
            "          [ 8.8100e-03,  3.1589e-03,  6.8041e-03],\n",
            "          [ 7.0985e-04, -1.5146e-03,  8.7831e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.6758e-03, -8.5020e-04, -5.9599e-03],\n",
            "          [-2.4371e-03, -2.4840e-03, -3.1960e-03],\n",
            "          [ 3.7871e-03,  5.8411e-03, -3.3701e-03]],\n",
            "\n",
            "         [[ 3.6858e-03,  2.3203e-03, -2.6045e-04],\n",
            "          [ 5.9758e-03,  7.4009e-03,  1.6916e-03],\n",
            "          [ 3.7050e-03, -2.7300e-03, -5.9737e-03]],\n",
            "\n",
            "         [[ 1.4280e-03,  5.8773e-03,  7.4685e-03],\n",
            "          [-2.7658e-03,  3.2653e-03,  4.2443e-03],\n",
            "          [-5.8526e-03, -5.9399e-04,  3.0387e-03]]],\n",
            "\n",
            "\n",
            "        [[[-7.8085e-04, -6.8853e-04, -3.4071e-03],\n",
            "          [-8.5416e-04, -4.0764e-04, -1.8886e-03],\n",
            "          [-2.4146e-03, -1.5823e-04, -2.7691e-03]],\n",
            "\n",
            "         [[ 5.2232e-05, -4.4055e-03,  1.9053e-03],\n",
            "          [-1.1593e-03, -2.4102e-03, -3.7063e-04],\n",
            "          [ 2.0429e-03, -8.7030e-04, -1.1045e-03]],\n",
            "\n",
            "         [[ 3.7335e-04,  1.8409e-04, -3.9171e-03],\n",
            "          [-1.6283e-03, -1.2947e-03, -6.4541e-03],\n",
            "          [ 4.5307e-03,  3.9615e-03, -9.6709e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5149e-03,  2.1625e-03, -5.4861e-03],\n",
            "          [ 4.0236e-03,  2.7681e-03, -1.2245e-03],\n",
            "          [-6.6147e-03, -3.7822e-03, -4.1144e-03]],\n",
            "\n",
            "         [[-8.5379e-04, -2.0651e-03,  1.1708e-03],\n",
            "          [-2.4254e-03, -6.9257e-04,  1.9265e-03],\n",
            "          [-4.3897e-05, -3.1189e-03, -4.2246e-03]],\n",
            "\n",
            "         [[ 2.2259e-03, -6.0580e-03, -4.0014e-03],\n",
            "          [ 4.4290e-03, -2.4921e-03,  1.6850e-03],\n",
            "          [ 2.8269e-03, -1.3182e-03, -2.1307e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.4443e-04, -3.5648e-04,  1.2468e-03],\n",
            "          [ 4.8107e-04,  1.4490e-03,  2.0203e-03],\n",
            "          [-4.1458e-05,  4.3910e-03,  5.2779e-04]],\n",
            "\n",
            "         [[ 1.9320e-03, -2.5458e-04,  1.4578e-03],\n",
            "          [ 2.1895e-03, -2.8225e-04, -3.9774e-04],\n",
            "          [ 3.8026e-03,  1.3629e-03,  1.0387e-03]],\n",
            "\n",
            "         [[ 3.6959e-03, -7.3872e-04,  7.0210e-04],\n",
            "          [ 4.5421e-03, -5.5870e-03,  1.0819e-03],\n",
            "          [ 1.3552e-03, -1.4932e-03, -2.5204e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4849e-04, -4.9909e-04, -1.1880e-03],\n",
            "          [-6.6796e-04, -1.2555e-03,  8.6039e-04],\n",
            "          [ 1.3679e-04, -1.0149e-04, -8.3673e-04]],\n",
            "\n",
            "         [[ 5.9144e-04,  2.7939e-04, -1.0138e-03],\n",
            "          [ 6.3784e-04, -6.1923e-04, -3.0482e-04],\n",
            "          [-1.7314e-03, -3.1313e-03,  1.1820e-03]],\n",
            "\n",
            "         [[ 4.3231e-04,  4.0566e-03, -2.0941e-04],\n",
            "          [ 4.0653e-03,  6.8899e-03,  2.0688e-04],\n",
            "          [ 6.4613e-03,  8.3851e-03,  6.7488e-04]]]], device='cuda:0')}, 11: {'momentum_buffer': tensor([ 4.6883e-03,  1.6173e-03, -1.0340e-03,  2.0020e-03,  9.5675e-04,\n",
            "         1.1225e-03,  2.3963e-03,  4.4275e-04,  7.5854e-03,  8.6969e-04,\n",
            "         9.1595e-04, -3.7571e-05, -6.7192e-03,  1.1928e-02,  7.1276e-04,\n",
            "         8.7992e-04,  3.8806e-03, -2.7560e-03,  7.2154e-05, -2.0048e-03,\n",
            "         3.8038e-03,  4.4390e-03, -4.4415e-03, -4.9054e-03, -1.9997e-03,\n",
            "        -1.6870e-04,  1.2389e-03,  4.0337e-03,  3.2547e-03,  4.8300e-05,\n",
            "         5.0881e-04,  3.6501e-04,  1.7212e-03, -3.0175e-03,  1.6905e-03,\n",
            "        -6.0410e-03,  3.0642e-03,  6.9187e-04,  3.6756e-03, -4.6500e-03,\n",
            "         5.0102e-04, -2.8023e-03,  2.5746e-03, -6.9103e-04, -2.4640e-04,\n",
            "        -1.0918e-03, -5.6366e-03, -2.5887e-04, -2.4421e-03,  2.4932e-03,\n",
            "         6.3061e-04,  1.5773e-03, -2.7280e-03,  2.9812e-03, -3.1048e-03,\n",
            "         3.7927e-03,  2.6766e-03,  6.4168e-03, -4.8581e-03,  3.1836e-03,\n",
            "         6.6482e-03,  7.0102e-03,  1.3864e-03, -1.4578e-03,  4.7734e-03,\n",
            "        -4.6809e-03, -4.4772e-03, -5.4292e-03,  1.1540e-04, -3.0234e-03,\n",
            "         5.2099e-04,  2.1927e-03,  1.4614e-03, -1.7600e-04,  3.1967e-04,\n",
            "        -4.1223e-04, -1.8034e-03,  1.0092e-03, -4.7252e-03, -7.3293e-03,\n",
            "        -7.4387e-04,  3.2784e-03,  3.0170e-03,  2.2227e-03,  5.0689e-03,\n",
            "         6.9891e-03,  4.1900e-03, -6.4052e-03,  3.6015e-03,  1.5414e-03,\n",
            "         4.0390e-03, -5.5325e-03, -1.4172e-04,  6.1387e-03,  2.6798e-03,\n",
            "        -2.7717e-03, -3.6309e-03,  2.1993e-03, -9.0386e-03,  5.8551e-04,\n",
            "        -3.2208e-03,  2.3725e-03, -1.2944e-04, -1.6252e-04,  6.2389e-03,\n",
            "         6.5471e-03, -8.7549e-03,  4.4076e-03, -4.7113e-03, -3.9023e-03,\n",
            "         6.3542e-04,  2.0196e-03,  4.1786e-03, -6.9198e-03, -6.6744e-04,\n",
            "        -2.8422e-04, -4.0444e-03, -1.7431e-03, -5.8706e-03,  4.1436e-03,\n",
            "        -7.0933e-03,  3.7199e-03,  6.7594e-04,  4.0817e-03,  1.7387e-03,\n",
            "        -2.1552e-03,  3.3024e-03, -4.7154e-03,  6.8841e-03, -3.1750e-03,\n",
            "         2.0291e-03, -3.5738e-04, -1.7199e-04, -3.0315e-03,  6.1454e-03,\n",
            "         1.9414e-03, -1.6639e-03, -3.8824e-04,  2.3953e-03, -8.2570e-03,\n",
            "        -1.5184e-03,  1.1388e-03, -8.4027e-04, -5.4335e-04,  6.2094e-04,\n",
            "        -1.9059e-03,  9.7826e-05,  6.0094e-05, -3.9664e-04, -1.5270e-03,\n",
            "         6.1738e-03,  2.3837e-03,  6.6357e-03,  2.0483e-04, -1.4367e-03,\n",
            "         4.1876e-03,  6.7654e-04, -2.0248e-03,  6.7623e-03, -1.1165e-03,\n",
            "         3.9474e-03, -8.1773e-04, -1.2265e-03, -3.5516e-03,  9.7060e-04,\n",
            "         6.3340e-04,  8.8130e-04,  2.8190e-03, -4.3762e-03, -3.8019e-03,\n",
            "         4.1250e-03,  3.8718e-03, -2.1677e-03,  2.8949e-03, -3.7502e-03,\n",
            "         5.2589e-03,  1.6601e-03,  3.6768e-03,  3.9659e-03, -1.9348e-05,\n",
            "         1.7974e-03,  8.1260e-04, -5.3250e-04, -1.7985e-03,  2.8509e-03,\n",
            "         8.3046e-03, -1.1764e-03, -4.4265e-04,  2.6601e-03,  2.1507e-03,\n",
            "         5.5966e-03, -3.2816e-03, -7.3874e-03, -1.4032e-03,  6.1139e-03,\n",
            "         1.7402e-03,  3.9190e-03, -4.2535e-03, -3.2475e-03, -3.1385e-03,\n",
            "        -7.7449e-04, -1.2855e-03,  1.7997e-03, -4.6250e-04,  3.6254e-03,\n",
            "         1.8286e-03,  2.7041e-03,  2.7655e-03, -1.7918e-03, -1.0930e-03,\n",
            "        -8.2312e-03, -6.5783e-03, -1.6797e-03,  7.3200e-04,  2.1511e-03,\n",
            "        -1.2896e-03, -9.1906e-04, -4.2071e-03,  8.3823e-04, -2.0109e-03,\n",
            "        -4.5050e-03, -4.9195e-03,  1.3901e-03, -5.7337e-03, -3.3015e-03,\n",
            "         2.7651e-03,  2.6280e-03, -2.8069e-03, -5.7101e-03, -1.5419e-03,\n",
            "         9.7291e-03, -6.4525e-03,  2.9030e-04, -5.9075e-03, -4.2250e-04,\n",
            "         1.9276e-03, -2.2482e-03, -7.0579e-03, -1.7895e-03,  2.2992e-03,\n",
            "         1.4466e-03,  1.5984e-03,  1.0748e-03, -5.6515e-04,  2.8190e-03,\n",
            "         6.5905e-04, -1.7808e-03, -1.2891e-03, -8.5943e-03,  1.1028e-02,\n",
            "         6.7921e-04, -7.7839e-05, -4.9918e-03,  2.5328e-03,  1.4331e-03,\n",
            "         2.9559e-03], device='cuda:0')}, 12: {'momentum_buffer': tensor([[[[ 1.1371e-03, -1.9409e-03,  3.1064e-03],\n",
            "          [-3.1399e-03, -3.3888e-03,  2.4062e-03],\n",
            "          [ 6.8204e-03,  1.4575e-03, -4.4172e-05]],\n",
            "\n",
            "         [[ 2.8718e-04,  2.8389e-03,  2.4139e-03],\n",
            "          [ 3.6772e-04, -6.4686e-04,  3.9363e-04],\n",
            "          [-2.9467e-03,  9.0112e-04, -2.1965e-03]],\n",
            "\n",
            "         [[ 4.5673e-03,  3.2898e-03, -4.6443e-04],\n",
            "          [-3.3419e-04, -1.7564e-03, -2.8401e-05],\n",
            "          [-1.3030e-03, -1.1788e-03,  2.4226e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8550e-03,  3.9228e-03,  3.6116e-03],\n",
            "          [-5.0369e-03, -2.2190e-03,  8.0178e-04],\n",
            "          [ 4.9911e-03, -2.9971e-03,  2.5503e-03]],\n",
            "\n",
            "         [[-5.8160e-03,  3.2424e-04,  1.9383e-03],\n",
            "          [ 8.3411e-04,  1.4518e-03,  4.9111e-03],\n",
            "          [ 7.7669e-03, -3.4091e-04,  4.0852e-05]],\n",
            "\n",
            "         [[ 2.2147e-03,  4.0915e-05,  8.5850e-04],\n",
            "          [ 5.2333e-03,  6.6078e-04,  1.9788e-04],\n",
            "          [ 2.7673e-03,  2.4555e-03,  5.3212e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 8.5018e-03,  2.3372e-03,  4.7501e-03],\n",
            "          [ 8.7430e-04,  4.4308e-04,  1.2790e-02],\n",
            "          [-3.0087e-03,  1.9440e-03,  9.7726e-03]],\n",
            "\n",
            "         [[-4.0114e-04, -1.0213e-03, -5.3988e-04],\n",
            "          [ 2.1656e-03,  1.7893e-03,  2.3809e-03],\n",
            "          [-1.2798e-03, -6.6237e-03, -2.4822e-03]],\n",
            "\n",
            "         [[ 7.7708e-04,  2.2049e-03, -4.2892e-04],\n",
            "          [-2.7415e-04,  4.9930e-03,  3.1178e-03],\n",
            "          [ 2.5252e-03, -2.3809e-03,  2.1498e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.5420e-03, -1.0521e-03,  1.2853e-02],\n",
            "          [ 5.5346e-04,  9.1612e-04,  2.1276e-03],\n",
            "          [-3.2508e-03,  2.0166e-03, -5.1743e-04]],\n",
            "\n",
            "         [[-3.9686e-05, -5.1854e-03,  1.6125e-03],\n",
            "          [ 2.1675e-03, -2.1094e-03, -7.4395e-03],\n",
            "          [ 1.1783e-03,  1.1027e-03, -7.1773e-03]],\n",
            "\n",
            "         [[ 5.1509e-03, -1.8801e-03,  1.4161e-03],\n",
            "          [-5.2649e-03, -2.8952e-03, -7.7985e-04],\n",
            "          [ 1.5101e-03, -2.6332e-03, -8.5565e-04]]],\n",
            "\n",
            "\n",
            "        [[[-2.8220e-03,  3.4905e-04, -1.2449e-03],\n",
            "          [-1.4770e-03,  1.2867e-03,  1.2056e-03],\n",
            "          [-1.3363e-03, -1.7984e-03,  3.2468e-03]],\n",
            "\n",
            "         [[-1.9622e-04,  2.8030e-04, -8.4740e-04],\n",
            "          [-1.2560e-03,  1.4605e-03,  2.8678e-04],\n",
            "          [ 7.5038e-05, -7.0050e-04, -4.0816e-04]],\n",
            "\n",
            "         [[ 1.1068e-04,  1.1563e-03,  1.4852e-04],\n",
            "          [-8.1245e-04,  1.4020e-03,  6.5627e-03],\n",
            "          [-8.5350e-04, -4.5970e-04, -5.4102e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.0885e-03, -8.9084e-03, -3.6419e-04],\n",
            "          [-4.8435e-03, -1.0503e-03,  7.3079e-04],\n",
            "          [-1.4263e-03,  6.7873e-03, -4.3570e-03]],\n",
            "\n",
            "         [[-7.4368e-04, -3.1964e-03,  1.9257e-04],\n",
            "          [ 8.3419e-04, -3.2065e-03,  9.2469e-04],\n",
            "          [ 3.2613e-04,  8.1542e-05, -1.5054e-03]],\n",
            "\n",
            "         [[-4.1664e-04, -2.0292e-03, -4.9858e-03],\n",
            "          [-8.4082e-04, -1.3536e-03, -1.5480e-03],\n",
            "          [-5.9464e-04, -5.8401e-03, -1.9844e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.9142e-03,  3.2709e-03,  8.3086e-03],\n",
            "          [-3.4325e-06, -2.1481e-05,  1.0412e-02],\n",
            "          [-6.3255e-03,  6.0235e-03,  2.0966e-02]],\n",
            "\n",
            "         [[-1.6270e-03, -1.0759e-03,  3.9794e-03],\n",
            "          [ 4.8393e-03,  1.1172e-02,  1.3615e-03],\n",
            "          [ 6.5391e-03,  1.4105e-02,  2.1230e-03]],\n",
            "\n",
            "         [[-6.8316e-04, -3.4341e-03,  9.1275e-04],\n",
            "          [ 8.8993e-04, -2.8234e-03, -1.8788e-04],\n",
            "          [-5.6864e-04,  7.3885e-04, -8.8027e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1512e-02,  8.0838e-03, -3.5718e-04],\n",
            "          [ 6.8588e-03,  9.5576e-03,  4.9980e-03],\n",
            "          [-4.7399e-03,  1.9371e-02,  9.2148e-03]],\n",
            "\n",
            "         [[-6.1027e-04,  1.2202e-02, -1.1548e-04],\n",
            "          [-6.4521e-03,  4.9322e-04,  5.0064e-03],\n",
            "          [ 8.1864e-04,  1.6459e-02,  7.3774e-03]],\n",
            "\n",
            "         [[-1.4977e-03, -4.5124e-03,  6.4577e-04],\n",
            "          [ 4.5330e-04,  1.9937e-05,  1.7014e-03],\n",
            "          [-3.4224e-03,  1.8814e-03,  1.1969e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1297e-03,  3.5433e-03,  3.1864e-03],\n",
            "          [ 1.7477e-03,  5.1222e-03,  5.3160e-03],\n",
            "          [ 8.2473e-04, -6.8794e-04, -8.7959e-03]],\n",
            "\n",
            "         [[ 8.9499e-04, -1.0535e-03,  1.2606e-03],\n",
            "          [-1.0763e-03,  1.4703e-03,  1.3779e-03],\n",
            "          [ 2.2112e-03, -1.9729e-04, -2.2138e-03]],\n",
            "\n",
            "         [[-5.6127e-04, -1.7642e-03,  3.4683e-04],\n",
            "          [-1.1756e-04, -1.8683e-03, -7.7021e-04],\n",
            "          [-9.0747e-04,  4.0773e-04,  2.9952e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.3768e-05,  6.1318e-03,  3.1585e-03],\n",
            "          [ 1.9935e-03,  4.7964e-03,  3.3809e-03],\n",
            "          [-9.0336e-04, -1.0624e-03, -4.3096e-04]],\n",
            "\n",
            "         [[ 3.2326e-04,  6.3006e-04, -2.7293e-04],\n",
            "          [ 2.6108e-04,  1.3427e-03, -1.8836e-03],\n",
            "          [ 3.2733e-03,  1.0671e-03,  2.3913e-04]],\n",
            "\n",
            "         [[ 2.8083e-03,  3.7895e-03,  9.1990e-04],\n",
            "          [-1.4517e-03, -1.2798e-04,  1.7566e-04],\n",
            "          [ 8.9168e-04,  2.4725e-03, -3.1506e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.1273e-03,  4.7891e-03, -2.4161e-03],\n",
            "          [-8.4840e-04, -6.2339e-04, -4.7650e-04],\n",
            "          [-1.9555e-04, -1.2277e-03,  1.8230e-03]],\n",
            "\n",
            "         [[ 1.4534e-03,  1.3448e-04,  1.2052e-03],\n",
            "          [ 1.0407e-03, -1.7203e-03, -9.6087e-05],\n",
            "          [ 6.2317e-03,  1.3044e-03,  3.0315e-03]],\n",
            "\n",
            "         [[ 1.8265e-03, -8.4126e-04,  6.1692e-04],\n",
            "          [-4.2556e-04, -1.4792e-03,  3.0761e-04],\n",
            "          [ 2.3234e-03, -4.8003e-04,  2.1171e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.3567e-04, -3.0166e-04,  1.0097e-02],\n",
            "          [ 2.4963e-04, -1.3904e-03,  4.9639e-03],\n",
            "          [ 5.5457e-03,  8.0440e-03,  3.5798e-03]],\n",
            "\n",
            "         [[ 2.3012e-03,  1.7686e-03,  2.6408e-03],\n",
            "          [-8.7561e-04,  2.4187e-03,  4.3802e-03],\n",
            "          [ 7.0211e-03,  4.3195e-03, -6.9648e-04]],\n",
            "\n",
            "         [[ 6.4761e-03,  2.1339e-03,  3.0477e-03],\n",
            "          [ 4.0220e-03, -3.1605e-04, -1.3132e-03],\n",
            "          [ 5.5283e-03, -3.9033e-03, -2.4999e-05]]]], device='cuda:0')}, 13: {'momentum_buffer': tensor([-2.0355e-03, -8.4102e-04,  2.5929e-04,  2.2423e-03, -6.9482e-04,\n",
            "         2.7751e-03,  1.6165e-03, -6.9853e-03,  7.2401e-04,  1.1767e-03,\n",
            "        -1.5791e-03, -1.9177e-03,  2.5232e-03,  6.2688e-03, -1.7123e-04,\n",
            "         1.7612e-03, -2.5143e-03, -6.0040e-04, -3.3247e-03,  2.3195e-03,\n",
            "        -9.1656e-04,  1.4601e-03,  4.1270e-04,  4.8418e-04, -9.7353e-04,\n",
            "         2.9379e-04, -9.1792e-05, -2.1639e-04,  2.8778e-03,  3.0719e-03,\n",
            "        -1.1827e-03,  8.3082e-04,  2.4167e-03, -1.2420e-03,  4.0683e-04,\n",
            "         3.7193e-03,  3.7818e-03,  2.0317e-03,  8.0866e-04, -3.0643e-03,\n",
            "         4.2383e-03,  5.3248e-05,  6.8817e-03,  2.7651e-03,  4.1712e-03,\n",
            "         3.4929e-03, -2.2045e-03,  1.4214e-03, -2.1897e-03, -1.8275e-03,\n",
            "         1.5088e-04, -7.7479e-04, -8.6650e-04,  2.6773e-03,  7.8646e-06,\n",
            "         2.2577e-03,  1.6114e-03, -1.4877e-03, -1.0260e-03, -9.3863e-04,\n",
            "         2.3905e-03,  2.4565e-03, -1.8303e-03,  6.6393e-03,  2.5117e-03,\n",
            "         8.0338e-04,  1.9218e-03,  5.8119e-03,  8.9302e-04,  2.2082e-03,\n",
            "        -1.6030e-03,  5.1209e-04,  4.3740e-03,  1.3415e-03, -2.3830e-03,\n",
            "        -2.8839e-03, -3.4227e-03,  6.3328e-04,  2.3472e-03, -1.5511e-03,\n",
            "        -4.0122e-04, -2.4838e-03, -1.3568e-03,  1.1860e-03,  7.7417e-04,\n",
            "        -1.4330e-03, -3.7198e-03, -1.0166e-04, -2.8125e-03,  7.9770e-04,\n",
            "        -7.7089e-04,  4.4058e-03, -1.0291e-03, -2.3805e-03,  2.4873e-03,\n",
            "         1.8083e-03, -2.2942e-03, -1.9387e-03,  4.0577e-04,  2.6600e-04,\n",
            "        -1.3093e-03,  1.4418e-03, -3.0328e-03, -2.0710e-03, -2.9708e-04,\n",
            "        -1.9125e-03, -1.6005e-03,  5.7178e-03, -2.0814e-03, -5.6594e-04,\n",
            "        -1.2462e-03,  7.9288e-05,  2.1101e-03,  6.5427e-04, -1.0989e-03,\n",
            "        -1.7458e-03,  3.6545e-03, -9.0239e-04, -3.2849e-03,  8.9785e-04,\n",
            "         1.0570e-03,  2.9532e-03, -1.1908e-03,  4.2563e-03, -5.0088e-03,\n",
            "         1.4220e-03,  1.9843e-04,  9.1596e-04,  3.4045e-03, -1.9165e-03,\n",
            "        -5.7494e-03,  2.7117e-03,  4.1694e-04, -5.9406e-03,  1.3275e-03,\n",
            "        -1.1518e-03,  1.8536e-03, -1.6282e-03, -2.8537e-03, -2.0044e-04,\n",
            "         5.5336e-04,  6.8783e-04, -4.7410e-04, -1.5935e-03, -3.8142e-03,\n",
            "        -2.7726e-04,  1.7873e-03, -3.0346e-03,  3.5072e-03, -2.0927e-03,\n",
            "         1.1540e-03, -2.0903e-05, -8.2770e-04, -2.3754e-03, -4.7531e-04,\n",
            "        -3.4523e-04,  5.6376e-03,  9.8389e-04,  1.9391e-03, -2.7757e-03,\n",
            "         6.4017e-04, -1.8163e-04,  4.5779e-04, -5.7798e-04, -6.0115e-03,\n",
            "        -2.6041e-03, -1.7671e-04, -1.1712e-04,  2.7903e-04, -1.0756e-03,\n",
            "        -2.4040e-04,  1.0592e-03, -2.2186e-03, -2.8409e-03, -9.3105e-04,\n",
            "         1.6611e-03,  2.5884e-03,  1.2881e-03,  2.5966e-03, -3.6960e-03,\n",
            "         2.5511e-03, -2.6015e-03, -1.9376e-03, -6.3789e-03,  1.9717e-06,\n",
            "         3.9800e-03,  2.9251e-03, -4.2514e-03,  1.8757e-03,  2.2908e-03,\n",
            "        -2.0675e-03, -1.1118e-03,  1.3981e-05, -1.8735e-03, -3.4316e-03,\n",
            "         1.1765e-03,  1.1195e-03, -1.0942e-03,  1.4076e-03,  3.9758e-04,\n",
            "         1.2380e-03,  1.3726e-03, -1.2582e-04, -7.8984e-04, -6.5157e-04,\n",
            "        -1.2787e-03,  3.7950e-03, -1.1206e-03, -4.2959e-03, -6.2609e-05,\n",
            "         3.4895e-03, -3.4756e-04, -7.7208e-03, -2.3208e-03,  2.8844e-03,\n",
            "        -4.0053e-03, -9.9010e-04, -1.7165e-03,  2.7180e-04,  3.2402e-03,\n",
            "        -6.2852e-04, -2.4123e-03,  6.1222e-04,  6.0760e-03, -2.0455e-03,\n",
            "        -2.4462e-03,  3.6734e-04, -2.5849e-03, -2.3927e-03, -3.3931e-03,\n",
            "        -7.9324e-04,  5.6018e-04, -2.4569e-03, -2.5142e-03,  4.8447e-03,\n",
            "         5.1044e-03,  2.5320e-04, -1.8632e-03, -7.2880e-03, -1.6338e-03,\n",
            "         6.2260e-03, -1.0065e-03, -7.4501e-03, -1.0608e-03,  1.5646e-03,\n",
            "        -1.4009e-03,  2.9220e-03,  4.1553e-04, -8.0404e-03, -4.0313e-03,\n",
            "         2.1271e-03,  2.9395e-03, -1.6112e-03,  1.4827e-03, -1.4850e-04,\n",
            "         1.0754e-03,  1.5410e-03, -5.6409e-04,  1.6782e-03, -4.1333e-03,\n",
            "         2.0266e-04, -3.9514e-03, -5.6237e-05, -5.1065e-03, -1.3599e-04,\n",
            "        -2.1790e-03, -2.5273e-03, -1.2444e-03,  1.3137e-03,  4.8460e-03,\n",
            "         1.8769e-04, -1.0823e-03,  9.3969e-04,  1.6045e-03,  4.1245e-04,\n",
            "         2.1763e-03,  1.2880e-03, -2.1164e-04,  8.4631e-04,  7.2082e-04,\n",
            "        -1.2620e-03, -4.1682e-03, -4.8006e-04,  4.7048e-03,  6.5913e-04,\n",
            "        -3.1478e-03, -3.6157e-04, -1.7212e-03,  5.8606e-04,  4.5378e-03,\n",
            "        -9.7188e-04,  1.2255e-03, -3.5727e-04,  6.7191e-04,  4.2522e-03,\n",
            "        -6.6019e-04, -1.2360e-04, -1.0587e-03, -3.9630e-03, -3.4462e-03,\n",
            "         1.8272e-03, -1.3266e-03,  9.0791e-05,  1.6412e-04,  7.1660e-04,\n",
            "         3.8673e-03, -8.7729e-04, -1.0989e-03,  1.7788e-03,  2.6906e-03,\n",
            "         2.2765e-03,  4.4709e-03, -7.8452e-04, -7.4277e-04, -1.1700e-03,\n",
            "         8.2203e-04, -1.7681e-03, -3.5094e-03,  8.8795e-04, -1.5742e-04,\n",
            "         9.5672e-04, -2.4233e-03, -5.5207e-03, -9.0899e-04,  2.4894e-03,\n",
            "        -2.4099e-03,  1.0021e-03,  1.3441e-03,  8.5290e-04,  1.9872e-03,\n",
            "         1.1567e-03,  4.0336e-03,  4.3191e-03, -8.2482e-04,  2.0795e-03,\n",
            "        -2.2428e-04, -5.9713e-04, -3.3671e-03, -2.4897e-03,  3.6602e-03,\n",
            "        -2.3408e-03,  1.3816e-03, -5.9184e-04,  2.8130e-03, -8.1818e-04,\n",
            "        -4.0774e-03,  3.7213e-03,  8.9935e-04,  2.2113e-03, -3.1339e-04,\n",
            "        -1.0039e-02,  7.7486e-03,  4.0638e-03,  1.7291e-03,  9.8880e-06,\n",
            "         1.2711e-03,  1.4473e-03,  4.2013e-04, -1.0007e-03,  9.2995e-04,\n",
            "        -3.6827e-04,  1.3391e-04, -4.9189e-04,  5.4373e-04,  3.8094e-03,\n",
            "        -6.1834e-04, -1.3924e-03, -2.2428e-03, -5.9918e-03,  2.0360e-03,\n",
            "        -2.1748e-03,  4.8829e-03, -4.3433e-03, -5.6297e-03,  9.1076e-05,\n",
            "         8.2151e-04, -1.0940e-03,  3.4638e-03, -1.0150e-04,  5.5147e-04,\n",
            "        -2.4479e-03,  7.1833e-03, -1.4808e-03,  1.0436e-03, -1.7944e-03,\n",
            "        -1.4216e-03, -4.7109e-03,  3.4507e-03, -2.7288e-03, -1.5779e-03,\n",
            "         1.0315e-03, -1.3980e-03, -4.6414e-04, -7.2228e-04,  1.7798e-03,\n",
            "         1.2874e-03,  8.2622e-04, -5.6537e-05,  5.4918e-04,  5.7945e-04,\n",
            "         6.6900e-04,  5.1552e-03, -1.3210e-03,  1.1493e-05, -2.4213e-03,\n",
            "        -2.6674e-03, -1.9846e-03, -2.3088e-03, -4.3793e-04,  6.8170e-04,\n",
            "         2.3040e-04, -2.5749e-03, -3.1292e-03, -7.8955e-04, -1.0363e-03,\n",
            "        -3.7968e-04, -5.9493e-04,  7.4362e-03,  1.2276e-03, -1.1576e-03,\n",
            "        -1.0011e-03,  2.9446e-03, -1.6853e-03,  1.2314e-03,  5.6636e-04,\n",
            "        -3.6463e-03, -1.7403e-03, -3.4850e-03,  8.8679e-04, -3.6014e-03,\n",
            "        -1.7829e-03,  1.4244e-03,  3.1344e-03, -1.5293e-03,  2.7444e-03,\n",
            "        -2.2018e-04,  1.7582e-04, -3.9337e-03,  9.6719e-04, -1.6252e-03,\n",
            "        -3.0035e-05, -1.9274e-04,  5.3795e-04, -1.2870e-03,  2.7784e-03,\n",
            "         1.2324e-03, -1.9118e-03,  4.2324e-03,  2.3982e-03, -1.6699e-03,\n",
            "         7.3261e-04,  2.4759e-03, -9.4871e-04,  4.5578e-03,  1.6149e-04,\n",
            "         2.3701e-03,  1.1772e-03,  1.8932e-03, -2.0442e-03, -5.9845e-03,\n",
            "         9.8008e-03, -4.8962e-04, -3.0349e-03, -3.4905e-04, -1.0195e-03,\n",
            "        -6.9042e-03,  4.9533e-03,  3.5033e-03, -1.5657e-03, -4.3580e-03,\n",
            "        -4.0375e-03,  2.8961e-03, -2.7357e-04,  2.1802e-03, -5.3067e-04,\n",
            "         1.2046e-03, -1.1010e-04, -2.7035e-03,  3.4171e-03, -1.6494e-03,\n",
            "         1.6036e-03,  3.6566e-03,  6.4963e-03,  2.0857e-03,  4.2151e-05,\n",
            "         9.4922e-04,  1.3498e-03, -1.9306e-03,  2.0311e-04, -2.0006e-03,\n",
            "         5.1302e-04, -2.9229e-03, -2.4136e-03, -3.9479e-03, -1.4937e-03,\n",
            "         1.3774e-04,  4.7427e-04,  3.7592e-03,  2.8527e-03, -3.1541e-03,\n",
            "         3.5596e-03, -6.2557e-03, -1.6390e-03, -2.7396e-03, -2.5280e-03,\n",
            "         3.7885e-03,  1.1591e-03,  5.1947e-05,  9.6214e-04, -1.6936e-03,\n",
            "         2.9820e-03,  2.7953e-03], device='cuda:0')}, 14: {'momentum_buffer': tensor([[[[-4.7103e-03, -9.5869e-03, -3.8317e-03],\n",
            "          [ 3.8467e-05, -1.8142e-03,  1.1961e-03],\n",
            "          [ 1.0824e-03, -3.1684e-04,  1.3214e-03]],\n",
            "\n",
            "         [[-2.1723e-03, -1.0060e-03, -2.4817e-03],\n",
            "          [ 3.0318e-03,  3.8945e-03,  9.1836e-04],\n",
            "          [-4.1751e-03,  1.7106e-04,  1.3551e-03]],\n",
            "\n",
            "         [[-9.0370e-04, -4.7259e-03, -2.0395e-03],\n",
            "          [-1.1390e-04, -6.8396e-04,  8.7386e-05],\n",
            "          [ 2.5877e-04,  4.7613e-04,  1.1809e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.3495e-03,  2.7033e-03, -5.6813e-03],\n",
            "          [-2.0355e-02,  1.6868e-03,  4.2176e-03],\n",
            "          [-2.6876e-03,  3.8609e-03,  1.8617e-03]],\n",
            "\n",
            "         [[-2.7918e-04, -1.8178e-03, -1.1175e-03],\n",
            "          [ 1.6584e-04,  4.6507e-04, -1.1297e-03],\n",
            "          [-1.0322e-03, -7.9438e-04,  5.5124e-04]],\n",
            "\n",
            "         [[-9.6186e-03, -8.4044e-03, -2.0339e-03],\n",
            "          [-1.6879e-04,  1.0509e-03,  1.5002e-03],\n",
            "          [ 4.6619e-04, -1.0878e-03, -2.2383e-05]]],\n",
            "\n",
            "\n",
            "        [[[-4.9820e-03, -2.3364e-03,  4.7833e-03],\n",
            "          [-5.7808e-03, -1.3122e-04, -7.5960e-04],\n",
            "          [-1.3031e-03, -6.6060e-03, -2.9815e-03]],\n",
            "\n",
            "         [[ 1.2008e-04, -3.7494e-03,  2.9477e-03],\n",
            "          [-1.4961e-04, -7.2273e-03,  6.5156e-04],\n",
            "          [ 5.5237e-04, -2.0597e-03,  3.0957e-03]],\n",
            "\n",
            "         [[-2.6805e-03,  7.1284e-04, -6.0766e-06],\n",
            "          [ 2.0329e-03,  1.6448e-03,  4.4612e-04],\n",
            "          [-3.0239e-03,  9.7889e-04,  5.9328e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.3841e-03, -4.7881e-03, -7.5363e-03],\n",
            "          [-6.0855e-03, -3.3437e-03,  6.4010e-03],\n",
            "          [ 2.6207e-03,  1.7233e-03, -6.4215e-03]],\n",
            "\n",
            "         [[ 1.2779e-03, -2.0109e-04, -3.5225e-03],\n",
            "          [ 8.3553e-03, -4.9260e-03, -3.4919e-03],\n",
            "          [ 1.3588e-03,  3.4269e-04,  7.6750e-03]],\n",
            "\n",
            "         [[-7.4438e-04,  2.4442e-04, -1.0417e-02],\n",
            "          [-9.6244e-03,  1.7117e-03, -5.8237e-03],\n",
            "          [-2.1491e-03, -9.4422e-05, -4.9748e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5345e-03,  4.7832e-05,  2.4087e-05],\n",
            "          [-3.1015e-03,  1.2776e-03, -1.2819e-04],\n",
            "          [ 4.9612e-04,  1.2665e-03,  2.3359e-03]],\n",
            "\n",
            "         [[ 8.7198e-04,  2.6116e-04,  4.5630e-04],\n",
            "          [-1.5218e-03, -5.7869e-03, -2.5957e-04],\n",
            "          [-4.0395e-04,  3.5007e-03,  1.7958e-03]],\n",
            "\n",
            "         [[ 1.1145e-03,  7.6070e-04,  3.6739e-04],\n",
            "          [-2.5638e-03,  3.8507e-04,  2.0625e-04],\n",
            "          [ 5.8437e-04,  1.2218e-03,  3.0563e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.7983e-04, -1.9858e-03,  6.7529e-04],\n",
            "          [ 3.8908e-03, -5.1658e-04,  1.0282e-04],\n",
            "          [ 7.8551e-03,  6.2185e-03,  6.5334e-04]],\n",
            "\n",
            "         [[ 1.1871e-03, -2.4458e-04, -1.0062e-04],\n",
            "          [ 1.2225e-04, -4.4205e-03, -1.2887e-03],\n",
            "          [ 5.0251e-04,  8.4687e-04,  1.2089e-04]],\n",
            "\n",
            "         [[-4.8269e-06,  1.7933e-03,  2.8179e-03],\n",
            "          [ 1.3144e-04,  1.0032e-03, -1.6439e-03],\n",
            "          [-2.6288e-03, -1.7970e-03, -5.1368e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-5.8477e-03,  3.7074e-03, -2.7002e-03],\n",
            "          [ 8.7702e-04, -1.7159e-03, -2.3950e-03],\n",
            "          [ 8.6872e-04, -2.7441e-03, -1.2655e-04]],\n",
            "\n",
            "         [[-1.7341e-03, -3.1938e-03, -3.6392e-03],\n",
            "          [-2.4237e-03, -2.4879e-03, -1.4483e-03],\n",
            "          [ 3.7436e-03,  5.3395e-03, -8.7581e-04]],\n",
            "\n",
            "         [[ 1.1017e-03, -1.1838e-03, -6.7005e-04],\n",
            "          [ 5.5660e-04, -3.8932e-03, -9.3875e-04],\n",
            "          [ 3.0461e-04, -7.0038e-05,  1.2400e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.3237e-03,  1.0157e-02, -8.7618e-04],\n",
            "          [-2.0797e-04, -7.8386e-04, -5.7969e-04],\n",
            "          [ 1.3439e-03,  4.5712e-04,  8.3345e-04]],\n",
            "\n",
            "         [[ 2.6355e-04, -2.3899e-03, -2.4996e-03],\n",
            "          [ 6.0547e-04,  1.1583e-03,  1.0236e-04],\n",
            "          [ 9.7323e-04,  2.6774e-03, -3.2821e-04]],\n",
            "\n",
            "         [[ 2.6174e-03,  8.0525e-05, -2.8244e-04],\n",
            "          [-1.2646e-03, -3.3978e-05,  2.9909e-04],\n",
            "          [ 2.4048e-05,  5.5319e-04,  1.3395e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1930e-04,  2.5196e-03,  5.4320e-04],\n",
            "          [ 9.2911e-04,  6.7454e-04, -1.5112e-04],\n",
            "          [-5.7888e-04, -1.3414e-04,  1.2513e-03]],\n",
            "\n",
            "         [[-9.2355e-05,  1.5130e-04,  3.0863e-04],\n",
            "          [-9.7834e-04,  2.3292e-03, -1.0889e-02],\n",
            "          [ 1.3246e-04, -6.4884e-03,  8.6396e-04]],\n",
            "\n",
            "         [[-3.5859e-04,  1.2215e-03,  2.2095e-03],\n",
            "          [ 6.4248e-03,  2.3142e-03,  6.3503e-03],\n",
            "          [ 9.2286e-03, -2.3309e-03,  7.1674e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.8891e-03,  8.6974e-03,  1.1584e-02],\n",
            "          [ 1.1195e-02, -4.2758e-03,  1.4319e-02],\n",
            "          [ 5.0305e-03,  6.0787e-03,  1.5964e-03]],\n",
            "\n",
            "         [[-6.0327e-04, -2.5194e-03,  4.1030e-03],\n",
            "          [ 1.2896e-04, -1.4729e-03,  1.1865e-03],\n",
            "          [ 7.9918e-05,  1.1167e-03,  1.9665e-03]],\n",
            "\n",
            "         [[ 5.3648e-04, -1.1933e-04,  4.3071e-03],\n",
            "          [ 3.7670e-04, -1.0115e-03, -1.1201e-04],\n",
            "          [ 3.5789e-06, -1.3972e-03,  6.8081e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9380e-04,  9.4700e-04,  4.0633e-03],\n",
            "          [ 2.5080e-03,  2.8046e-03,  1.3217e-03],\n",
            "          [ 5.2743e-04, -1.8932e-03,  3.6008e-03]],\n",
            "\n",
            "         [[ 3.4661e-03,  5.8111e-04,  6.4754e-03],\n",
            "          [-1.6341e-03, -1.1162e-03,  6.5744e-03],\n",
            "          [-4.8443e-03, -8.8925e-03,  2.5971e-04]],\n",
            "\n",
            "         [[-6.4281e-04, -2.9832e-03, -6.1593e-04],\n",
            "          [-2.8187e-03, -1.9700e-03,  2.8320e-04],\n",
            "          [ 5.9404e-03, -7.0426e-04, -1.6452e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.5247e-04, -8.5410e-04,  6.9101e-03],\n",
            "          [ 5.2316e-03,  3.7310e-03, -5.8008e-03],\n",
            "          [-1.1726e-03,  3.5764e-03,  8.4184e-03]],\n",
            "\n",
            "         [[ 4.2565e-03,  4.6119e-03,  4.3960e-03],\n",
            "          [ 2.5540e-03,  3.7375e-03,  4.0377e-03],\n",
            "          [-2.5175e-03,  6.9108e-04, -2.6667e-03]],\n",
            "\n",
            "         [[ 4.7912e-04,  7.3699e-03, -7.1281e-03],\n",
            "          [ 1.8305e-03,  5.5362e-03, -3.0096e-03],\n",
            "          [-7.8719e-04, -2.4989e-03,  6.9677e-03]]]], device='cuda:0')}, 15: {'momentum_buffer': tensor([-1.4864e-03, -7.7490e-04, -8.9639e-04, -4.1518e-04, -2.6049e-03,\n",
            "         1.8497e-04,  1.0431e-03,  6.0395e-03, -3.1926e-03, -2.7090e-03,\n",
            "        -2.4420e-03,  1.5520e-04,  1.8498e-03, -2.5469e-03, -2.8765e-03,\n",
            "         7.1235e-04, -6.2294e-04, -3.0333e-03, -1.5555e-03,  1.5835e-03,\n",
            "         8.7727e-04,  4.7358e-03,  3.1712e-03, -2.5987e-03,  1.6523e-03,\n",
            "        -8.6754e-03,  2.1166e-03,  5.5558e-03, -2.5385e-04, -6.2250e-03,\n",
            "        -3.8903e-03,  8.1096e-04,  1.7315e-03, -2.7652e-03,  7.2220e-04,\n",
            "        -1.3878e-03, -9.0909e-04,  1.3420e-03,  2.5282e-03, -3.6583e-03,\n",
            "        -3.3581e-03, -2.9597e-04,  1.0596e-03, -2.5838e-03, -7.7088e-05,\n",
            "        -1.3642e-03,  4.1807e-03,  4.6036e-03,  1.0639e-04, -2.3188e-03,\n",
            "         2.1424e-03, -2.8486e-04,  4.0151e-03,  8.3129e-03, -4.8881e-03,\n",
            "         5.0929e-03,  3.5452e-03,  4.9904e-05,  3.8047e-03, -3.8318e-03,\n",
            "        -3.4489e-03,  4.2279e-03,  1.5622e-02, -3.1833e-03,  6.7214e-03,\n",
            "         7.6499e-03, -3.1224e-04,  1.7719e-03,  4.4021e-03,  1.8733e-03,\n",
            "        -3.2074e-03,  8.8376e-04, -2.7976e-03,  7.2204e-03,  9.0129e-03,\n",
            "        -5.1174e-03, -1.6936e-03,  3.3104e-03, -4.6000e-03,  5.1616e-03,\n",
            "         2.0878e-03,  3.1160e-03, -7.0580e-03, -4.4692e-03, -3.7003e-03,\n",
            "        -1.5122e-03, -1.0177e-02,  1.5248e-03, -1.0729e-03, -7.7656e-04,\n",
            "         8.4708e-03, -2.3832e-03,  8.4636e-03, -1.0905e-03,  2.8198e-03,\n",
            "        -3.5136e-04, -4.4807e-03,  6.2874e-03,  4.4828e-03,  1.1367e-03,\n",
            "        -9.2940e-03,  4.8511e-04, -2.5884e-03, -4.3737e-04,  3.2687e-04,\n",
            "         6.6333e-04, -2.0022e-03, -1.3667e-03,  7.9506e-03,  2.8277e-04,\n",
            "        -2.5546e-03,  2.3605e-03, -8.6411e-03,  6.7414e-03, -5.6342e-03,\n",
            "        -1.4881e-03, -2.4598e-03, -5.3291e-03,  2.2176e-03,  3.3620e-03,\n",
            "         9.0203e-04,  7.6126e-03,  3.2882e-03, -2.2817e-03, -8.6179e-03,\n",
            "         5.2629e-03, -2.4790e-03, -9.6567e-03,  3.2009e-03,  4.3678e-04,\n",
            "        -1.4924e-03, -4.0973e-03,  3.8571e-03, -1.0706e-03, -6.8181e-04,\n",
            "         4.8430e-03,  3.5968e-04,  3.8698e-03, -8.1643e-05,  9.9830e-04,\n",
            "         9.5316e-03,  4.3093e-03, -3.9351e-03, -1.4923e-03,  8.5218e-04,\n",
            "        -1.2215e-03,  4.1747e-03,  1.0026e-02, -3.3909e-03, -2.1410e-03,\n",
            "         1.8217e-03,  4.3033e-03,  1.8655e-03, -1.8715e-03,  4.7933e-04,\n",
            "        -3.1908e-03, -5.6614e-03,  8.1044e-03, -1.0780e-03, -1.1727e-03,\n",
            "        -2.7029e-03,  2.3114e-03, -3.1947e-04,  3.7275e-03,  1.1754e-03,\n",
            "         5.6280e-03, -7.5775e-03, -1.9723e-03,  2.9685e-03, -4.7667e-03,\n",
            "        -7.5760e-03,  4.1381e-04, -2.4930e-03, -7.4337e-04, -9.1492e-04,\n",
            "         1.9054e-03,  6.0523e-04, -1.3152e-03, -1.5174e-03, -1.5421e-03,\n",
            "         2.5043e-03,  3.4186e-03, -4.6510e-03,  1.8310e-03,  2.9880e-03,\n",
            "        -1.1667e-03,  3.5701e-03,  2.7020e-03, -3.6448e-03, -1.8720e-03,\n",
            "        -2.1257e-03,  2.8890e-03,  3.3474e-03, -1.0065e-03, -4.2106e-03,\n",
            "        -8.7080e-03, -3.2261e-03, -1.4441e-03,  1.3085e-03, -3.0203e-03,\n",
            "        -4.1781e-03,  5.8754e-05, -3.3087e-03, -1.4132e-03, -4.7484e-03,\n",
            "        -1.9363e-03,  7.4938e-03,  2.6027e-03, -6.4804e-04,  1.8077e-03,\n",
            "         2.6955e-03,  1.0778e-05, -3.0124e-03, -1.8411e-03,  1.1452e-03,\n",
            "        -5.6216e-03, -4.9942e-03,  6.9678e-04,  4.9591e-03, -4.8458e-03,\n",
            "        -1.3760e-03,  1.5510e-03, -5.1921e-03,  4.1110e-03, -7.2571e-04,\n",
            "         7.3561e-04,  1.8044e-04,  4.6374e-04,  2.4570e-03,  1.1857e-03,\n",
            "        -6.3569e-03,  6.4862e-03,  2.0931e-03,  4.8392e-04, -8.5023e-04,\n",
            "         2.1888e-03, -2.1290e-03,  3.8130e-03, -3.2990e-03, -3.3921e-03,\n",
            "         2.0190e-04, -4.0939e-03,  3.1150e-05, -1.9725e-03,  4.3781e-03,\n",
            "        -6.2479e-03, -1.4211e-04, -7.3503e-05,  3.2535e-04, -4.5792e-03,\n",
            "         1.6086e-03,  7.5406e-06,  1.5665e-03, -1.0164e-03,  9.8731e-03,\n",
            "        -5.7426e-03,  1.5155e-03,  5.6153e-03,  5.3482e-03, -5.8695e-03,\n",
            "        -2.9652e-04, -1.7208e-03,  2.4830e-03,  2.4542e-03,  3.2870e-03,\n",
            "         7.4795e-03, -6.3960e-03, -3.0798e-03, -6.4347e-04,  1.6359e-03,\n",
            "         3.9360e-03,  3.6982e-03, -5.3176e-03,  6.4075e-03,  6.3833e-03,\n",
            "         4.1845e-03, -4.7100e-03, -1.1054e-02,  6.6103e-03,  1.4349e-03,\n",
            "         1.7433e-03,  3.2144e-04, -3.3985e-04, -2.4064e-06,  3.0744e-03,\n",
            "        -7.7145e-03, -1.1489e-03, -2.5081e-03, -2.8876e-03,  1.2732e-03,\n",
            "         2.6076e-03,  5.5094e-03,  2.1429e-03,  5.5478e-03, -4.9866e-03,\n",
            "        -2.3715e-03, -9.0330e-03, -8.0862e-03,  1.1127e-03, -1.2618e-03,\n",
            "        -3.8864e-03, -6.2574e-03, -9.5205e-04, -2.0314e-04, -1.6504e-03,\n",
            "         4.4323e-03,  9.7255e-04, -9.6750e-04,  3.4340e-03,  5.4783e-03,\n",
            "         3.0485e-04,  7.5485e-03,  2.1477e-03, -6.4317e-03, -1.2718e-03,\n",
            "         1.0574e-03, -1.2839e-02,  1.1916e-02, -1.8845e-03, -9.9192e-03,\n",
            "         3.3325e-03,  5.4246e-03, -5.1062e-04, -4.1650e-03, -4.8483e-04,\n",
            "        -2.1343e-03, -6.0846e-04,  3.2460e-03, -3.5916e-03, -1.1181e-03,\n",
            "        -2.6604e-03, -3.7903e-03,  4.3345e-03,  5.6560e-03,  8.0343e-04,\n",
            "         9.7451e-04, -8.5526e-04,  1.4641e-03, -8.1444e-04,  5.9418e-03,\n",
            "        -6.1483e-04,  5.9206e-04, -2.9691e-03, -2.2896e-04,  5.3395e-04,\n",
            "        -2.1075e-03, -5.8544e-03,  2.1145e-03,  8.1231e-04,  2.0863e-03,\n",
            "        -2.4402e-03, -6.2561e-04, -1.0164e-04,  2.1823e-03,  1.5817e-03,\n",
            "         4.5654e-03, -8.1257e-04,  5.4208e-03,  1.6686e-03, -2.2980e-03,\n",
            "        -3.0983e-03,  2.2466e-03, -3.4013e-03,  1.5159e-03, -8.8838e-04,\n",
            "         6.9142e-03, -4.1465e-04, -1.3854e-03, -2.4411e-04, -4.0682e-03,\n",
            "         1.2010e-03, -4.2507e-03, -1.4259e-03,  5.6424e-03,  5.0557e-04,\n",
            "        -1.1642e-03,  5.9565e-04, -1.1111e-03, -1.1280e-03, -1.5304e-04,\n",
            "         1.8837e-03, -7.2262e-03, -3.8199e-03,  4.9351e-03, -5.3946e-03,\n",
            "         3.7619e-03, -2.5024e-04, -1.9735e-03,  5.6713e-03, -3.2729e-03,\n",
            "         3.6152e-03, -8.4654e-06, -6.3246e-03,  2.2280e-04, -1.5282e-03,\n",
            "        -1.9695e-03, -2.8257e-03,  1.0032e-03, -5.5086e-04, -2.5889e-03,\n",
            "        -4.5980e-03,  2.4005e-03, -3.9810e-03,  5.0005e-04,  7.5041e-04,\n",
            "        -5.1652e-04, -4.0765e-03, -8.0615e-03, -1.5653e-03, -1.3528e-02,\n",
            "         2.1526e-03, -6.1533e-03,  5.2053e-03, -1.9930e-03,  7.2291e-04,\n",
            "         4.3699e-03,  1.6610e-04, -1.0331e-03,  3.3290e-03,  1.5371e-03,\n",
            "         1.7774e-03, -7.9034e-03,  4.5144e-03,  1.9024e-03,  9.4067e-04,\n",
            "         6.5016e-03, -4.3949e-03,  3.5038e-03,  5.4293e-03,  3.1588e-04,\n",
            "         1.5157e-03, -5.5066e-03,  4.3891e-04, -3.5752e-03,  4.2407e-03,\n",
            "         3.6255e-03, -6.1400e-04, -1.0687e-03,  3.4018e-03,  6.1431e-04,\n",
            "         6.3424e-04, -1.1133e-04, -6.1035e-03, -3.9002e-04,  1.7175e-03,\n",
            "        -2.3015e-04, -1.3339e-03, -4.7053e-03, -3.5760e-03, -3.5215e-03,\n",
            "        -2.7652e-03,  6.3337e-04, -1.0389e-03, -5.0974e-03, -9.3450e-03,\n",
            "        -1.6700e-03,  5.1730e-03, -1.9025e-03,  2.2777e-03, -3.2994e-03,\n",
            "        -2.6395e-03, -3.6102e-03, -6.8537e-03,  2.7141e-03, -1.6706e-03,\n",
            "        -4.8021e-03, -8.3216e-04, -9.2490e-03, -1.8457e-03,  8.8321e-04,\n",
            "        -8.5654e-03, -3.1062e-04, -4.8479e-03,  4.3249e-03,  3.2918e-03,\n",
            "         1.3972e-04,  1.9015e-03,  3.4677e-03,  9.2268e-03,  3.4490e-03,\n",
            "         2.7282e-03,  3.4437e-03, -4.0727e-03,  3.3148e-03, -3.7316e-03,\n",
            "        -1.6144e-02,  9.7474e-04, -1.5648e-03, -6.4036e-03,  6.0580e-03,\n",
            "        -1.4073e-03, -4.2621e-03,  2.9443e-03,  2.7315e-03,  6.4473e-04,\n",
            "         5.4484e-03,  6.7503e-04, -7.0582e-03, -3.4785e-04,  2.8229e-03,\n",
            "         8.1455e-03, -7.3304e-05,  6.1287e-04,  2.4190e-05, -3.9421e-03,\n",
            "        -1.5161e-03,  1.2113e-03,  1.6725e-03,  1.3300e-03,  3.5835e-03,\n",
            "        -2.9017e-03, -3.2528e-06], device='cuda:0')}, 16: {'momentum_buffer': tensor([[[[ 2.5381e-04, -2.7981e-04, -6.2014e-04],\n",
            "          [-9.7942e-04, -4.4426e-03, -1.5808e-03],\n",
            "          [-6.4569e-04, -2.2671e-05, -4.2121e-04]],\n",
            "\n",
            "         [[ 3.4044e-05,  3.8732e-05,  1.1376e-04],\n",
            "          [ 1.4521e-04, -2.2389e-04, -5.0420e-04],\n",
            "          [ 1.7238e-03,  1.6438e-03, -1.2093e-04]],\n",
            "\n",
            "         [[-9.2978e-05, -1.4122e-03, -4.8834e-04],\n",
            "          [-1.2750e-03, -1.2643e-04, -1.4671e-03],\n",
            "          [ 5.0275e-04,  3.9475e-04, -6.5600e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.6278e-04, -7.2650e-05, -1.6514e-04],\n",
            "          [ 5.4467e-04,  4.2846e-03,  1.4870e-03],\n",
            "          [ 9.0271e-04,  1.9318e-03,  1.9823e-04]],\n",
            "\n",
            "         [[ 2.5481e-04,  8.9915e-05, -2.1679e-04],\n",
            "          [-8.6019e-04, -2.0979e-03, -9.8514e-04],\n",
            "          [ 2.3262e-03, -1.7756e-05, -2.8478e-03]],\n",
            "\n",
            "         [[ 1.8847e-04,  1.2622e-03,  1.9886e-03],\n",
            "          [-1.3867e-03, -4.2735e-03, -5.5952e-04],\n",
            "          [ 8.5506e-04,  1.0662e-04, -5.1881e-04]]],\n",
            "\n",
            "\n",
            "        [[[-9.5367e-07,  5.0136e-05,  4.5155e-06],\n",
            "          [-2.4539e-03, -2.6181e-03,  6.2777e-05],\n",
            "          [ 1.6569e-04, -1.7922e-03,  6.6831e-04]],\n",
            "\n",
            "         [[ 1.2676e-04,  1.5137e-04,  9.7071e-05],\n",
            "          [ 1.1590e-04, -6.9727e-06, -3.1953e-04],\n",
            "          [ 5.8109e-04, -4.2811e-04, -1.3771e-04]],\n",
            "\n",
            "         [[-2.9685e-05, -1.3012e-03,  5.6588e-04],\n",
            "          [-1.5215e-04,  3.9076e-04,  7.4199e-04],\n",
            "          [ 9.8338e-05,  1.0776e-03, -1.6011e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.4449e-05, -1.7719e-04,  1.2447e-04],\n",
            "          [-2.3383e-04, -8.6706e-04,  4.5485e-05],\n",
            "          [ 1.4205e-05, -1.4043e-05,  4.4789e-04]],\n",
            "\n",
            "         [[ 1.0023e-04,  3.6255e-04,  3.9018e-06],\n",
            "          [ 2.1325e-04,  4.8117e-05,  6.8634e-05],\n",
            "          [-9.9540e-05,  3.4925e-06,  4.0393e-05]],\n",
            "\n",
            "         [[-3.6612e-05, -3.8224e-04,  1.4345e-04],\n",
            "          [ 2.4282e-05,  2.6351e-04, -4.2065e-04],\n",
            "          [ 1.0553e-05,  7.2450e-04, -2.4017e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0337e-05, -4.8835e-04, -8.9497e-05],\n",
            "          [ 2.0524e-04,  2.1430e-03,  8.6478e-04],\n",
            "          [-1.9162e-04,  3.9231e-04, -1.1948e-03]],\n",
            "\n",
            "         [[-9.0987e-04, -9.3086e-04, -1.6752e-05],\n",
            "          [-7.7297e-05, -1.2528e-03, -3.4735e-06],\n",
            "          [ 2.5662e-03,  1.0059e-03, -4.1890e-06]],\n",
            "\n",
            "         [[ 9.8809e-05, -1.6212e-04,  2.4837e-04],\n",
            "          [-6.0296e-04, -5.2888e-04, -1.1110e-07],\n",
            "          [ 1.1495e-03, -3.1937e-04, -2.9780e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0219e-04, -6.1169e-04,  9.8557e-05],\n",
            "          [-6.3471e-05, -1.2872e-03,  4.9308e-04],\n",
            "          [ 3.4393e-04,  3.8289e-03,  3.3210e-04]],\n",
            "\n",
            "         [[ 3.8076e-04,  4.2426e-04,  6.2216e-07],\n",
            "          [-1.4044e-04, -4.0917e-04, -4.7339e-05],\n",
            "          [-2.7223e-03, -1.5822e-03, -2.2579e-03]],\n",
            "\n",
            "         [[ 1.1744e-03, -1.7627e-03, -8.6474e-05],\n",
            "          [-5.4296e-04, -1.4680e-04, -2.9400e-04],\n",
            "          [ 5.9993e-04, -2.6359e-04, -8.6577e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.7461e-03, -5.0122e-04, -1.3597e-03],\n",
            "          [ 2.9456e-04,  5.1362e-04, -7.7733e-04],\n",
            "          [-4.9741e-05,  4.1037e-04,  3.4806e-03]],\n",
            "\n",
            "         [[-9.1922e-04,  2.6322e-04, -9.9438e-04],\n",
            "          [-1.7194e-04,  1.0793e-02, -2.2536e-02],\n",
            "          [-1.6795e-04,  4.6585e-03,  5.2080e-03]],\n",
            "\n",
            "         [[ 1.7915e-05, -3.7930e-04, -9.7209e-05],\n",
            "          [-5.9035e-06, -4.0566e-04, -1.9393e-03],\n",
            "          [-2.7190e-05, -3.8054e-04, -9.5709e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7123e-06, -8.6517e-05,  7.6849e-05],\n",
            "          [ 3.7335e-03,  3.5047e-03,  4.1029e-03],\n",
            "          [-7.2958e-04,  3.7462e-04,  3.4650e-05]],\n",
            "\n",
            "         [[ 3.3197e-05,  8.9175e-04, -6.9914e-04],\n",
            "          [-1.0841e-03, -7.3136e-05, -1.3649e-03],\n",
            "          [-6.8671e-04,  1.0119e-02,  2.6221e-03]],\n",
            "\n",
            "         [[-5.5951e-05, -6.3403e-04,  3.8802e-03],\n",
            "          [ 1.9298e-03,  7.5570e-03,  1.4314e-03],\n",
            "          [ 2.9032e-03,  9.0815e-03, -1.0058e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 8.8317e-04,  4.0535e-03, -5.3521e-03],\n",
            "          [ 1.1010e-03,  2.6122e-03, -7.0619e-03],\n",
            "          [ 1.7677e-04,  8.9316e-04, -5.3284e-03]],\n",
            "\n",
            "         [[-9.7096e-05, -7.3875e-04, -2.7625e-04],\n",
            "          [ 4.7525e-04,  1.0685e-03, -1.5902e-03],\n",
            "          [-2.6293e-03,  2.3246e-04, -2.4378e-03]],\n",
            "\n",
            "         [[ 2.4656e-04, -1.0178e-03, -6.5821e-03],\n",
            "          [ 3.5701e-04,  8.3996e-04, -2.2465e-03],\n",
            "          [ 2.3045e-05,  1.9563e-03,  2.2591e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.8498e-05, -8.8219e-04, -3.7357e-03],\n",
            "          [-3.4619e-03,  3.2149e-03, -3.0523e-03],\n",
            "          [-4.2472e-03, -9.9707e-04, -5.0771e-03]],\n",
            "\n",
            "         [[-3.6477e-03, -1.4931e-03, -8.9562e-04],\n",
            "          [ 1.6933e-03, -1.0182e-03, -2.7810e-04],\n",
            "          [-3.4587e-04, -6.8053e-04, -8.3604e-05]],\n",
            "\n",
            "         [[-1.7877e-04, -2.4360e-03, -2.1374e-03],\n",
            "          [ 9.8173e-04, -1.7065e-03, -1.3085e-03],\n",
            "          [ 7.6629e-04, -1.6224e-03,  6.4378e-04]]],\n",
            "\n",
            "\n",
            "        [[[-1.0511e-05,  3.4978e-05,  2.2292e-06],\n",
            "          [ 1.5738e-04,  1.3450e-03, -5.5958e-04],\n",
            "          [ 1.0285e-04,  3.9973e-04,  3.5229e-04]],\n",
            "\n",
            "         [[ 5.8089e-04,  2.6166e-04,  1.4489e-04],\n",
            "          [ 3.2195e-05,  2.5781e-04,  7.1535e-06],\n",
            "          [-1.1029e-07,  7.7340e-06,  7.3379e-06]],\n",
            "\n",
            "         [[-1.0709e-04, -1.2067e-04,  4.1358e-04],\n",
            "          [-6.8535e-05,  1.2107e-04,  6.0933e-04],\n",
            "          [ 3.8267e-08, -3.4857e-05, -1.1727e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2655e-05,  2.3907e-06,  9.1138e-06],\n",
            "          [-6.7620e-07, -9.6025e-05, -1.7717e-03],\n",
            "          [-1.4488e-04,  2.1105e-04, -2.8798e-04]],\n",
            "\n",
            "         [[-1.7234e-04, -3.5852e-04, -2.3476e-04],\n",
            "          [-6.6303e-04, -5.8886e-04, -2.2371e-04],\n",
            "          [-1.9935e-05, -2.9760e-04,  1.1024e-05]],\n",
            "\n",
            "         [[-3.5780e-04, -8.8529e-04,  4.8833e-04],\n",
            "          [ 1.1802e-04, -5.7974e-04,  2.1581e-04],\n",
            "          [-2.4210e-05, -2.9393e-04, -1.3759e-05]]]], device='cuda:0')}, 17: {'momentum_buffer': tensor([-4.3850e-04,  6.3722e-03, -6.3845e-03,  2.3733e-03,  3.1314e-03,\n",
            "         7.8097e-04, -1.0285e-03,  9.7867e-04, -2.6140e-03, -4.1884e-03,\n",
            "        -4.5082e-05, -6.7286e-03,  1.9984e-05, -6.9206e-03,  9.9818e-04,\n",
            "         1.8883e-03, -3.3259e-03, -2.5966e-03, -1.1352e-03,  4.8796e-04,\n",
            "         2.6423e-03,  7.5086e-05, -2.0965e-04,  7.5113e-03,  4.3614e-04,\n",
            "         1.4505e-03,  1.2030e-02, -5.8385e-03, -4.4796e-03, -5.3403e-04,\n",
            "         2.9968e-03,  9.0726e-03,  5.4724e-04, -9.5765e-04, -1.2563e-04,\n",
            "        -4.0063e-03, -1.1852e-04, -2.3704e-03,  1.7106e-03,  1.6178e-03,\n",
            "        -1.4333e-03,  9.8736e-05,  4.4026e-03,  8.5098e-03, -1.1143e-02,\n",
            "        -4.7332e-03, -1.7317e-02, -4.5801e-04, -1.8895e-05,  6.2845e-04,\n",
            "         1.7931e-03,  3.6929e-04,  2.9380e-03,  1.9469e-03, -8.6506e-04,\n",
            "         4.1925e-03,  1.3442e-03, -3.9644e-04, -8.3639e-04,  1.3964e-03,\n",
            "         2.1283e-03,  1.7035e-04,  1.0378e-04,  2.6620e-03, -3.8217e-03,\n",
            "         3.5717e-04,  6.9086e-04, -6.1900e-04,  2.9555e-04,  4.2981e-03,\n",
            "         1.8965e-03,  1.4320e-03, -6.8115e-03, -7.0639e-04, -7.5596e-04,\n",
            "         4.1041e-04, -1.2833e-04, -2.9339e-03, -2.3543e-03,  2.0276e-03,\n",
            "         3.0175e-05,  6.4404e-04,  1.2233e-03, -9.1436e-03, -1.1265e-03,\n",
            "         9.2611e-03,  2.5020e-03,  1.9462e-03,  4.5793e-05, -5.9928e-04,\n",
            "        -3.2298e-03,  1.3515e-03, -1.0194e-02, -1.6530e-03,  3.0326e-04,\n",
            "         6.3281e-04, -2.7250e-04, -1.4072e-02, -8.7591e-04,  7.6475e-04,\n",
            "        -3.9190e-03, -3.2232e-03,  2.1598e-03, -1.7279e-03,  8.4328e-04,\n",
            "        -2.7815e-04,  3.1161e-04,  3.4490e-03, -5.6307e-03, -1.0374e-03,\n",
            "         1.0565e-02,  1.7679e-03,  1.6452e-03,  7.5072e-04,  2.5023e-03,\n",
            "         3.6717e-03,  7.5543e-03, -1.1927e-02,  3.5584e-03, -1.0531e-03,\n",
            "        -9.2419e-03,  3.1311e-04, -1.1725e-03, -1.4577e-02, -1.9356e-03,\n",
            "        -2.5917e-04, -1.4488e-03, -1.5008e-03, -4.4055e-03, -7.9179e-04,\n",
            "         1.6022e-03,  3.8869e-04,  3.6480e-03, -5.7418e-03,  5.5162e-04,\n",
            "        -2.3364e-03, -2.1763e-03,  2.1179e-03,  2.1674e-03, -1.2086e-04,\n",
            "         1.6223e-03, -8.3654e-04,  3.8142e-03, -5.7533e-03, -6.8796e-04,\n",
            "        -4.9674e-04,  1.9364e-04,  7.3483e-04, -5.0517e-04,  4.0464e-03,\n",
            "         1.5607e-02, -2.2961e-03,  7.7907e-03,  5.1295e-03,  2.2787e-03,\n",
            "         1.8562e-03,  9.3681e-04,  7.2340e-03,  1.4203e-03,  1.4096e-03,\n",
            "        -1.7500e-05, -1.4013e-03,  3.5543e-03, -1.4380e-03, -2.1163e-03,\n",
            "        -1.9506e-04,  5.3852e-03, -7.4286e-03, -1.1508e-03, -4.1569e-03,\n",
            "        -2.4597e-03,  3.2026e-03,  1.3339e-04, -3.7177e-04,  2.4201e-04,\n",
            "         3.0357e-04, -1.2507e-03,  8.6026e-04, -8.4982e-04,  4.3670e-03,\n",
            "         2.5165e-03, -5.3364e-03,  1.5631e-03, -2.7568e-04, -4.6450e-03,\n",
            "         3.2201e-03, -1.7977e-03,  1.1126e-03, -8.2918e-04, -8.3940e-03,\n",
            "         1.5562e-03, -1.6749e-03,  1.0801e-03, -7.7369e-03, -1.3452e-03,\n",
            "         1.7340e-03,  3.3290e-04,  1.9167e-03,  1.4110e-03, -3.4601e-03,\n",
            "         2.8015e-04, -1.0957e-04,  8.4667e-04, -6.0552e-03, -2.7948e-03,\n",
            "        -7.8807e-03, -2.7507e-03,  9.4294e-03, -4.3008e-03, -2.9433e-03,\n",
            "        -1.0063e-02, -1.5407e-03,  8.0510e-03, -3.0945e-04,  5.7244e-04,\n",
            "        -2.0229e-03,  9.0859e-04,  2.7109e-04, -5.5080e-04,  2.2944e-03,\n",
            "         8.0188e-03, -4.2170e-03,  1.5587e-03,  1.4575e-03, -3.7626e-03,\n",
            "         9.5931e-04,  3.7271e-03,  9.7033e-04,  4.5648e-03,  3.3878e-03,\n",
            "         3.6494e-03,  3.2720e-03,  7.5659e-04,  8.9338e-04,  1.2442e-02,\n",
            "         2.8078e-03, -3.9248e-03, -8.1186e-04,  1.6375e-03, -1.9582e-03,\n",
            "        -2.5168e-04,  6.8149e-03,  2.5433e-04,  1.8675e-02, -6.8728e-04,\n",
            "         7.5251e-03, -4.5014e-04,  8.4701e-05, -4.0064e-03,  6.3651e-04,\n",
            "        -2.9261e-04,  6.6947e-05, -5.7478e-03,  5.1488e-03,  1.8915e-04,\n",
            "         1.9617e-04, -4.8927e-03, -1.0693e-04,  7.2842e-04, -1.2310e-03,\n",
            "        -1.4282e-03, -1.4045e-03, -3.5331e-06,  4.5810e-03,  5.9814e-03,\n",
            "        -1.3567e-03, -1.2031e-02, -4.3005e-05,  9.6467e-04,  2.2704e-03,\n",
            "         7.4813e-03, -2.0936e-03, -1.1240e-02, -3.9422e-03,  7.5014e-04,\n",
            "        -1.6319e-04, -8.1031e-04,  1.6917e-02,  3.7542e-03,  1.2688e-03,\n",
            "         1.0869e-03, -6.1043e-03,  6.3101e-03, -1.1177e-03,  4.8189e-03,\n",
            "         1.1533e-02,  5.2621e-04, -1.1669e-03,  2.0819e-04,  1.2765e-03,\n",
            "        -2.8656e-04, -5.2227e-03, -6.6168e-04,  6.1080e-04,  7.9704e-04,\n",
            "        -1.7698e-02, -5.8874e-03,  3.1145e-04,  1.1996e-03,  2.5652e-03,\n",
            "         6.2444e-04, -7.6252e-04,  1.6106e-03, -9.7758e-03,  9.7602e-03,\n",
            "         6.2773e-05,  1.5423e-03,  1.2374e-03, -1.6165e-03, -4.7861e-03,\n",
            "         5.5295e-04, -2.8721e-03,  2.8823e-03, -1.8202e-03,  5.6052e-03,\n",
            "         3.2975e-03, -6.8707e-03, -1.2726e-03, -1.2241e-02,  3.0826e-03,\n",
            "        -7.5824e-03,  1.6367e-03, -7.3707e-04, -2.3050e-03,  4.3835e-03,\n",
            "         2.2111e-03, -1.8083e-03, -2.4435e-03,  2.9561e-04, -1.9019e-03,\n",
            "         7.3057e-04,  1.4114e-04,  7.9980e-04, -5.0299e-03, -1.4844e-03,\n",
            "        -2.4291e-03, -2.4953e-03, -1.6466e-03, -2.4508e-03,  9.8973e-04,\n",
            "         1.2017e-03, -1.7581e-03, -3.2960e-03, -2.2979e-03,  1.0966e-03,\n",
            "        -7.5651e-03,  3.8535e-04,  2.7311e-04,  2.7641e-04, -3.6036e-03,\n",
            "        -4.3470e-03, -3.3290e-03,  2.0501e-03, -4.1662e-03, -3.1843e-03,\n",
            "        -2.4282e-03, -8.9959e-03,  1.9244e-04,  3.9976e-03, -2.7120e-03,\n",
            "        -7.8060e-03, -4.4081e-03,  2.0496e-03,  1.3796e-03,  1.6030e-02,\n",
            "        -2.6483e-03,  7.0295e-03,  1.0808e-02, -3.4321e-03,  3.6409e-04,\n",
            "         1.9676e-03,  6.9274e-04,  4.0357e-04, -4.3175e-03, -1.5243e-03,\n",
            "        -2.3324e-03, -1.4758e-04,  2.5998e-03, -3.6341e-04,  2.3036e-03,\n",
            "         2.5498e-03,  3.5415e-03,  5.2193e-04, -3.6758e-03, -5.3081e-03,\n",
            "        -1.3789e-03,  3.4733e-03,  4.4020e-03, -3.7618e-03,  9.1241e-04,\n",
            "         4.0722e-02, -2.1069e-03, -2.1124e-03, -9.8027e-03,  1.7406e-03,\n",
            "         1.0184e-03,  5.7704e-03,  5.8588e-03,  1.4676e-03, -1.9592e-03,\n",
            "         2.0239e-03,  2.6978e-03,  1.4941e-03,  1.1102e-03,  1.4920e-03,\n",
            "        -4.1517e-04, -1.9071e-03,  1.2288e-03,  4.6627e-03, -7.1755e-03,\n",
            "         3.7518e-03,  1.1299e-03,  5.1302e-03,  3.8965e-03,  2.0185e-03,\n",
            "         3.8283e-04,  7.5317e-04,  2.7529e-03,  1.0994e-03, -2.7427e-03,\n",
            "         1.7532e-03,  6.4896e-03,  5.7628e-04, -4.0153e-03,  2.0457e-02,\n",
            "        -1.3420e-03,  8.8315e-04, -9.9341e-04, -3.8254e-03,  2.5997e-03,\n",
            "        -3.1005e-03, -4.3162e-04,  9.5176e-04, -6.8197e-04,  6.4427e-04,\n",
            "        -1.1480e-03,  2.1242e-03, -2.5013e-04, -8.2971e-04, -7.0957e-04,\n",
            "        -1.9132e-03, -2.4183e-03, -5.8229e-05, -8.3229e-03, -2.6955e-05,\n",
            "         8.8804e-04, -4.1165e-03,  9.8392e-04,  3.2395e-03, -2.5881e-03,\n",
            "        -5.5322e-03,  1.1534e-02, -4.4904e-03,  6.5550e-03,  2.3613e-03,\n",
            "         8.3169e-03, -8.3842e-03, -1.0042e-03, -2.5998e-05,  3.2101e-03,\n",
            "        -6.1900e-04, -2.2171e-04,  1.2932e-03,  1.5827e-03, -6.3222e-03,\n",
            "         2.9118e-04, -5.3511e-04,  1.2140e-03, -1.2077e-03, -1.4654e-03,\n",
            "        -2.0308e-03, -3.8685e-04,  3.7455e-03, -1.6121e-02,  2.7544e-03,\n",
            "         2.0922e-03,  7.4637e-04,  8.8230e-03, -5.7497e-04,  5.8503e-03,\n",
            "         1.3632e-03,  1.5689e-04,  1.8954e-02,  6.9521e-03,  6.4142e-04,\n",
            "        -7.0273e-03,  6.3070e-03, -5.6861e-04, -1.4329e-03,  1.7170e-03,\n",
            "        -6.0281e-03, -6.0031e-04,  5.6667e-04,  6.1701e-04, -5.0154e-03,\n",
            "         6.5629e-03,  1.2929e-03,  2.9610e-03,  7.3295e-03, -1.4618e-04,\n",
            "        -1.0786e-03,  2.9549e-03,  1.3829e-03, -4.7689e-04,  7.7439e-04,\n",
            "         9.3051e-04, -1.0516e-03,  2.4315e-03, -1.6733e-04,  1.3320e-05,\n",
            "         1.1001e-03,  3.2023e-03], device='cuda:0')}, 18: {'momentum_buffer': tensor([[[[-6.5545e-08, -2.1601e-05,  5.4038e-07],\n",
            "          [-5.5882e-06,  3.2887e-04,  1.5107e-05],\n",
            "          [-9.1479e-06,  2.3674e-06, -1.7843e-04]],\n",
            "\n",
            "         [[ 4.3093e-07,  6.5740e-06, -7.8084e-06],\n",
            "          [ 2.2557e-05,  7.0818e-06, -5.7178e-05],\n",
            "          [ 3.3477e-05,  4.6268e-05, -1.1916e-04]],\n",
            "\n",
            "         [[ 2.8990e-14,  3.3931e-13, -2.3476e-05],\n",
            "          [-1.3362e-08, -1.7547e-06,  1.6102e-05],\n",
            "          [ 1.1825e-06, -1.2828e-04, -1.4882e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3394e-13,  1.9516e-13, -6.4418e-13],\n",
            "          [ 4.3442e-05,  3.1147e-04,  3.5162e-06],\n",
            "          [ 8.6576e-05,  1.7400e-04,  1.4440e-03]],\n",
            "\n",
            "         [[-4.7489e-11, -1.1381e-08, -1.9165e-07],\n",
            "          [ 5.2706e-05, -6.2184e-05, -4.7458e-04],\n",
            "          [ 2.9535e-06, -3.0039e-05,  1.5198e-04]],\n",
            "\n",
            "         [[-5.6052e-45,  9.2039e-08,  3.8226e-07],\n",
            "          [ 3.2960e-07,  1.9089e-05,  6.1249e-06],\n",
            "          [-9.8053e-08,  5.0900e-05,  1.7711e-07]]],\n",
            "\n",
            "\n",
            "        [[[-4.5122e-04,  2.4496e-03,  4.4055e-03],\n",
            "          [ 8.5350e-05,  5.3945e-04,  3.0364e-03],\n",
            "          [-1.3024e-03,  3.1784e-03,  4.7707e-04]],\n",
            "\n",
            "         [[ 1.7734e-05,  3.3347e-05,  6.6822e-05],\n",
            "          [ 1.8768e-03,  3.7355e-03,  3.3375e-03],\n",
            "          [ 9.9665e-05,  9.7512e-04, -9.9078e-05]],\n",
            "\n",
            "         [[-1.8521e-06,  8.2166e-05, -5.7261e-05],\n",
            "          [-1.7085e-06, -1.1935e-06, -1.8373e-05],\n",
            "          [-8.8593e-05,  7.3627e-07,  4.0278e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.5045e-04,  1.3500e-03,  2.8303e-04],\n",
            "          [ 1.4194e-03,  6.0985e-03,  1.9516e-03],\n",
            "          [ 4.5885e-04,  4.5503e-04,  9.7887e-05]],\n",
            "\n",
            "         [[ 4.3672e-04, -2.5149e-04, -1.1010e-05],\n",
            "          [ 3.0597e-04, -1.6420e-03, -1.0519e-03],\n",
            "          [ 3.0138e-04, -1.4158e-03, -2.8318e-03]],\n",
            "\n",
            "         [[ 4.7594e-06,  3.1815e-05,  4.1466e-06],\n",
            "          [ 5.9475e-06, -3.7168e-05,  1.6718e-05],\n",
            "          [ 1.8088e-04,  1.1211e-04,  4.7076e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 3.9205e-06, -1.4693e-06,  6.8804e-07],\n",
            "          [-1.1504e-03,  1.9382e-03, -1.7032e-03],\n",
            "          [-1.7577e-03,  5.5436e-03,  1.0514e-03]],\n",
            "\n",
            "         [[-1.2876e-07, -3.1431e-06, -7.1969e-08],\n",
            "          [-1.3070e-05, -5.2812e-04, -1.3041e-03],\n",
            "          [-2.8061e-05, -3.5918e-04,  2.3733e-04]],\n",
            "\n",
            "         [[ 1.2740e-22, -1.8061e-07,  1.7576e-06],\n",
            "          [-3.7839e-05,  1.5918e-03, -4.3635e-03],\n",
            "          [ 1.5349e-07,  1.6307e-03, -2.9794e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.5780e-14,  1.5452e-07,  1.5873e-08],\n",
            "          [ 1.4393e-04, -6.9879e-05, -2.0121e-05],\n",
            "          [ 4.7652e-04, -9.3863e-06,  5.4563e-03]],\n",
            "\n",
            "         [[ 9.7404e-08,  7.6788e-08,  3.9583e-07],\n",
            "          [-7.8182e-04,  2.3131e-04,  7.6690e-03],\n",
            "          [ 8.7089e-05, -1.5177e-03,  2.3304e-03]],\n",
            "\n",
            "         [[-5.1870e-14, -4.2841e-12, -6.8529e-14],\n",
            "          [-1.1558e-03, -6.0681e-06, -4.6697e-05],\n",
            "          [ 2.1859e-04,  6.8740e-05, -8.8876e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 7.0969e-07, -2.0425e-06, -3.2040e-06],\n",
            "          [ 3.0284e-06,  8.5386e-06, -1.8759e-04],\n",
            "          [-3.5104e-06, -5.4946e-07, -2.0725e-05]],\n",
            "\n",
            "         [[ 6.9768e-08, -7.6158e-08, -1.4218e-08],\n",
            "          [ 8.0685e-09, -6.1272e-06, -8.7469e-08],\n",
            "          [ 4.8319e-08,  4.2291e-08, -3.2048e-06]],\n",
            "\n",
            "         [[ 5.9832e-16,  6.7119e-08,  1.7438e-07],\n",
            "          [ 2.4307e-09,  1.9695e-08,  4.3839e-08],\n",
            "          [-7.6866e-14, -5.3296e-07,  3.0039e-07]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.9375e-08, -7.1697e-07, -2.8641e-08],\n",
            "          [-5.6751e-06,  2.4139e-07,  3.0723e-07],\n",
            "          [-2.6243e-06,  7.1382e-06, -8.6637e-09]],\n",
            "\n",
            "         [[-1.0661e-07, -3.7193e-07, -1.8957e-06],\n",
            "          [-3.2811e-07, -1.0193e-06,  1.9611e-05],\n",
            "          [-2.8301e-06, -6.5940e-07, -3.4258e-06]],\n",
            "\n",
            "         [[-1.4101e-23,  4.3813e-14,  1.3156e-14],\n",
            "          [ 4.2411e-15,  3.8782e-09, -2.1383e-10],\n",
            "          [ 7.9600e-15, -2.5536e-06,  7.5068e-05]]],\n",
            "\n",
            "\n",
            "        [[[-3.9041e-06,  4.9983e-04,  3.1687e-05],\n",
            "          [-1.2806e-08, -5.8570e-04,  1.2386e-03],\n",
            "          [-3.8465e-05,  5.8056e-04,  2.1111e-04]],\n",
            "\n",
            "         [[ 3.1895e-12, -3.9476e-05,  2.2247e-04],\n",
            "          [ 1.0592e-05,  1.2986e-04, -4.1930e-05],\n",
            "          [-3.3210e-07,  4.9378e-06, -1.3032e-04]],\n",
            "\n",
            "         [[-1.7725e-34,  3.1594e-05,  1.1494e-05],\n",
            "          [ 1.7577e-06, -3.8964e-05,  2.8495e-05],\n",
            "          [ 3.3529e-07, -3.9403e-05,  1.2471e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6001e-09,  4.3901e-06, -1.3833e-05],\n",
            "          [ 1.3804e-04,  5.9562e-05, -1.2568e-04],\n",
            "          [-4.1340e-05,  1.4698e-03,  7.6560e-04]],\n",
            "\n",
            "         [[ 9.8272e-25,  1.6198e-05, -7.3612e-07],\n",
            "          [ 3.4948e-07,  7.4267e-05,  3.5834e-05],\n",
            "          [-4.6780e-05, -3.0355e-04, -3.7514e-04]],\n",
            "\n",
            "         [[ 5.6052e-45,  2.5469e-06,  1.3550e-08],\n",
            "          [-4.3388e-16,  1.0161e-05, -5.4623e-06],\n",
            "          [ 1.3268e-06, -1.9780e-06,  2.3463e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 8.9722e-07, -2.7013e-04, -8.0360e-04],\n",
            "          [-2.7400e-04,  1.0608e-03,  5.4882e-04],\n",
            "          [ 1.4703e-04, -5.2413e-04,  2.4879e-03]],\n",
            "\n",
            "         [[ 4.1140e-06,  1.0026e-05,  2.0198e-04],\n",
            "          [ 4.7894e-04, -5.8429e-04, -2.5330e-04],\n",
            "          [ 4.0983e-04, -2.1153e-04, -5.7113e-04]],\n",
            "\n",
            "         [[-2.0142e-06,  1.1712e-05,  7.8767e-06],\n",
            "          [ 1.2560e-05,  2.1712e-05,  4.5092e-05],\n",
            "          [-3.5157e-08,  4.1754e-05, -2.4589e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.3830e-20,  9.8202e-09, -2.3951e-09],\n",
            "          [-2.1768e-03,  1.9621e-04,  1.8444e-04],\n",
            "          [ 1.3107e-03,  7.8751e-04, -7.7997e-05]],\n",
            "\n",
            "         [[-2.5642e-11,  3.5778e-06,  4.9744e-06],\n",
            "          [-1.3237e-05,  5.3148e-04, -2.1428e-03],\n",
            "          [ 7.9854e-05,  8.5096e-04,  1.2765e-03]],\n",
            "\n",
            "         [[-5.6052e-45,  4.3839e-07,  1.4470e-06],\n",
            "          [ 5.8173e-06, -2.6572e-07,  6.3606e-04],\n",
            "          [-1.3306e-05,  2.1499e-04,  1.6625e-05]]]], device='cuda:0')}, 19: {'momentum_buffer': tensor([-2.4998e-03,  7.6026e-03,  1.0872e-03, -1.1378e-02, -3.0026e-03,\n",
            "         4.3705e-03,  3.2556e-03, -3.0970e-03,  8.7449e-03,  2.4738e-03,\n",
            "         4.7238e-03,  3.2897e-04, -1.4661e-02, -6.0163e-05,  1.2010e-04,\n",
            "        -1.9771e-03,  2.1142e-03, -6.6988e-04, -4.2042e-03, -3.4708e-04,\n",
            "         7.7109e-03, -1.0605e-02,  5.1200e-03,  1.1381e-03, -6.4611e-04,\n",
            "         6.1974e-03,  7.0078e-04, -1.6881e-03, -1.7560e-03,  2.3007e-03,\n",
            "         4.9979e-03, -8.1979e-04, -6.1142e-05, -8.8563e-03, -1.8716e-04,\n",
            "        -4.2171e-03, -4.1021e-04, -2.4699e-04,  8.7924e-03,  3.5372e-05,\n",
            "        -2.5953e-03, -1.5004e-02,  7.5849e-04, -6.1844e-03,  6.6168e-03,\n",
            "         6.1250e-03, -3.8023e-03,  1.5858e-04, -5.3224e-03,  4.0198e-04,\n",
            "        -5.6964e-04,  3.2495e-03, -1.9304e-03,  2.9830e-03, -2.6964e-03,\n",
            "        -7.4719e-03, -2.8851e-04, -1.8625e-03, -1.6064e-03,  6.8666e-03,\n",
            "        -6.8804e-03,  6.9451e-04,  3.3281e-03,  3.2419e-04, -2.3339e-03,\n",
            "        -5.9534e-04,  6.6507e-03, -4.9752e-03,  9.1983e-03,  2.1735e-03,\n",
            "        -3.4197e-03,  9.8638e-04, -6.9577e-03,  4.4042e-03,  4.9444e-03,\n",
            "         6.1385e-04,  1.5059e-05, -2.1609e-03, -2.5356e-04, -1.9671e-04,\n",
            "        -1.9521e-04, -5.6452e-03,  6.9841e-04, -4.2805e-03, -6.7581e-03,\n",
            "        -3.1614e-03,  3.6206e-03, -3.6173e-04,  3.8100e-03,  1.6310e-03,\n",
            "         9.9023e-03,  2.3373e-05,  3.2562e-03,  5.5611e-04,  4.6306e-03,\n",
            "         1.1249e-03,  4.6416e-03, -9.8861e-04, -6.8893e-04,  5.0636e-03,\n",
            "         2.9753e-03,  1.3562e-03, -1.1731e-02,  8.8010e-07, -1.4199e-03,\n",
            "         1.4023e-03,  3.4540e-03, -3.3634e-03,  3.8505e-03,  3.9280e-04,\n",
            "         7.0338e-03,  6.4951e-03,  5.3404e-03, -5.4686e-03,  2.8701e-04,\n",
            "         6.9187e-03,  3.0832e-03,  9.4944e-03, -2.3460e-03, -2.3884e-03,\n",
            "         7.5887e-04,  2.2244e-03, -4.5719e-04, -4.0000e-03, -7.1795e-03,\n",
            "        -1.1455e-03,  2.5138e-03,  3.5859e-05,  2.9923e-03,  1.0014e-03,\n",
            "         1.1433e-02,  3.1785e-03,  1.8854e-03, -7.1157e-03, -1.4735e-03,\n",
            "         3.2818e-03,  9.0899e-04,  5.7720e-04,  2.2404e-04,  1.9759e-03,\n",
            "         5.8967e-03, -3.1751e-04,  3.5674e-03, -1.3360e-02, -4.1143e-05,\n",
            "         2.4620e-03,  3.5215e-03,  5.4816e-04,  2.7902e-03,  1.0991e-03,\n",
            "        -7.3393e-03, -5.0195e-03,  1.0973e-02, -8.7310e-04, -8.6075e-04,\n",
            "         8.5992e-04,  2.8366e-03, -1.2963e-03, -2.3020e-03, -3.8021e-05,\n",
            "         4.8481e-03, -3.3449e-05, -4.0064e-04, -6.9026e-04, -3.2086e-03,\n",
            "        -1.3564e-04, -1.0444e-03, -1.8909e-03,  2.8627e-03,  3.8337e-04,\n",
            "         1.4720e-06,  2.2779e-04,  4.4316e-04,  1.0689e-03, -5.7427e-03,\n",
            "         2.2143e-03, -7.1742e-04, -1.5980e-03, -6.7532e-03, -1.1984e-03,\n",
            "        -3.0299e-03,  1.3107e-03,  2.8601e-04, -5.5900e-03, -1.0039e-03,\n",
            "         6.2280e-03,  4.2248e-05,  1.5488e-03,  1.5399e-02, -4.2365e-04,\n",
            "         8.5919e-04,  4.7565e-03,  8.3624e-03, -9.8146e-03, -1.7256e-03,\n",
            "         1.2004e-03,  2.2216e-03, -2.5150e-03, -5.9596e-04,  1.5344e-03,\n",
            "        -6.2029e-03,  1.6073e-03, -2.2389e-03,  7.5205e-04,  1.1911e-02,\n",
            "         8.5062e-03,  2.5254e-03, -1.3043e-03,  4.5788e-03, -2.5623e-03,\n",
            "        -3.1217e-03, -2.1249e-03,  2.2303e-05, -1.2953e-04,  3.6840e-05,\n",
            "         3.6745e-03,  5.1100e-03, -6.2870e-03, -1.5137e-02, -1.8540e-04,\n",
            "         3.7932e-03,  6.8770e-03,  5.7418e-03, -7.2173e-03,  1.5831e-02,\n",
            "        -7.3056e-05,  2.2038e-03,  2.3927e-03,  8.5566e-03, -2.5143e-03,\n",
            "        -1.4479e-03, -3.9876e-03, -2.5454e-03, -3.1882e-03, -6.3169e-03,\n",
            "         4.3399e-04, -4.1494e-03, -1.3632e-02, -5.0648e-03,  1.2021e-02,\n",
            "         1.0793e-03,  8.2540e-03, -2.7344e-03,  3.2527e-03,  1.1664e-04,\n",
            "        -6.6867e-03,  3.0388e-03,  5.5607e-03, -1.8738e-03,  7.3024e-05,\n",
            "        -6.3815e-04, -6.1343e-03, -5.4148e-03, -1.1227e-03, -4.9165e-03,\n",
            "         6.9739e-04, -6.8601e-04,  6.1666e-04,  1.5800e-02, -2.0960e-03,\n",
            "         1.7771e-04, -2.8075e-03, -7.4925e-05,  3.6586e-04, -6.7236e-05,\n",
            "        -5.2430e-04,  1.1470e-03,  5.2352e-04,  1.2448e-02, -2.3212e-03,\n",
            "         3.5787e-03, -6.1020e-03,  1.8804e-02,  1.8793e-03, -1.1078e-03,\n",
            "        -2.7878e-03, -5.9254e-03, -1.4287e-04,  4.3019e-03, -4.9155e-04,\n",
            "         1.9355e-06,  3.8278e-03,  2.3837e-03,  9.9823e-03, -2.3034e-03,\n",
            "         1.5612e-03, -2.2266e-03, -2.2129e-04,  1.2155e-03, -1.2860e-03,\n",
            "        -1.3947e-03, -1.6993e-03,  3.8846e-03,  3.0418e-03,  6.1812e-03,\n",
            "        -4.6582e-03,  3.3660e-03,  5.1787e-04, -8.5089e-03, -4.1395e-03,\n",
            "         2.1081e-03, -3.7833e-04,  5.6721e-03,  2.3086e-03,  2.4212e-04,\n",
            "         4.1634e-03, -6.1882e-04,  8.9119e-03,  3.4712e-03, -2.5589e-03,\n",
            "         3.3348e-03,  7.7417e-03, -1.0920e-03,  2.0804e-03, -1.3307e-03,\n",
            "        -3.9952e-03, -1.5306e-02,  5.4162e-03, -2.2339e-03, -8.7026e-04,\n",
            "         1.6011e-03,  6.6970e-03, -4.0607e-03,  2.1332e-03,  1.3088e-03,\n",
            "        -1.1374e-02, -1.5789e-03, -2.3433e-02,  2.7917e-03, -2.4917e-03,\n",
            "         3.1543e-03,  4.1619e-03, -2.1389e-02, -6.7593e-03, -1.3657e-03,\n",
            "         1.7971e-04,  2.3981e-04, -8.4706e-04,  7.0411e-03, -2.7026e-03,\n",
            "        -1.8923e-03, -7.4362e-04, -7.5895e-04, -1.4659e-03, -6.6486e-03,\n",
            "         2.8432e-03,  1.7921e-02,  8.7365e-04, -2.3146e-04,  2.0789e-03,\n",
            "         3.1589e-03,  4.3489e-03, -4.7377e-03,  1.1684e-03, -7.2612e-04,\n",
            "        -4.1592e-04,  2.1073e-03, -8.9605e-03,  4.3866e-04,  4.1781e-03,\n",
            "        -7.8268e-03,  4.4921e-04, -4.0813e-03,  7.2815e-03, -2.8952e-04,\n",
            "         1.0641e-03,  9.0474e-03,  3.1943e-03,  6.7924e-04,  3.6802e-03,\n",
            "        -1.8416e-03,  3.3847e-03, -1.9498e-03,  4.6311e-03,  6.1636e-03,\n",
            "         1.1242e-02, -7.6085e-05, -2.2042e-03,  1.0826e-03, -1.2529e-02,\n",
            "        -1.0169e-03,  1.5965e-03, -5.6804e-03,  8.3221e-03, -3.7411e-03,\n",
            "        -2.5278e-05,  3.8623e-03, -4.8343e-03, -3.8577e-03,  4.1838e-04,\n",
            "         3.6302e-03,  3.7330e-03, -8.1343e-04,  1.7850e-02,  1.0546e-02,\n",
            "        -6.1514e-04,  3.7915e-04, -9.5315e-04,  6.7171e-04,  4.2728e-03,\n",
            "        -2.8745e-03, -3.0299e-03, -3.0747e-04, -2.8642e-03,  2.4092e-04,\n",
            "         9.3211e-03,  2.0075e-03, -1.4115e-03, -8.9259e-04, -2.9840e-03,\n",
            "         1.5657e-03,  4.5499e-04,  5.9157e-03,  7.9238e-04, -9.3153e-05,\n",
            "         9.4338e-04,  2.1098e-03, -5.0466e-03, -6.6532e-03,  6.8587e-03,\n",
            "         1.6531e-04,  6.8995e-03, -3.3825e-03,  1.8747e-03,  2.3207e-04,\n",
            "         3.1419e-06, -9.4986e-04, -4.8193e-03,  2.8274e-03,  1.1834e-04,\n",
            "         5.6735e-05, -4.9860e-03,  3.7617e-03,  6.4281e-04, -4.5655e-03,\n",
            "        -5.7321e-03, -4.8653e-03,  9.9002e-03,  1.9738e-03, -7.8775e-05,\n",
            "         1.1498e-02, -5.5147e-03, -7.8426e-03,  3.8402e-03, -8.1888e-03,\n",
            "         7.2351e-03,  4.2251e-03,  6.4183e-03, -1.8229e-03,  2.9942e-04,\n",
            "        -4.2416e-03, -3.3040e-03, -3.1183e-03,  3.5866e-03, -1.8837e-03,\n",
            "        -1.3783e-03,  4.8563e-03, -4.9643e-06, -1.8453e-03,  3.4195e-04,\n",
            "         2.6836e-03, -3.8477e-03, -2.8537e-03, -3.6279e-03,  6.2949e-03,\n",
            "        -1.4143e-02, -3.9687e-03,  1.7974e-03, -5.0803e-03,  3.7547e-04,\n",
            "         1.3184e-05, -3.1214e-03,  2.9237e-03, -1.3980e-03,  1.2122e-03,\n",
            "         1.5880e-03, -4.7702e-03,  2.6880e-03, -9.1341e-03, -8.4016e-03,\n",
            "        -4.1546e-03, -2.5203e-04,  1.6520e-04,  1.3110e-03, -7.8868e-04,\n",
            "        -8.5308e-03, -1.2419e-03, -1.7140e-03,  4.9926e-04,  2.4019e-03,\n",
            "         2.7019e-03,  2.9940e-03, -8.0058e-03,  5.5762e-03,  3.6182e-03,\n",
            "        -6.8843e-03,  1.0736e-03,  1.7525e-04,  4.1105e-03,  7.0026e-03,\n",
            "        -6.1721e-03,  4.0810e-03,  1.1550e-02, -6.5552e-04, -4.0444e-03,\n",
            "         2.6880e-03, -4.4198e-03, -3.2455e-04, -2.6926e-04,  2.0397e-03,\n",
            "         4.0270e-03, -4.4567e-03], device='cuda:0')}, 20: {'momentum_buffer': tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  5.4338e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  8.6920e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  6.1477e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  2.9411e-07,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.2689e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -7.3294e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  3.0943e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.8895e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  2.3561e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.5414e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.7793e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  2.3901e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  4.9413e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.0070e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -3.5692e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.4211e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -6.0831e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -7.2017e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.1834e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.7195e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.3008e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.0158e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.1797e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  3.9800e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  5.2397e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -5.5229e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  4.6420e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -3.6313e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  2.4980e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  4.4578e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  9.6346e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -3.5455e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -5.6237e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.1095e-07,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -8.0340e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.1273e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0')}, 21: {'momentum_buffer': tensor([ 4.0288e-03, -8.3318e-03,  2.8228e-03,  1.1312e-05, -2.2816e-03,\n",
            "         1.2110e-03,  1.0576e-03,  3.5683e-04, -9.7515e-05, -5.0811e-03,\n",
            "         1.8715e-03, -8.2454e-04, -4.1562e-03,  3.0360e-03,  4.0399e-05,\n",
            "         2.1098e-03,  1.7440e-04, -5.5352e-03,  6.1284e-03,  5.9576e-03,\n",
            "         2.7838e-03, -4.3407e-03,  1.0311e-06, -4.9638e-04,  9.2139e-03,\n",
            "        -5.9963e-03,  5.8342e-04, -6.3927e-03, -9.8601e-03, -2.6850e-03,\n",
            "         1.6088e-03,  2.5425e-03,  1.4191e-03,  2.2831e-03,  5.3287e-04,\n",
            "         1.3980e-02,  7.9561e-04,  4.0663e-03,  3.6402e-03,  5.4605e-03,\n",
            "        -3.0284e-03,  5.2492e-03,  3.1310e-03,  5.5885e-03, -1.4719e-03,\n",
            "        -4.3207e-04, -2.2412e-03, -3.0230e-03,  2.0130e-05,  3.7795e-03,\n",
            "         1.2267e-02,  4.5849e-03, -3.1836e-04, -6.7268e-03,  6.1427e-03,\n",
            "         6.1258e-03, -1.6423e-04, -8.5786e-03,  1.1794e-02, -1.1883e-03,\n",
            "        -5.9832e-03,  3.4909e-04, -1.2368e-03,  1.7310e-03,  1.9229e-02,\n",
            "         2.0040e-03,  8.7263e-06,  1.4146e-03,  1.0671e-03,  5.3195e-04,\n",
            "        -4.4293e-03,  5.8536e-05,  2.1180e-02, -7.0363e-04,  2.4636e-03,\n",
            "        -1.6983e-03,  1.4046e-03,  1.6987e-02, -3.5709e-03,  1.3014e-03,\n",
            "         3.2123e-04,  4.7199e-03,  7.2466e-03,  1.1923e-03,  1.3293e-05,\n",
            "         1.0790e-03,  2.4019e-03,  4.2863e-03,  3.3573e-03,  7.8183e-04,\n",
            "         5.0977e-03,  1.0308e-03,  1.2686e-02, -8.5582e-03,  1.3317e-05,\n",
            "        -3.4631e-03,  5.2364e-03,  7.1310e-03,  6.3738e-03, -1.2676e-03,\n",
            "        -9.3771e-04,  2.9638e-03,  4.0881e-03,  3.0055e-03,  3.0392e-03,\n",
            "        -6.9699e-04, -2.6210e-03,  4.2779e-03, -4.5001e-04,  2.0117e-03,\n",
            "         8.8368e-03, -7.0604e-03, -1.1980e-04, -9.6943e-03,  4.4449e-03,\n",
            "        -2.8425e-03, -7.1164e-03, -2.1206e-03, -9.3974e-03, -1.5219e-03,\n",
            "        -1.1960e-02,  3.6014e-04,  7.8651e-03,  9.6863e-03,  8.9010e-03,\n",
            "        -7.2034e-03,  4.1373e-03, -5.4081e-03,  2.3185e-03,  3.5516e-03,\n",
            "         8.8594e-03, -6.6080e-04, -2.8700e-03, -1.2334e-02, -7.3179e-03,\n",
            "        -9.5324e-07,  2.0164e-03, -2.1804e-03,  5.6052e-45, -1.9715e-03,\n",
            "         7.2405e-03,  7.8599e-03, -1.5669e-02,  5.2896e-03, -2.2058e-03,\n",
            "        -1.2503e-04, -6.3117e-05,  3.3228e-03, -2.3349e-04,  1.1725e-03,\n",
            "        -1.2862e-03,  7.0426e-04, -3.8594e-03,  9.9230e-04,  1.0871e-03,\n",
            "        -4.7676e-04,  6.8428e-04,  1.0384e-02,  4.6128e-04,  4.2935e-05,\n",
            "         8.2003e-03,  2.2844e-03,  1.8556e-03,  3.9523e-03,  6.9541e-04,\n",
            "         6.4452e-03,  1.7056e-03, -7.4520e-03,  6.8709e-03, -1.3630e-02,\n",
            "        -2.9827e-03,  8.7719e-03,  1.4386e-03, -7.1714e-03,  1.3564e-03,\n",
            "        -7.2293e-03, -1.7346e-03,  3.2772e-03,  2.0797e-04,  1.4067e-04,\n",
            "        -8.0829e-03,  8.6918e-03, -9.5291e-03,  7.2517e-03, -2.3323e-03,\n",
            "        -1.4291e-03,  2.5086e-03,  1.9376e-03,  5.3160e-03,  8.2776e-03,\n",
            "         1.8269e-03,  1.7194e-03,  2.2411e-05,  9.8594e-04, -2.0469e-03,\n",
            "        -9.3372e-05, -1.1634e-03, -6.7078e-03,  5.6291e-03,  9.9884e-05,\n",
            "        -5.1759e-03, -3.6860e-03, -5.4953e-03, -7.8176e-04, -6.2593e-04,\n",
            "        -2.1980e-03, -2.8818e-03, -3.9338e-03,  5.0383e-03,  3.4145e-03,\n",
            "        -1.2124e-02,  1.5060e-03,  2.9149e-03, -1.0061e-03,  1.1317e-03,\n",
            "         4.6978e-03, -3.2713e-03, -6.1392e-04,  8.4701e-04, -1.6122e-03,\n",
            "        -1.0900e-02,  1.0942e-02,  1.2206e-02,  8.1548e-03,  2.6852e-03,\n",
            "         1.1662e-02,  9.5182e-03,  4.2444e-03, -5.4630e-03, -3.1069e-03,\n",
            "        -1.9705e-03, -8.3213e-04,  6.3752e-03, -7.6310e-03,  1.3474e-02,\n",
            "         1.3946e-02, -3.2785e-03, -1.5522e-03,  6.7426e-03,  2.7589e-04,\n",
            "         1.8687e-03,  8.7137e-04, -2.7683e-03,  2.0721e-05,  1.1683e-03,\n",
            "        -9.3336e-04,  3.1468e-03, -6.8869e-04,  3.4146e-04,  4.6997e-03,\n",
            "        -1.3585e-04, -4.9362e-04, -6.6390e-04,  1.6643e-03,  9.2661e-03,\n",
            "         4.9991e-03,  4.3127e-04,  6.0388e-04,  7.5814e-04, -1.7296e-03,\n",
            "         4.8266e-04,  1.0964e-10,  1.1602e-03, -5.9920e-03, -1.2516e-02,\n",
            "         6.6580e-03,  1.2994e-02,  6.0913e-03, -3.0977e-04,  1.7941e-03,\n",
            "         2.3013e-03,  6.9521e-03, -1.0826e-02,  2.6959e-03,  3.7000e-03,\n",
            "         1.0383e-02,  3.7340e-04,  1.3037e-03,  3.6067e-03,  1.1733e-03,\n",
            "         4.4444e-04, -3.1624e-04,  1.7925e-02,  4.5602e-04, -5.8197e-04,\n",
            "         8.8616e-04,  3.9439e-03, -8.4399e-04,  8.7584e-04, -1.3509e-03,\n",
            "         2.0119e-03,  3.6709e-03,  1.5008e-02, -7.7909e-03,  6.5423e-07,\n",
            "         6.0373e-03,  2.3125e-03,  2.8381e-03,  3.9327e-04,  1.0019e-03,\n",
            "         4.6251e-03,  2.9233e-03,  9.7378e-03,  6.0989e-03,  3.5462e-04,\n",
            "         1.8554e-04,  1.4685e-03,  3.8210e-03,  3.7752e-03,  1.2980e-04,\n",
            "        -6.6083e-03,  1.1959e-02,  2.3402e-03,  1.7381e-04,  2.1847e-03,\n",
            "         6.2727e-03, -7.8975e-05,  4.8670e-05,  9.5489e-03, -1.7633e-03,\n",
            "        -5.1862e-03, -5.6051e-03,  2.6177e-03,  6.6659e-03, -8.4438e-05,\n",
            "        -1.2034e-03,  3.0692e-03,  1.9176e-03,  6.1867e-04,  8.5348e-05,\n",
            "         3.8154e-03,  6.3968e-04,  7.8209e-03,  3.8369e-03,  1.4785e-02,\n",
            "         1.0205e-03,  9.6508e-03, -5.3181e-03,  7.7896e-03,  9.8449e-04,\n",
            "        -2.3219e-04,  1.0179e-02,  8.8435e-03, -9.8439e-03,  7.3924e-03,\n",
            "        -9.2832e-04,  4.2719e-03,  1.2507e-03,  8.0565e-03, -7.0285e-03,\n",
            "        -5.6052e-45,  4.2008e-03, -1.7951e-03, -2.7108e-05, -4.4077e-04,\n",
            "         3.6600e-03,  2.0051e-03,  4.6983e-03, -4.1313e-03, -5.0915e-03,\n",
            "        -7.1431e-04,  1.5795e-03,  2.5321e-03, -1.9616e-03,  8.0341e-05,\n",
            "        -3.8581e-04, -1.4792e-03,  3.0235e-05, -8.6084e-04,  7.5150e-04,\n",
            "         1.2210e-02,  3.0492e-03, -1.7428e-03,  5.3889e-04, -9.0560e-04,\n",
            "         5.2749e-03,  8.0283e-05, -9.1235e-03, -9.5110e-05,  1.0392e-03,\n",
            "        -1.7476e-03, -8.2137e-05, -2.8585e-06,  3.3003e-03,  2.6876e-05,\n",
            "         1.1943e-02,  1.0404e-02,  3.6535e-03,  7.4913e-03, -2.7463e-02,\n",
            "        -1.1789e-04, -2.8815e-03, -1.1279e-03,  9.4542e-03,  4.3876e-03,\n",
            "         4.4891e-04,  3.5776e-03,  1.1847e-02,  8.7664e-03, -1.2354e-03,\n",
            "        -3.6701e-03, -2.0742e-03,  3.0433e-06,  1.9791e-03,  2.0512e-07,\n",
            "         1.7680e-03,  6.7571e-03,  2.3410e-04,  3.9976e-03, -5.0628e-03,\n",
            "         2.2541e-03, -1.6214e-04,  1.1918e-02,  4.0688e-03,  3.9991e-03,\n",
            "         1.2403e-03, -2.8330e-03, -1.7027e-05,  3.6861e-03, -3.5643e-03,\n",
            "         1.5943e-03, -1.9938e-03,  4.1173e-03, -1.8427e-03, -3.2241e-04,\n",
            "        -1.9768e-03, -2.0271e-03, -8.1028e-03,  2.8167e-04,  9.6417e-05,\n",
            "         3.2580e-04, -9.0089e-04, -1.2977e-02,  7.5414e-03,  4.0002e-03,\n",
            "         3.6090e-04,  5.7961e-03,  2.5767e-03,  1.7226e-03,  1.1985e-04,\n",
            "         1.9859e-03,  2.0207e-03, -7.7451e-06,  1.1581e-03,  2.9913e-03,\n",
            "         4.2987e-06, -1.5219e-03,  4.6812e-03,  1.1916e-02, -4.4578e-03,\n",
            "         4.3672e-04,  3.0771e-03,  2.0998e-03,  6.7999e-03,  3.4180e-09,\n",
            "        -3.9926e-03,  1.7909e-02,  3.2152e-03, -1.0430e-02,  1.6111e-02,\n",
            "        -9.9853e-04, -9.7377e-04, -3.2292e-03,  1.1038e-02, -1.0018e-03,\n",
            "        -4.1044e-03, -2.3081e-03,  1.2152e-02,  2.0122e-02,  4.0533e-03,\n",
            "         5.5609e-04, -5.7073e-03,  4.2503e-03, -7.1647e-03,  1.3971e-02,\n",
            "        -1.0087e-03,  5.8625e-04,  8.9549e-03, -3.4701e-04,  2.3307e-04,\n",
            "         5.1810e-03,  2.5902e-06,  5.1007e-03, -4.6837e-03,  3.5673e-03,\n",
            "         6.6227e-04,  1.7062e-03,  1.4433e-02,  5.0783e-03,  9.4482e-04,\n",
            "         2.4936e-03,  2.0966e-03, -1.1406e-03, -1.4176e-05, -3.4528e-03,\n",
            "        -1.4319e-02, -2.5551e-03,  2.8034e-03, -2.3849e-03, -7.5974e-03,\n",
            "        -1.0676e-03,  7.4127e-03,  3.3257e-03, -2.2988e-05,  1.1244e-02,\n",
            "        -1.2970e-02,  3.5915e-03,  4.9352e-04, -6.2005e-03,  5.2240e-04,\n",
            "        -3.4665e-04,  4.5807e-03], device='cuda:0')}, 22: {'momentum_buffer': tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  8.1366e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  2.6727e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  4.2221e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -8.6739e-07,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.3562e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  3.7731e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  3.4714e-06,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.2230e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -6.7215e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.1173e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  4.5668e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -3.6595e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -2.1647e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  6.7792e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.9717e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -7.8630e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -8.0850e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  6.9106e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  3.5696e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -7.0111e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.7894e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -9.5361e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -5.7565e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.4325e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -4.0218e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -8.1729e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.5912e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.8572e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  3.0713e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  5.2912e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -2.2195e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  2.6904e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.2281e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  9.8496e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.9364e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  6.3822e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0')}, 23: {'momentum_buffer': tensor([ 2.5244e-02,  3.7824e-04, -1.0333e-02,  1.2142e-03,  2.1571e-02,\n",
            "        -2.7745e-02, -1.2399e-02,  8.4255e-04, -5.4018e-04, -2.8878e-03,\n",
            "        -1.4378e-03,  4.1156e-03, -6.9370e-03, -1.9313e-03, -2.2322e-03,\n",
            "         7.0017e-03,  1.3956e-02, -8.3656e-03,  5.1934e-03,  7.9546e-03,\n",
            "        -3.7815e-03,  2.9815e-04,  2.7121e-03,  6.2994e-03, -4.3175e-03,\n",
            "         0.0000e+00,  8.8823e-05,  4.8709e-04, -7.4611e-03, -6.0056e-03,\n",
            "        -4.8348e-03, -3.3452e-03, -3.8424e-04, -2.6446e-03, -6.2598e-03,\n",
            "         0.0000e+00, -7.1172e-06, -3.0610e-03,  1.9511e-02,  5.6052e-45,\n",
            "        -6.7756e-04,  1.4716e-03, -2.1059e-02, -9.9317e-04,  5.1388e-03,\n",
            "         4.4051e-04, -1.3604e-03,  3.8753e-36,  5.1041e-03,  1.4102e-06,\n",
            "         1.3819e-02, -1.5993e-05, -9.0396e-03, -1.4128e-02, -1.9227e-03,\n",
            "        -2.6254e-04,  3.9430e-03, -9.1727e-04,  3.1168e-03, -2.8509e-04,\n",
            "         1.0861e-03, -1.5391e-02, -1.1423e-05, -5.5155e-03, -4.3224e-03,\n",
            "         3.1311e-03, -7.9298e-04, -3.2029e-03, -3.8396e-03,  2.5905e-03,\n",
            "         4.9307e-04, -3.5460e-03, -2.8339e-03, -3.1867e-08, -1.7703e-02,\n",
            "        -2.6971e-02,  5.1615e-03, -1.0048e-02, -1.3674e-02, -3.5805e-03,\n",
            "         1.3942e-02, -5.8941e-06,  2.9129e-03, -2.1413e-03, -1.0926e-02,\n",
            "         1.7523e-03, -3.9278e-05, -3.4060e-03,  7.2055e-03, -1.2242e-03,\n",
            "         1.8858e-03, -6.4778e-07, -9.0583e-05, -2.3779e-02, -7.5610e-05,\n",
            "         1.9881e-03, -3.1020e-04, -1.9096e-02, -1.0316e-02,  5.6052e-45,\n",
            "         4.4231e-08,  5.6052e-45, -6.5541e-03, -4.5440e-04,  2.7050e-03,\n",
            "         1.5812e-03, -1.2901e-02, -2.1607e-02, -3.9476e-03,  8.4243e-03,\n",
            "         2.6524e-02, -4.6637e-03, -1.7524e-05,  4.7154e-11, -3.3670e-03,\n",
            "        -7.5067e-08,  1.2891e-02, -1.6668e-03, -2.3076e-02, -2.2008e-02,\n",
            "        -2.2269e-04, -2.9070e-04,  9.8537e-04, -2.4608e-03, -5.0460e-03,\n",
            "        -1.3404e-03, -2.1781e-04, -1.1595e-02, -1.6968e-03,  3.9438e-08,\n",
            "        -1.0371e-03, -9.9389e-03, -8.2391e-03, -1.8041e-03, -1.4167e-03,\n",
            "        -3.2796e-02,  4.0846e-03,  1.5144e-14, -5.5268e-04, -1.2328e-02,\n",
            "         1.5936e-02,  2.4954e-04, -6.7307e-05, -1.3567e-03, -1.6881e-03,\n",
            "        -1.0610e-02,  6.2341e-04, -4.4321e-06, -4.3266e-03, -1.3249e-03,\n",
            "        -6.4992e-06,  9.0089e-03, -1.2823e-08,  1.4460e-03,  4.6159e-04,\n",
            "        -2.1877e-03, -3.3817e-02,  7.0622e-07, -2.8552e-02, -2.1407e-03,\n",
            "         1.9442e-03, -4.8594e-03, -4.1721e-03, -5.6052e-45, -1.4848e-03,\n",
            "        -4.9255e-09, -4.3729e-03, -4.8950e-03,  6.6206e-32,  1.2032e-02,\n",
            "        -3.0581e-04, -1.4132e-03, -9.9680e-03, -8.8860e-03, -2.2943e-04,\n",
            "         1.6702e-40, -3.8188e-03,  1.8696e-02, -1.5551e-03, -6.7650e-03,\n",
            "         6.7995e-03,  8.1717e-03,  1.6381e-04, -3.9780e-05, -1.4379e-05,\n",
            "         3.2268e-04, -1.3918e-03,  4.0231e-03, -5.2462e-09,  5.2277e-04,\n",
            "         0.0000e+00, -1.6494e-03, -4.7466e-03,  5.8385e-03, -6.7167e-03,\n",
            "        -5.4223e-03, -2.3897e-04, -8.1481e-03,  2.9957e-05, -1.2104e-03,\n",
            "         1.5949e-02, -1.2055e-02, -5.6052e-45,  3.2424e-03,  2.5346e-03,\n",
            "        -9.9670e-04, -1.5087e-02, -3.3532e-03, -3.6385e-04, -4.8213e-03,\n",
            "        -2.0446e-02, -3.3962e-03,  4.3669e-03,  1.3558e-05,  9.8964e-07,\n",
            "         6.6680e-05, -1.9862e-02, -7.1323e-03, -7.7353e-03, -7.6329e-04,\n",
            "         2.4612e-03,  2.2617e-03,  1.0399e-02, -5.8790e-03, -1.2202e-02,\n",
            "        -1.2062e-02, -1.3854e-05, -4.0082e-03,  6.8482e-03,  2.9358e-04,\n",
            "         3.6588e-04, -4.1659e-03, -5.7574e-03, -8.0788e-04, -1.1048e-03,\n",
            "        -4.8394e-03,  3.4653e-09, -2.0751e-02, -9.2885e-04, -1.0989e-03,\n",
            "         8.3298e-03, -4.5560e-03, -5.1117e-03, -1.7570e-03, -1.3546e-03,\n",
            "        -1.0738e-03, -1.2293e-02,  2.8321e-03, -7.1057e-03, -3.8364e-12,\n",
            "         2.3485e-03, -6.5820e-03, -6.0270e-03, -2.5905e-03, -4.8555e-03,\n",
            "         4.3181e-04, -4.0296e-05, -3.4776e-07,  1.5256e-03,  5.4784e-03,\n",
            "        -4.8433e-03, -1.8580e-08, -2.5880e-05,  2.8287e-05, -2.0248e-04,\n",
            "        -2.1614e-03, -6.1279e-03,  2.2437e-02, -3.1637e-03, -2.3703e-03,\n",
            "        -7.7363e-03, -1.1049e-02, -2.5500e-04,  2.0733e-04,  5.5102e-04,\n",
            "         9.5519e-04,  3.7091e-04,  7.2344e-03,  3.3888e-03, -1.5575e-02,\n",
            "        -1.8517e-02, -5.6052e-45, -6.9553e-03, -4.8956e-03,  0.0000e+00,\n",
            "        -3.0817e-03, -3.3002e-04,  1.1600e-08,  3.1280e-05, -1.5107e-02,\n",
            "         2.6682e-03, -9.7050e-03, -1.3165e-04,  4.5954e-03, -3.8100e-04,\n",
            "         1.0843e-02, -5.3538e-03,  2.7864e-04,  4.7477e-03,  3.0349e-03,\n",
            "        -4.6333e-04, -1.5873e-09, -1.7347e-03,  5.4320e-04,  7.4605e-05,\n",
            "        -6.4645e-05,  2.7642e-03, -2.7291e-06, -6.0406e-03, -1.3213e-02,\n",
            "        -5.0812e-04,  2.7405e-04, -5.1602e-05,  1.3530e-02,  1.7544e-02,\n",
            "        -1.4154e-05,  2.1733e-03, -1.1319e-03,  2.1392e-05, -1.9665e-02,\n",
            "        -8.6348e-03, -5.5092e-06,  1.9046e-04, -1.3320e-04,  3.5307e-06,\n",
            "        -4.0759e-03,  4.8909e-04,  5.0149e-04, -7.8969e-08, -6.8006e-03,\n",
            "         1.3754e-09, -1.8523e-05, -5.9876e-04, -4.5940e-03, -6.5936e-32,\n",
            "        -2.1185e-02, -1.3996e-02, -5.5323e-04, -2.0411e-02, -1.2728e-03,\n",
            "         2.2609e-03, -1.4569e-03,  9.5980e-04,  3.2355e-03, -5.6052e-45,\n",
            "        -2.0000e-05, -4.4864e-03, -4.0856e-03, -5.2984e-03, -5.8907e-03,\n",
            "        -4.9336e-03, -4.9837e-03,  0.0000e+00,  4.7350e-03, -2.2314e-02,\n",
            "        -7.5757e-03, -6.7737e-03,  2.9975e-03, -1.8065e-03, -7.1291e-03,\n",
            "        -4.8118e-03,  1.6086e-08, -1.9359e-03, -4.8421e-03,  1.3335e-02,\n",
            "        -8.4043e-04, -7.7612e-03, -1.2422e-02, -1.1588e-05, -1.6314e-02,\n",
            "         8.1186e-03, -4.4076e-03, -6.3792e-03,  8.6071e-03,  7.0961e-04,\n",
            "         5.0625e-04, -8.2882e-03, -1.5538e-04, -1.2648e-02,  1.1076e-02,\n",
            "        -1.5552e-02, -4.1941e-04,  4.1625e-03, -1.1455e-02, -2.9486e-02,\n",
            "         1.1892e-03, -8.0777e-03, -2.0499e-03,  1.6054e-03, -5.8300e-03,\n",
            "        -4.6904e-05,  9.0287e-03, -5.9599e-04,  5.6822e-03,  8.7768e-03,\n",
            "        -7.1731e-04, -2.3061e-03, -1.5038e-03, -4.6371e-03, -1.3913e-03,\n",
            "         5.5717e-03,  6.5369e-03, -4.5327e-07,  4.2871e-03, -5.0721e-12,\n",
            "        -8.0443e-03,  1.9052e-04, -5.1711e-04, -1.2644e-02, -6.3896e-03,\n",
            "        -2.8297e-02,  2.7815e-03, -1.2841e-02, -6.5606e-03, -1.3944e-02,\n",
            "        -1.3158e-02, -1.0065e-02,  9.6939e-05,  4.8547e-07, -6.1470e-03,\n",
            "        -3.6424e-03, -2.0628e-03, -8.2681e-06,  5.8920e-07,  3.8545e-05,\n",
            "        -9.0085e-03,  9.9678e-05,  3.2888e-05,  3.4671e-03, -7.2093e-03,\n",
            "        -6.0446e-03, -1.8485e-03, -3.1650e-03, -4.3807e-02,  0.0000e+00,\n",
            "         1.6019e-02, -9.0257e-03, -1.7474e-03,  2.4846e-03,  1.5104e-03,\n",
            "         1.6860e-03, -5.6052e-45,  1.4187e-03,  2.9986e-03, -1.0147e-02,\n",
            "        -4.7589e-08,  5.8787e-03,  3.6733e-03,  3.8011e-04, -5.0682e-04,\n",
            "        -3.9109e-02, -4.2114e-03, -4.4754e-03,  5.9831e-04, -1.0116e-02,\n",
            "         5.6052e-45, -1.7316e-02,  2.1811e-05,  1.1321e-05, -7.5172e-03,\n",
            "         8.7239e-04, -2.8751e-04, -4.0253e-02,  8.9967e-05, -1.2829e-03,\n",
            "         6.3625e-04, -8.8973e-03, -2.7272e-06, -9.9838e-03, -3.1499e-03,\n",
            "         4.3774e-03, -3.7713e-03, -6.5223e-04, -5.0217e-04,  2.2902e-03,\n",
            "        -1.4268e-03, -2.0122e-04, -1.3869e-02, -1.8208e-03,  1.0865e-02,\n",
            "         2.6008e-04,  3.9011e-03, -2.2158e-04,  1.9925e-02, -6.2548e-05,\n",
            "        -3.3082e-04, -1.9071e-02, -4.6666e-03, -1.6248e-04, -2.9704e-03,\n",
            "        -3.3012e-03,  1.8040e-03, -1.2641e-03, -3.3986e-03,  1.7258e-03,\n",
            "         1.0587e-02,  4.3633e-03,  3.1582e-10, -2.1626e-02, -7.7142e-03,\n",
            "        -2.2753e-04,  0.0000e+00, -9.8744e-03, -1.2728e-03,  2.4460e-02,\n",
            "        -3.7612e-03, -1.9897e-03,  6.5619e-06,  1.4888e-03,  1.1916e-03,\n",
            "        -5.6052e-45,  1.4537e-02], device='cuda:0')}, 24: {'momentum_buffer': tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.6373e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  2.5502e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  7.7881e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  2.4784e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.1289e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.2621e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  2.8754e-06,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -4.7397e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  7.5581e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.2327e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  6.6900e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -7.3145e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.4197e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.4686e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  5.4297e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  5.4770e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.6794e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.6860e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -2.4337e-09,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.0516e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -1.9798e-06,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -4.6707e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  4.4523e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -2.7249e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -5.6052e-45,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -5.6052e-45,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -5.6052e-45,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -5.6052e-45,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -5.6052e-45,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -5.6052e-45,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  2.6380e-05,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  2.2964e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  8.4944e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  3.4962e-03,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  8.8837e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  2.6400e-06,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0')}, 25: {'momentum_buffer': tensor([[-0.0002, -0.0002, -0.0002,  ..., -0.0003, -0.0003, -0.0003],\n",
            "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
            "        [-0.0001, -0.0001, -0.0001,  ..., -0.0015, -0.0015, -0.0015],\n",
            "        ...,\n",
            "        [ 0.0003,  0.0003,  0.0003,  ..., -0.0006, -0.0006, -0.0006],\n",
            "        [ 0.0003,  0.0003,  0.0003,  ..., -0.0012, -0.0012, -0.0012],\n",
            "        [-0.0005, -0.0005, -0.0005,  ...,  0.0006,  0.0006,  0.0006]],\n",
            "       device='cuda:0')}, 26: {'momentum_buffer': tensor([[ 0.0163,  0.0105,  0.0107, -0.0012, -0.0017,  0.0056,  0.0097, -0.0159,\n",
            "         -0.0040,  0.0087, -0.0063,  0.0026, -0.0012,  0.0134, -0.0011,  0.0099,\n",
            "         -0.0065, -0.0060, -0.0188, -0.0254, -0.0109,  0.0052, -0.0150,  0.0088,\n",
            "          0.0147, -0.0159,  0.0183,  0.0029, -0.0183, -0.0042, -0.0289, -0.0166,\n",
            "         -0.0093, -0.0056, -0.0065,  0.0095, -0.0007,  0.0099,  0.0113,  0.0017,\n",
            "          0.0017,  0.0187, -0.0094,  0.0190, -0.0168,  0.0027,  0.0099, -0.0149,\n",
            "         -0.0021,  0.0064,  0.0162,  0.0098,  0.0182, -0.0042, -0.0063, -0.0111,\n",
            "          0.0083,  0.0020,  0.0207,  0.0050, -0.0122, -0.0046, -0.0133,  0.0034],\n",
            "        [-0.0016,  0.0020,  0.0157,  0.0169, -0.0160,  0.0021,  0.0074,  0.0206,\n",
            "          0.0033,  0.0064,  0.0124,  0.0019, -0.0207, -0.0078,  0.0047, -0.0070,\n",
            "         -0.0153, -0.0106,  0.0043,  0.0028, -0.0140,  0.0163,  0.0058,  0.0059,\n",
            "         -0.0020, -0.0202,  0.0068,  0.0049, -0.0048,  0.0189,  0.0049,  0.0111,\n",
            "          0.0203,  0.0068,  0.0129,  0.0003, -0.0028, -0.0060,  0.0298, -0.0037,\n",
            "         -0.0211, -0.0041, -0.0079,  0.0295, -0.0252,  0.0159,  0.0031, -0.0026,\n",
            "          0.0108,  0.0006,  0.0092, -0.0019,  0.0195,  0.0102, -0.0090, -0.0286,\n",
            "          0.0085,  0.0054, -0.0185,  0.0041, -0.0055,  0.0129, -0.0080, -0.0066],\n",
            "        [-0.0179, -0.0264, -0.0246, -0.0375,  0.0169,  0.0220,  0.0035, -0.0380,\n",
            "          0.0133, -0.0015, -0.0214,  0.0065,  0.0267, -0.0100,  0.0053,  0.0115,\n",
            "          0.0673,  0.0368,  0.0026, -0.0131,  0.0003, -0.0428,  0.0044,  0.0075,\n",
            "         -0.0125,  0.0113,  0.0231, -0.0280,  0.0044, -0.0226, -0.0018, -0.0151,\n",
            "         -0.0186, -0.0340,  0.0056, -0.0089,  0.0228, -0.0254, -0.0327,  0.0080,\n",
            "          0.0319,  0.0141,  0.0208, -0.0130,  0.0282, -0.0248,  0.0075, -0.0146,\n",
            "          0.0032,  0.0076,  0.0125,  0.0066, -0.0244, -0.0063,  0.0159,  0.0278,\n",
            "          0.0024, -0.0022,  0.0184, -0.0483,  0.0065, -0.0152, -0.0018, -0.0024],\n",
            "        [-0.0223, -0.0289,  0.0008, -0.0568,  0.0193,  0.0149, -0.0501, -0.0132,\n",
            "          0.0220,  0.0927,  0.0344, -0.0498,  0.0357,  0.0082, -0.0198, -0.0164,\n",
            "          0.0290,  0.0805,  0.0004,  0.0204, -0.0190, -0.0561,  0.0255, -0.0175,\n",
            "         -0.0127, -0.0108,  0.0329,  0.0232, -0.0359, -0.0003,  0.0010,  0.0356,\n",
            "         -0.0171, -0.0011, -0.0209,  0.0031,  0.0337, -0.0227,  0.0103,  0.0227,\n",
            "          0.0531,  0.0344, -0.0714, -0.0869, -0.0192,  0.0081, -0.0261,  0.0318,\n",
            "         -0.0597, -0.0265,  0.0468,  0.0052, -0.0252,  0.0280,  0.0165,  0.0040,\n",
            "          0.0172, -0.0211,  0.0090, -0.0051,  0.0321,  0.0423, -0.0013,  0.0042],\n",
            "        [-0.0057,  0.0061,  0.0465, -0.0019, -0.0071,  0.0321, -0.0031,  0.0119,\n",
            "          0.0015,  0.0244,  0.0241,  0.0025, -0.0133, -0.0357, -0.0116, -0.0092,\n",
            "          0.0018,  0.0294,  0.0143, -0.0269, -0.0181, -0.0141,  0.0452,  0.0176,\n",
            "         -0.0145, -0.0155, -0.0021, -0.0094, -0.0248, -0.0100, -0.0072,  0.0296,\n",
            "          0.0315, -0.0267,  0.0004, -0.0042,  0.0105, -0.0460,  0.0210, -0.0058,\n",
            "         -0.0102,  0.0056,  0.0036,  0.0206, -0.0360,  0.0027,  0.0092,  0.0095,\n",
            "         -0.0069, -0.0026,  0.0360, -0.0266,  0.0101, -0.0179,  0.0062, -0.0189,\n",
            "          0.0310, -0.0206, -0.0261, -0.0086, -0.0101,  0.0302, -0.0378, -0.0183],\n",
            "        [-0.0086,  0.0039, -0.0166,  0.0523,  0.0011, -0.0361,  0.0174,  0.0631,\n",
            "         -0.0035, -0.0393,  0.0101,  0.0196, -0.0294,  0.0166,  0.0038, -0.0125,\n",
            "         -0.0385, -0.0552,  0.0207,  0.0165,  0.0269,  0.0472, -0.0093, -0.0182,\n",
            "          0.0059,  0.0055, -0.0459,  0.0116,  0.0265,  0.0400,  0.0425, -0.0027,\n",
            "          0.0050,  0.0539,  0.0170,  0.0144, -0.0245,  0.0194, -0.0045, -0.0079,\n",
            "         -0.0492, -0.0362,  0.0221,  0.0342, -0.0021,  0.0062, -0.0028, -0.0031,\n",
            "          0.0462, -0.0100, -0.0568, -0.0039,  0.0016,  0.0021, -0.0031, -0.0140,\n",
            "          0.0005, -0.0016, -0.0226,  0.0425, -0.0137, -0.0040,  0.0140,  0.0106],\n",
            "        [ 0.0119,  0.0231, -0.0074,  0.0400, -0.0262, -0.0155,  0.0210,  0.0140,\n",
            "         -0.0157, -0.0539, -0.0178,  0.0143, -0.0269, -0.0027,  0.0167,  0.0044,\n",
            "         -0.0284, -0.0561,  0.0011,  0.0059,  0.0132,  0.0421, -0.0181,  0.0084,\n",
            "          0.0028,  0.0108, -0.0165, -0.0068,  0.0329,  0.0047,  0.0047, -0.0122,\n",
            "          0.0150,  0.0088,  0.0180, -0.0086, -0.0211,  0.0227,  0.0011, -0.0147,\n",
            "         -0.0317, -0.0299,  0.0382,  0.0371,  0.0119,  0.0058,  0.0029, -0.0060,\n",
            "          0.0249,  0.0200, -0.0323,  0.0029,  0.0152, -0.0041, -0.0210,  0.0006,\n",
            "         -0.0259,  0.0208, -0.0133,  0.0095, -0.0040, -0.0269,  0.0228, -0.0061],\n",
            "        [-0.0143, -0.0360, -0.0209, -0.0196,  0.0102, -0.0172, -0.0064,  0.0061,\n",
            "          0.0172,  0.0099, -0.0021, -0.0047,  0.0176,  0.0374,  0.0026, -0.0071,\n",
            "          0.0071,  0.0168, -0.0018,  0.0150,  0.0051, -0.0129, -0.0175, -0.0170,\n",
            "         -0.0040,  0.0014,  0.0057,  0.0197, -0.0123,  0.0233,  0.0275, -0.0065,\n",
            "         -0.0066,  0.0230, -0.0117,  0.0225, -0.0067,  0.0098, -0.0239,  0.0117,\n",
            "          0.0047,  0.0054, -0.0270, -0.0204,  0.0051,  0.0005, -0.0114, -0.0039,\n",
            "          0.0013, -0.0216, -0.0076,  0.0108, -0.0187,  0.0195,  0.0013,  0.0101,\n",
            "          0.0010, -0.0017,  0.0110,  0.0120,  0.0118,  0.0088,  0.0210,  0.0189],\n",
            "        [-0.0006, -0.0060, -0.0013,  0.0148, -0.0113,  0.0074, -0.0035, -0.0047,\n",
            "         -0.0084, -0.0204, -0.0097,  0.0085, -0.0226, -0.0130,  0.0186, -0.0044,\n",
            "          0.0023, -0.0169,  0.0100,  0.0176,  0.0094,  0.0138, -0.0002,  0.0041,\n",
            "          0.0087, -0.0021,  0.0050, -0.0041,  0.0357,  0.0007,  0.0153, -0.0115,\n",
            "          0.0134, -0.0043,  0.0137, -0.0270, -0.0023, -0.0035, -0.0010, -0.0078,\n",
            "         -0.0188,  0.0087,  0.0171,  0.0142,  0.0201,  0.0017,  0.0212, -0.0119,\n",
            "          0.0121,  0.0099,  0.0021, -0.0034, -0.0007,  0.0116,  0.0023,  0.0073,\n",
            "         -0.0276,  0.0205, -0.0073, -0.0153, -0.0115,  0.0013, -0.0031, -0.0075],\n",
            "        [ 0.0429,  0.0517, -0.0030, -0.0069,  0.0148, -0.0153,  0.0040, -0.0439,\n",
            "         -0.0257, -0.0271, -0.0238, -0.0014,  0.0341, -0.0065, -0.0193,  0.0308,\n",
            "         -0.0189, -0.0187, -0.0330, -0.0129,  0.0071,  0.0012, -0.0208,  0.0004,\n",
            "          0.0135,  0.0355, -0.0274, -0.0139, -0.0035, -0.0505, -0.0579, -0.0116,\n",
            "         -0.0336, -0.0209, -0.0285, -0.0011, -0.0088,  0.0418, -0.0115, -0.0042,\n",
            "          0.0395, -0.0168,  0.0138, -0.0343,  0.0341, -0.0188, -0.0134,  0.0157,\n",
            "         -0.0298,  0.0162, -0.0261,  0.0005,  0.0043, -0.0388, -0.0029,  0.0227,\n",
            "         -0.0154, -0.0016,  0.0287,  0.0042,  0.0067, -0.0448,  0.0075,  0.0040]],\n",
            "       device='cuda:0')}}\n",
            "param_groups \t [{'lr': 0.01, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]}]\n"
          ]
        }
      ],
      "source": [
        "# Print model's state_dict\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "# Print optimizer's state_dict\n",
        "print(\"Optimizer's state_dict:\")\n",
        "for var_name in optimizer.state_dict():\n",
        "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za1A9Fn3A6t6"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FED57WTBWXJ"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(),'densenet_80_after.pt')\n",
        "!gzip -qf /content/densenet_80_after.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5syxsD4b1DfE"
      },
      "source": [
        "# Flops Counter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQXzFj351H0m",
        "outputId": "dc0eca26-5e57-404d-9aac-117b984caad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: module Bottleneck is treated as a zero-op.\n",
            "Warning: module Convnet is treated as a zero-op.\n",
            "Convnet(\n",
            "  23.64 M, 100.000% Params, 84.21 MMac, 100.000% MACs, \n",
            "  (l1): Sequential(\n",
            "    23.51 M, 99.443% Params, 84.08 MMac, 99.844% MACs, \n",
            "    (0): Conv2d(9.41 k, 0.040% Params, 2.41 MMac, 2.860% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(128, 0.001% Params, 32.77 KMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(0, 0.000% Params, 16.38 KMac, 0.019% MACs, inplace=True)\n",
            "    (3): MaxPool2d(0, 0.000% Params, 16.38 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (4): Sequential(\n",
            "      215.81 k, 0.913% Params, 13.89 MMac, 16.489% MACs, \n",
            "      (0): Bottleneck(\n",
            "        75.01 k, 0.317% Params, 4.83 MMac, 5.730% MACs, \n",
            "        (conv1): Conv2d(4.1 k, 0.017% Params, 262.14 KMac, 0.311% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, 0.001% Params, 8.19 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(36.86 k, 0.156% Params, 2.36 MMac, 2.802% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, 0.001% Params, 8.19 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(16.38 k, 0.069% Params, 1.05 MMac, 1.245% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, 0.002% Params, 32.77 KMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(0, 0.000% Params, 24.58 KMac, 0.029% MACs, inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          16.9 k, 0.071% Params, 1.08 MMac, 1.284% MACs, \n",
            "          (0): Conv2d(16.38 k, 0.069% Params, 1.05 MMac, 1.245% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, 0.002% Params, 32.77 KMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        70.4 k, 0.298% Params, 4.53 MMac, 5.380% MACs, \n",
            "        (conv1): Conv2d(16.38 k, 0.069% Params, 1.05 MMac, 1.245% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, 0.001% Params, 8.19 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(36.86 k, 0.156% Params, 2.36 MMac, 2.802% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, 0.001% Params, 8.19 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(16.38 k, 0.069% Params, 1.05 MMac, 1.245% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, 0.002% Params, 32.77 KMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(0, 0.000% Params, 24.58 KMac, 0.029% MACs, inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        70.4 k, 0.298% Params, 4.53 MMac, 5.380% MACs, \n",
            "        (conv1): Conv2d(16.38 k, 0.069% Params, 1.05 MMac, 1.245% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, 0.001% Params, 8.19 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(36.86 k, 0.156% Params, 2.36 MMac, 2.802% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, 0.001% Params, 8.19 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(16.38 k, 0.069% Params, 1.05 MMac, 1.245% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, 0.002% Params, 32.77 KMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(0, 0.000% Params, 24.58 KMac, 0.029% MACs, inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      1.22 M, 5.159% Params, 21.15 MMac, 25.120% MACs, \n",
            "      (0): Bottleneck(\n",
            "        379.39 k, 1.605% Params, 7.67 MMac, 9.113% MACs, \n",
            "        (conv1): Conv2d(32.77 k, 0.139% Params, 2.1 MMac, 2.490% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, 0.001% Params, 16.38 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(147.46 k, 0.624% Params, 2.36 MMac, 2.802% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, 0.001% Params, 4.1 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(65.54 k, 0.277% Params, 1.05 MMac, 1.245% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1.02 k, 0.004% Params, 16.38 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(0, 0.000% Params, 18.43 KMac, 0.022% MACs, inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          132.1 k, 0.559% Params, 2.11 MMac, 2.510% MACs, \n",
            "          (0): Conv2d(131.07 k, 0.554% Params, 2.1 MMac, 2.490% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1.02 k, 0.004% Params, 16.38 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        280.06 k, 1.185% Params, 4.49 MMac, 5.336% MACs, \n",
            "        (conv1): Conv2d(65.54 k, 0.277% Params, 1.05 MMac, 1.245% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, 0.001% Params, 4.1 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(147.46 k, 0.624% Params, 2.36 MMac, 2.802% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, 0.001% Params, 4.1 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(65.54 k, 0.277% Params, 1.05 MMac, 1.245% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1.02 k, 0.004% Params, 16.38 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(0, 0.000% Params, 12.29 KMac, 0.015% MACs, inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        280.06 k, 1.185% Params, 4.49 MMac, 5.336% MACs, \n",
            "        (conv1): Conv2d(65.54 k, 0.277% Params, 1.05 MMac, 1.245% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, 0.001% Params, 4.1 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(147.46 k, 0.624% Params, 2.36 MMac, 2.802% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, 0.001% Params, 4.1 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(65.54 k, 0.277% Params, 1.05 MMac, 1.245% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1.02 k, 0.004% Params, 16.38 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(0, 0.000% Params, 12.29 KMac, 0.015% MACs, inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        280.06 k, 1.185% Params, 4.49 MMac, 5.336% MACs, \n",
            "        (conv1): Conv2d(65.54 k, 0.277% Params, 1.05 MMac, 1.245% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, 0.001% Params, 4.1 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(147.46 k, 0.624% Params, 2.36 MMac, 2.802% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, 0.001% Params, 4.1 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(65.54 k, 0.277% Params, 1.05 MMac, 1.245% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1.02 k, 0.004% Params, 16.38 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(0, 0.000% Params, 12.29 KMac, 0.015% MACs, inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      7.1 M, 30.027% Params, 30.01 MMac, 35.640% MACs, \n",
            "      (0): Bottleneck(\n",
            "        1.51 M, 6.398% Params, 7.64 MMac, 9.070% MACs, \n",
            "        (conv1): Conv2d(131.07 k, 0.554% Params, 2.1 MMac, 2.490% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, 0.002% Params, 8.19 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(589.82 k, 2.495% Params, 2.36 MMac, 2.802% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, 0.002% Params, 2.05 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(262.14 k, 1.109% Params, 1.05 MMac, 1.245% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2.05 k, 0.009% Params, 8.19 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(0, 0.000% Params, 9.22 KMac, 0.011% MACs, inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          526.34 k, 2.226% Params, 2.11 MMac, 2.500% MACs, \n",
            "          (0): Conv2d(524.29 k, 2.218% Params, 2.1 MMac, 2.490% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2.05 k, 0.009% Params, 8.19 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        1.12 M, 4.726% Params, 4.47 MMac, 5.314% MACs, \n",
            "        (conv1): Conv2d(262.14 k, 1.109% Params, 1.05 MMac, 1.245% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, 0.002% Params, 2.05 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(589.82 k, 2.495% Params, 2.36 MMac, 2.802% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, 0.002% Params, 2.05 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(262.14 k, 1.109% Params, 1.05 MMac, 1.245% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2.05 k, 0.009% Params, 8.19 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(0, 0.000% Params, 6.14 KMac, 0.007% MACs, inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        1.12 M, 4.726% Params, 4.47 MMac, 5.314% MACs, \n",
            "        (conv1): Conv2d(262.14 k, 1.109% Params, 1.05 MMac, 1.245% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, 0.002% Params, 2.05 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(589.82 k, 2.495% Params, 2.36 MMac, 2.802% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, 0.002% Params, 2.05 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(262.14 k, 1.109% Params, 1.05 MMac, 1.245% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2.05 k, 0.009% Params, 8.19 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(0, 0.000% Params, 6.14 KMac, 0.007% MACs, inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        1.12 M, 4.726% Params, 4.47 MMac, 5.314% MACs, \n",
            "        (conv1): Conv2d(262.14 k, 1.109% Params, 1.05 MMac, 1.245% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, 0.002% Params, 2.05 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(589.82 k, 2.495% Params, 2.36 MMac, 2.802% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, 0.002% Params, 2.05 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(262.14 k, 1.109% Params, 1.05 MMac, 1.245% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2.05 k, 0.009% Params, 8.19 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(0, 0.000% Params, 6.14 KMac, 0.007% MACs, inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        1.12 M, 4.726% Params, 4.47 MMac, 5.314% MACs, \n",
            "        (conv1): Conv2d(262.14 k, 1.109% Params, 1.05 MMac, 1.245% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, 0.002% Params, 2.05 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(589.82 k, 2.495% Params, 2.36 MMac, 2.802% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, 0.002% Params, 2.05 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(262.14 k, 1.109% Params, 1.05 MMac, 1.245% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2.05 k, 0.009% Params, 8.19 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(0, 0.000% Params, 6.14 KMac, 0.007% MACs, inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        1.12 M, 4.726% Params, 4.47 MMac, 5.314% MACs, \n",
            "        (conv1): Conv2d(262.14 k, 1.109% Params, 1.05 MMac, 1.245% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, 0.002% Params, 2.05 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(589.82 k, 2.495% Params, 2.36 MMac, 2.802% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, 0.002% Params, 2.05 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(262.14 k, 1.109% Params, 1.05 MMac, 1.245% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2.05 k, 0.009% Params, 8.19 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(0, 0.000% Params, 6.14 KMac, 0.007% MACs, inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      14.96 M, 63.303% Params, 16.55 MMac, 19.655% MACs, \n",
            "      (0): Bottleneck(\n",
            "        6.04 M, 25.548% Params, 7.62 MMac, 9.049% MACs, \n",
            "        (conv1): Conv2d(524.29 k, 2.218% Params, 2.1 MMac, 2.490% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(1.02 k, 0.004% Params, 4.1 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(2.36 M, 9.980% Params, 2.36 MMac, 2.802% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(1.02 k, 0.004% Params, 1.02 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(1.05 M, 4.436% Params, 1.05 MMac, 1.245% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(4.1 k, 0.017% Params, 4.1 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(0, 0.000% Params, 4.61 KMac, 0.005% MACs, inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          2.1 M, 8.889% Params, 2.1 MMac, 2.495% MACs, \n",
            "          (0): Conv2d(2.1 M, 8.871% Params, 2.1 MMac, 2.490% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(4.1 k, 0.017% Params, 4.1 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        4.46 M, 18.877% Params, 4.47 MMac, 5.303% MACs, \n",
            "        (conv1): Conv2d(1.05 M, 4.436% Params, 1.05 MMac, 1.245% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(1.02 k, 0.004% Params, 1.02 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(2.36 M, 9.980% Params, 2.36 MMac, 2.802% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(1.02 k, 0.004% Params, 1.02 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(1.05 M, 4.436% Params, 1.05 MMac, 1.245% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(4.1 k, 0.017% Params, 4.1 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(0, 0.000% Params, 3.07 KMac, 0.004% MACs, inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        4.46 M, 18.877% Params, 4.47 MMac, 5.303% MACs, \n",
            "        (conv1): Conv2d(1.05 M, 4.436% Params, 1.05 MMac, 1.245% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(1.02 k, 0.004% Params, 1.02 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(2.36 M, 9.980% Params, 2.36 MMac, 2.802% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(1.02 k, 0.004% Params, 1.02 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(1.05 M, 4.436% Params, 1.05 MMac, 1.245% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(4.1 k, 0.017% Params, 4.1 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(0, 0.000% Params, 3.07 KMac, 0.004% MACs, inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (8): AdaptiveAvgPool2d(0, 0.000% Params, 2.05 KMac, 0.002% MACs, output_size=(1, 1))\n",
            "  )\n",
            "  (l2): Linear(131.07 k, 0.554% Params, 131.07 KMac, 0.156% MACs, in_features=2048, out_features=64, bias=False)\n",
            "  (l3): Linear(640, 0.003% Params, 640.0 Mac, 0.001% MACs, in_features=64, out_features=10, bias=False)\n",
            ")\n",
            "Computational complexity:       84.21 MMac\n",
            "Number of parameters:           23.64 M \n"
          ]
        }
      ],
      "source": [
        "with torch.cuda.device(0):\n",
        "  net = model\n",
        "  macs, params = get_model_complexity_info(net, (3, 32, 32), as_strings=True, print_per_layer_stat=True, verbose=True)\n",
        "  print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
        "  print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxAtdGhthHUp"
      },
      "source": [
        "# Model Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bCkAAI5hKUB",
        "outputId": "2d552a6d-e985-4038-cf7a-bc3a6995c2a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model size: 62.259MB\n"
          ]
        }
      ],
      "source": [
        "model = model #models.resnet18()\n",
        "param_size = 0\n",
        "for param in model.parameters():\n",
        "    param_size += param.nelement() * param.element_size()\n",
        "buffer_size = 0\n",
        "for buffer in model.buffers():\n",
        "    buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "print('model size: {:.3f}MB'.format(size_all_mb))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_nonzeros(model):\n",
        "    nonzero = total = 0\n",
        "    for name, p in model.named_parameters():\n",
        "        tensor = p.data.cpu().numpy()\n",
        "        nz_count = np.count_nonzero(tensor)\n",
        "        total_params = np.prod(tensor.shape)\n",
        "        nonzero += nz_count\n",
        "        total += total_params\n",
        "        print(f'{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | total_pruned = {total_params - nz_count :7} | shape = {tensor.shape}')\n",
        "    print(f'alive: {nonzero}, pruned : {total - nonzero}, total: {total}, Compression rate : {total/nonzero:10.2f}x  ({100 * (total-nonzero) / total:6.2f}% pruned)')\n",
        "    return (round((nonzero/total)*100,1))"
      ],
      "metadata": {
        "id": "PsDkTvkiXqYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_nonzeros(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjPpu_OQaV-a",
        "outputId": "84719c06-dc05-457b-ae76-1d4a55890e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l1.0.bias            | nonzeros =      64 /      64 (100.00%) | total_pruned =       0 | shape = (64,)\n",
            "l1.0.weight          | nonzeros =    1676 /    1728 ( 96.99%) | total_pruned =      52 | shape = (64, 3, 3, 3)\n",
            "l1.2.bias            | nonzeros =      64 /      64 (100.00%) | total_pruned =       0 | shape = (64,)\n",
            "l1.2.weight          | nonzeros =   32024 /   36864 ( 86.87%) | total_pruned =    4840 | shape = (64, 64, 3, 3)\n",
            "l1.5.bias            | nonzeros =     128 /     128 (100.00%) | total_pruned =       0 | shape = (128,)\n",
            "l1.5.weight          | nonzeros =   63608 /   73728 ( 86.27%) | total_pruned =   10120 | shape = (128, 64, 3, 3)\n",
            "l1.7.bias            | nonzeros =     128 /     128 (100.00%) | total_pruned =       0 | shape = (128,)\n",
            "l1.7.weight          | nonzeros =  123846 /  147456 ( 83.99%) | total_pruned =   23610 | shape = (128, 128, 3, 3)\n",
            "l1.10.bias           | nonzeros =     256 /     256 (100.00%) | total_pruned =       0 | shape = (256,)\n",
            "l1.10.weight         | nonzeros =  239841 /  294912 ( 81.33%) | total_pruned =   55071 | shape = (256, 128, 3, 3)\n",
            "l1.12.bias           | nonzeros =     256 /     256 (100.00%) | total_pruned =       0 | shape = (256,)\n",
            "l1.12.weight         | nonzeros =  456743 /  589824 ( 77.44%) | total_pruned =  133081 | shape = (256, 256, 3, 3)\n",
            "l1.14.bias           | nonzeros =     256 /     256 (100.00%) | total_pruned =       0 | shape = (256,)\n",
            "l1.14.weight         | nonzeros =  459275 /  589824 ( 77.87%) | total_pruned =  130549 | shape = (256, 256, 3, 3)\n",
            "l1.17.bias           | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)\n",
            "l1.17.weight         | nonzeros =  872143 / 1179648 ( 73.93%) | total_pruned =  307505 | shape = (512, 256, 3, 3)\n",
            "l1.19.bias           | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)\n",
            "l1.19.weight         | nonzeros = 1595502 / 2359296 ( 67.63%) | total_pruned =  763794 | shape = (512, 512, 3, 3)\n",
            "l1.21.bias           | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)\n",
            "l1.21.weight         | nonzeros = 1595408 / 2359296 ( 67.62%) | total_pruned =  763888 | shape = (512, 512, 3, 3)\n",
            "l1.24.bias           | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)\n",
            "l1.24.weight         | nonzeros = 1642717 / 2359296 ( 69.63%) | total_pruned =  716579 | shape = (512, 512, 3, 3)\n",
            "l1.26.bias           | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)\n",
            "l1.26.weight         | nonzeros = 1645744 / 2359296 ( 69.76%) | total_pruned =  713552 | shape = (512, 512, 3, 3)\n",
            "l1.28.bias           | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)\n",
            "l1.28.weight         | nonzeros = 1568798 / 2359296 ( 66.49%) | total_pruned =  790498 | shape = (512, 512, 3, 3)\n",
            "l3.weight            | nonzeros = 1123942 / 1605632 ( 70.00%) | total_pruned =  481690 | shape = (64, 25088)\n",
            "l4.weight            | nonzeros =     448 /     640 ( 70.00%) | total_pruned =     192 | shape = (10, 64)\n",
            "alive: 11425939, pruned : 4895021, total: 16320960, Compression rate :       1.43x  ( 29.99% pruned)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70.0"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get_model_complexity_info(model,)"
      ],
      "metadata": {
        "id": "7SzJpoM9i82X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTr8dhcDEfYT"
      },
      "source": [
        "# Visualization "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8tTFHAjEjX9"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.plot(loss_values)\n",
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}